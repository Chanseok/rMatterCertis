# Matter Certis v2 - Development Roadmap (ì—…ë°ì´íŠ¸)

**ğŸ“… ì—…ë°ì´íŠ¸: 2025ë…„ 7ì›” 2ì¼**
**ğŸ¯ í˜„ì¬ ìƒíƒœ: Phase 3 ì™„ë£Œ, Phase 4 ì‹œì‘**

## ğŸ† **ì™„ë£Œëœ ì£¼ìš” ë§ˆì¼ìŠ¤í†¤ë“¤**

### âœ… Phase 1-3 ì™„ë£Œ (2025ë…„ 7ì›” ì™„ë£Œ!)
- **í†µí•© ì„¤ì • ê´€ë¦¬**: ë°±ì—”ë“œ ë‹¨ì¼ ì§„ì‹¤ ì†ŒìŠ¤, IPC ê¸°ë°˜ ì„¤ì • ë¡œë“œ
- **ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ**: EventEmitter + í”„ë¡ íŠ¸ì—”ë“œ êµ¬ë…ì ì™„ì„±
- **SolidJS í”„ë¡ íŠ¸ì—”ë“œ**: ì™„ì „í•œ UI ë° ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
- **BatchCrawlingEngine**: 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ê¸°ë³¸ êµ¬ì¡° ì™„ì„±
- **íƒ€ì… ì•ˆì „ IPC**: ë°±ì—”ë“œ-í”„ë¡ íŠ¸ì—”ë“œ ì™„ì „í•œ íƒ€ì… ë§¤í•‘
- **ì½”ë“œ í’ˆì§ˆ**: 39ê°œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼, clippy ê²½ê³  ìµœì†Œí™”

---

## ğŸš€ **Phase 4: ê³ ê¸‰ í¬ë¡¤ë§ ì‹œìŠ¤í…œ (í˜„ì¬ ì§„í–‰ì¤‘ 15%)**

### ğŸ¯ **Phase 4.1: ì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ê³ ë„í™”** (4ì£¼)

#### Week 1-2: BatchCrawlingEngine ì„œë¹„ìŠ¤ ë¶„ë¦¬
**ëª©í‘œ**: í˜„ì¬ ë¸”ë™ë°•ìŠ¤ êµ¬ì¡°ë¥¼ ëª…ì‹œì  ì„œë¹„ìŠ¤ ë ˆì´ì–´ë¡œ ë¶„í•´

**í˜„ì¬ êµ¬ì¡°:**
```rust
impl BatchCrawlingEngine {
    pub async fn execute(&self) -> Result<()> {
        // ëª¨ë“  ë¡œì§ì´ í•˜ë‚˜ì˜ ë©”ì„œë“œì— í¬í•¨ë¨
        let total_pages = self.stage1_discover_total_pages().await?;
        let product_urls = self.stage2_collect_product_list(total_pages).await?;
        // ...
    }
}
```

**ëª©í‘œ êµ¬ì¡°:**
```rust
pub struct BatchCrawlingEngine {
    status_checker: Arc<dyn StatusChecker>,
    database_analyzer: Arc<dyn DatabaseAnalyzer>,
    product_list_collector: Arc<dyn ProductListCollector>,
    product_detail_collector: Arc<dyn ProductDetailCollector>,
    event_emitter: Arc<Option<EventEmitter>>,
}

impl BatchCrawlingEngine {
    pub async fn execute(&self) -> Result<()> {
        let status = self.status_checker.check_site_status().await?;
        let analysis = self.database_analyzer.analyze_current_state().await?;
        let product_urls = self.product_list_collector.collect_all_pages().await?;
        let products = self.product_detail_collector.collect_details(&product_urls).await?;
    }
}
```

**êµ¬í˜„ ê³„íš:**
- [ ] `StatusChecker` íŠ¸ë ˆì´íŠ¸ ë° êµ¬í˜„ì²´ ìƒì„±
- [ ] `DatabaseAnalyzer` íŠ¸ë ˆì´íŠ¸ ë° êµ¬í˜„ì²´ ìƒì„±
- [ ] `ProductListCollector` íŠ¸ë ˆì´íŠ¸ ë° êµ¬í˜„ì²´ ìƒì„±
- [ ] `ProductDetailCollector` íŠ¸ë ˆì´íŠ¸ ë° êµ¬í˜„ì²´ ìƒì„±
- [ ] ì˜ì¡´ì„± ì£¼ì… êµ¬ì¡°ë¡œ BatchCrawlingEngine ë¦¬íŒ©í† ë§

#### Week 3-4: ì„¸ë¶„í™”ëœ ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„
**ëª©í‘œ**: í˜„ì¬ ë‹¨ì¼ CrawlingProgressë¥¼ ìƒì„¸í•œ ì´ë²¤íŠ¸ë“¤ë¡œ ë¶„í•´

**í˜„ì¬ ì´ë²¤íŠ¸:**
```rust
pub async fn emit_progress(&self, progress: CrawlingProgress) -> EventResult
```

**ëª©í‘œ ì´ë²¤íŠ¸:**
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DetailedCrawlingEvent {
    SessionStarted { session_id: String, config: ComprehensiveCrawlerConfig },
    StageStarted { stage: String, message: String, estimated_duration: Option<u64> },
    PageProcessingStarted { page_number: u32, url: String },
    PageCompleted { page_number: u32, products_found: u32, processing_time: u64 },
    ProductProcessingStarted { product_url: String },
    ProductCompleted { product_url: String, success: bool, data_quality: f32 },
    BatchStarted { batch_number: u32, total_batches: u32, items_in_batch: u32 },
    BatchCompleted { batch_number: u32, success_count: u32, failure_count: u32 },
    ErrorOccurred { stage: String, error_type: String, message: String, recoverable: bool },
    RetryAttempt { item: String, attempt: u32, max_attempts: u32 },
    StageCompleted { stage: String, duration: u64, items_processed: u32 },
    SessionCompleted { session_id: String, total_duration: u64, final_stats: SessionStats },
}
```

**êµ¬í˜„ ê³„íš:**
- [ ] ì„¸ë¶„í™”ëœ ì´ë²¤íŠ¸ íƒ€ì… ì •ì˜
- [ ] ê° ì„œë¹„ìŠ¤ì—ì„œ í•´ë‹¹ ì´ë²¤íŠ¸ ë°©ì¶œ êµ¬í˜„
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ í™•ì¥
- [ ] ì‹¤ì‹œê°„ ì§„í–‰ë¥  ëŒ€ì‹œë³´ë“œ ê°œì„ 

### ğŸ¯ **Phase 4.2: ê³ ê¸‰ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸** (4ì£¼)

#### Week 5-6: ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ
**ëª©í‘œ**: ì¤‘ë³µ ì œê±°, ìœ íš¨ì„± ê²€ì‚¬, ì¶©ëŒ í•´ê²° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

```rust
pub struct DataProcessingPipeline {
    deduplication_service: Arc<DeduplicationService>,
    validation_service: Arc<ValidationService>,
    conflict_resolver: Arc<ConflictResolver>,
    quality_analyzer: Arc<DataQualityAnalyzer>,
}

impl DataProcessingPipeline {
    pub async fn process_batch(&self, products: Vec<MatterProduct>) -> Result<ProcessingResult> {
        // 1. ì¤‘ë³µ ì œê±° (URL, ì œí’ˆëª…, ì¸ì¦ë²ˆí˜¸ ê¸°ì¤€)
        let deduplicated = self.deduplication_service.remove_duplicates(products).await?;
        
        // 2. ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        let validated = self.validation_service.validate_all(deduplicated).await?;
        
        // 3. ê¸°ì¡´ ë°ì´í„°ì™€ ì¶©ëŒ í•´ê²°
        let resolved = self.conflict_resolver.resolve_conflicts(validated).await?;
        
        // 4. ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        let analyzed = self.quality_analyzer.analyze_quality(resolved).await?;
        
        Ok(ProcessingResult {
            processed: analyzed,
            duplicates_removed: duplicates_count,
            validation_errors: validation_errors,
            conflicts_resolved: conflicts_count,
            quality_score: overall_quality,
        })
    }
}
```

**êµ¬í˜„ ì„¸ë¶€ì‚¬í•­:**
- [ ] `DeduplicationService`: URL, ì œí’ˆëª…, ì¸ì¦ë²ˆí˜¸ ê¸°ì¤€ ì¤‘ë³µ íƒì§€ ë° ì œê±°
- [ ] `ValidationService`: í•„ìˆ˜ í•„ë“œ, ë°ì´í„° í˜•ì‹, ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
- [ ] `ConflictResolver`: ê¸°ì¡´ ë°ì´í„°ì™€ ì‹ ê·œ ë°ì´í„° ê°„ ì¶©ëŒ í•´ê²° ì „ëµ
- [ ] `DataQualityAnalyzer`: ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë° ë¦¬í¬íŠ¸ ìƒì„±

#### Week 7-8: ì§€ëŠ¥ì  ì¬ì‹œë„ ë° ë³µêµ¬ ì‹œìŠ¤í…œ
**ëª©í‘œ**: ë‹¤ì–‘í•œ ì˜¤ë¥˜ ìƒí™©ì— ëŒ€í•œ ì°¨ë³„í™”ëœ ì¬ì‹œë„ ì „ëµ

```rust
pub struct RetryManager {
    error_classifier: Arc<ErrorClassifier>,
    retry_strategies: HashMap<ErrorType, Box<dyn RetryStrategy>>,
    dead_letter_queue: Arc<DeadLetterQueue>,
    recovery_service: Arc<RecoveryService>,
}

impl RetryManager {
    pub async fn handle_failure(&self, item: FailedItem) -> Result<RetryDecision> {
        let error_type = self.error_classifier.classify(&item.error).await?;
        
        match error_type {
            ErrorType::NetworkTimeout => self.retry_with_exponential_backoff(item).await,
            ErrorType::RateLimit => self.retry_with_delay(item, Duration::from_secs(60)).await,
            ErrorType::ParsingError => self.retry_with_different_parser(item).await,
            ErrorType::ServerError => self.retry_later(item).await,
            ErrorType::Permanent => self.move_to_dead_letter_queue(item).await,
        }
    }
}
```

**êµ¬í˜„ ì„¸ë¶€ì‚¬í•­:**
- [ ] `ErrorClassifier`: ë„¤íŠ¸ì›Œí¬, íŒŒì‹±, ì„œë²„, ì˜êµ¬ ì˜¤ë¥˜ ë¶„ë¥˜
- [ ] ë‹¤ì–‘í•œ `RetryStrategy`: ì§€ìˆ˜ ë°±ì˜¤í”„, ê³ ì • ì§€ì—°, ì ì‘í˜• ì¬ì‹œë„
- [ ] `DeadLetterQueue`: ì˜êµ¬ ì‹¤íŒ¨ í•­ëª© ì €ì¥ ë° ìˆ˜ë™ ì¬ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤
- [ ] `RecoveryService`: ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ë° ìë™ ë³µêµ¬ ì „ëµ

### ğŸ¯ **Phase 4.3: ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§** (4ì£¼)

#### Week 9-10: ì ì‘í˜• ì„±ëŠ¥ ìµœì í™”
**ëª©í‘œ**: ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ì™€ ëŒ€ìƒ ì„œë²„ ìƒíƒœì— ë”°ë¥¸ ë™ì  ìµœì í™”

```rust
pub struct PerformanceOptimizer {
    system_monitor: Arc<SystemResourceMonitor>,
    target_monitor: Arc<TargetServerMonitor>,
    connection_pool: Arc<AdaptiveConnectionPool>,
    batch_optimizer: Arc<BatchSizeOptimizer>,
    concurrency_manager: Arc<ConcurrencyManager>,
}

impl PerformanceOptimizer {
    pub async fn optimize_continuously(&self) -> Result<()> {
        loop {
            let system_metrics = self.system_monitor.get_current_metrics().await?;
            let server_metrics = self.target_monitor.get_server_health().await?;
            
            // ë™ì  ìµœì í™” ê²°ì •
            if system_metrics.memory_usage > 0.8 {
                self.reduce_batch_size().await?;
            }
            
            if server_metrics.response_time > Duration::from_secs(5) {
                self.reduce_concurrency().await?;
            }
            
            if server_metrics.error_rate > 0.1 {
                self.increase_delays().await?;
            }
            
            tokio::time::sleep(Duration::from_secs(30)).await;
        }
    }
}
```

**êµ¬í˜„ ì„¸ë¶€ì‚¬í•­:**
- [ ] `SystemResourceMonitor`: CPU, ë©”ëª¨ë¦¬, ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- [ ] `TargetServerMonitor`: ëŒ€ìƒ ì„œë²„ ì‘ë‹µì‹œê°„, ì—ëŸ¬ìœ¨, ì œí•œ ìƒíƒœ ê°ì§€
- [ ] `AdaptiveConnectionPool`: ë™ì  ì—°ê²° í’€ í¬ê¸° ì¡°ì •
- [ ] `BatchSizeOptimizer`: ì„±ëŠ¥ ê¸°ë°˜ ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •
- [ ] `ConcurrencyManager`: ì ì‘í˜• ë™ì‹œì„± ë ˆë²¨ ê´€ë¦¬

#### Week 11-12: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ
**ëª©í‘œ**: í¬ê´„ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì•ŒëŒ ì‹œìŠ¤í…œ

```rust
pub struct MonitoringDashboard {
    metrics_collector: Arc<MetricsCollector>,
    alert_manager: Arc<AlertManager>,
    performance_analyzer: Arc<PerformanceAnalyzer>,
    report_generator: Arc<ReportGenerator>,
}

impl MonitoringDashboard {
    pub async fn start_monitoring(&self) -> Result<()> {
        // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        let metrics_stream = self.metrics_collector.start_collection().await?;
        
        // ì„±ëŠ¥ ë¶„ì„ ë° ì•ŒëŒ
        tokio::spawn(async move {
            while let Some(metrics) = metrics_stream.next().await {
                self.performance_analyzer.analyze(metrics).await?;
                self.alert_manager.check_thresholds(metrics).await?;
            }
        });
        
        // ì£¼ê¸°ì  ë¦¬í¬íŠ¸ ìƒì„±
        self.schedule_reports().await?;
        
        Ok(())
    }
}
```

**ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ:**
- [ ] **í¬ë¡¤ë§ ì„±ëŠ¥**: ì²˜ë¦¬ìœ¨, ì„±ê³µë¥ , ì‘ë‹µì‹œê°„, ì—ëŸ¬ìœ¨
- [ ] **ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤**: CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰
- [ ] **ë°ì´í„° í’ˆì§ˆ**: ì¤‘ë³µë¥ , ìœ íš¨ì„± ê²€ì¦ í†µê³¼ìœ¨, ì™„ì„±ë„
- [ ] **ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­**: ì‹ ê·œ ì œí’ˆ ë°œê²¬ìœ¨, ì—…ë°ì´íŠ¸ëœ ì •ë³´ëŸ‰

---

## ğŸš€ **Phase 5: í”„ë¡œë•ì…˜ ì¤€ë¹„ ë° ë°°í¬** (4ì£¼)

### Week 13-14: í†µí•© í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- [ ] ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ëŒ€í•œ End-to-End í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ìµœì í™” ê²€ì¦
- [ ] ì¥ì•  ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- [ ] ì‚¬ìš©ì ìˆ˜ìš© í…ŒìŠ¤íŠ¸

### Week 15-16: ë°°í¬ ì¤€ë¹„ ë° ë¬¸ì„œí™”
- [ ] í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì •
- [ ] ì‚¬ìš©ì ë§¤ë‰´ì–¼ ë° ê´€ë¦¬ì ê°€ì´ë“œ ì‘ì„±
- [ ] ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ ì„¤ì •
- [ ] ë°±ì—… ë° ë³µêµ¬ ì „ëµ ìˆ˜ë¦½

---

## ğŸ“Š **ì„±ê³µ ê¸°ì¤€ ë° KPI**

### **ê¸°ëŠ¥ì  ì™„ì„±ë„**
- [x] ê¸°ë³¸ í¬ë¡¤ë§ (100%)
- [x] ì‹¤ì‹œê°„ UI (100%) 
- [x] ì„¤ì • ê´€ë¦¬ (100%)
- [ ] ê³ ê¸‰ ë°ì´í„° ì²˜ë¦¬ (ëª©í‘œ: 90%)
- [ ] ì„±ëŠ¥ ìµœì í™” (ëª©í‘œ: 90%)

### **ì„±ëŠ¥ ëª©í‘œ**
- [ ] **ì²˜ë¦¬ ì†ë„**: 1000+ í˜ì´ì§€/ì‹œê°„
- [ ] **ì•ˆì •ì„±**: 99.5% ì—…íƒ€ì„
- [ ] **ë°ì´í„° í’ˆì§ˆ**: 95% ì •í™•ë„
- [ ] **ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ < 500MB

### **ê¸°ìˆ ì  í’ˆì§ˆ**
- [x] íƒ€ì… ì•ˆì „ì„± (100%)
- [x] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (90%)
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ (ëª©í‘œ: 90%)
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ëª©í‘œ: 90%)
- [ ] ë¬¸ì„œí™” (ëª©í‘œ: 95%)

---

## ğŸ¯ **ë‹¤ìŒ ë§ˆì¼ìŠ¤í†¤**

**ğŸ“… 2025ë…„ 7ì›” 15ì¼**: BatchCrawlingEngine ì„œë¹„ìŠ¤ ë¶„ë¦¬ ì™„ë£Œ  
**ğŸ“… 2025ë…„ 7ì›” 30ì¼**: ì„¸ë¶„í™”ëœ ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ì™„ë£Œ  
**ğŸ“… 2025ë…„ 8ì›” 15ì¼**: ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ  
**ğŸ“… 2025ë…„ 8ì›” 30ì¼**: ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì™„ë£Œ  
**ğŸ“… 2025ë…„ 9ì›” 15ì¼**: í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ  

---

**í˜„ì¬ ìš°ì„ ìˆœìœ„: BatchCrawlingEngine ì„œë¹„ìŠ¤ ë¶„ë¦¬ ì‘ì—… ì¦‰ì‹œ ì‹œì‘**
