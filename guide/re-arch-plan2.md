# rMatterCertis ìµœì¢… ì•„í‚¤í…ì²˜ ì¬êµ¬ì¶• ì‹¤í–‰ ê³„íš v2

*ë³¸ ë¬¸ì„œëŠ” `re-arch-plan.md`ì˜ êµ¬ì²´ì  êµ¬í˜„ ê³„íšê³¼ `re-arch-plan-improved.md`ì˜ êµ¬ì¡°ì  ê°œì„ ì‚¬í•­ì„ í†µí•©í•˜ì—¬, **ë„ë©”ì¸ ì§€ì‹, ì²´ê³„ì ì¸ ì—­í•  ë¶„ë‹´, UI ìƒí˜¸ì‘ìš©**ì„ ì™„ë²½í•˜ê²Œ ê²°í•©í•œ ìµœì¢… ì‹¤í–‰ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.*

## 1. í†µí•© ì•„í‚¤í…ì²˜ ì² í•™: ì™œ ì´ ì„¤ê³„ê°€ ìµœì ì¸ê°€?

### 1.1 í•µì‹¬ ì„¤ê³„ ì›ì¹™ (re-arch-plan-improved ê¸°ë°˜)

1. **ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬**: ê° ì»´í¬ë„ŒíŠ¸ì˜ ì—­í• ê³¼ ì±…ì„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì •ì˜
2. **ë„ë©”ì¸ ì§€ì‹ ì¤‘ì‹¬í™”**: CrawlingPlannerê°€ ëª¨ë“  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì§‘ì•½
3. **UI ìƒí˜¸ì‘ìš© ìš°ì„ **: ì‹¤ì‹œê°„ í”¼ë“œë°±ê³¼ ì‚¬ìš©ì ì œì–´ë¥¼ ì•„í‚¤í…ì²˜ í•µì‹¬ìœ¼ë¡œ ì„¤ê³„
4. **ì ì§„ì  êµì²´ ì „ëµ**: ê¸°ì¡´ ì‹œìŠ¤í…œ ì˜í–¥ ìµœì†Œí™”í•˜ë©° ë‹¨ê³„ë³„ ì „í™˜

### 1.2 í†µí•© ì „ëµ: ì™„ì „í•œ ì¬ì‘ì„± (Clean Slate)

**âŒ ì ì§„ì  êµì²´ ë°©ì‹ì˜ ë¬¸ì œì **:
- ì¤‘ê°„ì— ë²„ë ¤ì§€ëŠ” ì½”ë“œ ì–‘ì‚° (ì–´ëŒ‘í„°, í˜¸í™˜ì„± ë ˆì´ì–´ ë“±)
- í˜¼ë€ ê°€ì¤‘ (ë‘ ì‹œìŠ¤í…œ ê³µì¡´ìœ¼ë¡œ ì¸í•œ ë³µì¡ì„±)
- ë¶ˆì™„ì „í•œ ìƒˆ ì•„í‚¤í…ì²˜ (ê¸°ì¡´ ì‹œìŠ¤í…œ ì œì•½ ë•Œë¬¸)

**âœ… ì™„ì „í•œ ì¬ì‘ì„± ì ‘ê·¼ë²•**:

```mermaid
graph LR
    subgraph "ê¸°ì¡´ ì‹œìŠ¤í…œ (ì™„ì „ ìœ ì§€)"
        A1[CrawlingOrchestrator]
        A2[WorkerPool]
        A3[ê¸°ì¡´ UI]
    end
    
    subgraph "ìƒˆ ì•„í‚¤í…ì²˜ (ì™„ì „ ë…ë¦½)"
        B1["CrawlingFacade<br/>(ëª…í™•í•œ API)"]
        B2["SessionOrchestrator<br/>(ì›Œí¬í”Œë¡œ ì§€íœ˜)"]
        B3["CrawlingPlanner<br/>(ë„ë©”ì¸ ì§€ì‹ ì§‘ì•½)"]
        B4["SharedSessionState<br/>(ìƒíƒœ ê´€ë¦¬)"]
        B5["EventHub<br/>(ì‹¤ì‹œê°„ í”¼ë“œë°±)"]
    end
    
    subgraph "ì „í™˜ ì „ëµ"
        C1[ìƒˆ ì‹œìŠ¤í…œ ì™„ì „ êµ¬ì¶•]
        C2[ê¸°ëŠ¥ ê²€ì¦ ì™„ë£Œ]
        C3[ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í†µê³¼]
        C4[í•œ ë²ˆì— ì™„ì „ êµì²´]
        C5[ê¸°ì¡´ ì‹œìŠ¤í…œ ì œê±°]
    end
    
    A1 -.-> A1
    A2 -.-> A2
    A3 -.-> A3
    
    B1 --> C1
    B2 --> C1
    B3 --> C1
    B4 --> C1
    B5 --> C1
    
    C1 --> C2
    C2 --> C3
    C3 --> C4
    C4 --> C5
    
    style B1 fill:#e3f2fd
    style B3 fill:#fff3e0
    style B4 fill:#fce4ec
    style C4 fill:#c8e6c9
    style C5 fill:#ffcdd2
```

## 2. ìµœì¢… ì•„í‚¤í…ì²˜ ì„¤ê³„: êµ¬ì¡°ì  ê°œì„  + êµ¬ì²´ì  êµ¬í˜„

### 2.1 ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    subgraph "UI / User Interaction Layer"
        UI[CrawlingDashboard UI<br/>ì‹¤ì‹œê°„ ìƒíƒœ ì¶”ì ]
        CMD[User Commands<br/>'Start, Stop, Continue, Cancel']
    end

    subgraph "Application Facade Layer"
        CF["<b>CrawlingFacade</b><br/>UIì™€ ì‹œìŠ¤í…œ ê°„ ìœ ì¼í•œ í†µë¡œ<br/>- ëª…ë ¹ ìˆ˜ì‹ /ì²˜ë¦¬<br/>- ì´ë²¤íŠ¸ êµ¬ë…/ì „ë‹¬"]
    end

    subgraph "Orchestration Layer"
        SO["<b>SessionOrchestrator</b><br/>ì›Œí¬í”Œë¡œ ì´ê´„ ì§€íœ˜ì<br/>- ë¶„ì„ â†’ ê³„íš â†’ ì‹¤í–‰<br/>- ë‹¨ê³„ë³„ ì´ë²¤íŠ¸ ë°œí–‰"]
        SS["<b>SharedSessionState</b><br/>ìƒíƒœ ì „íŒŒ ë° ì œì–´<br/>- Arc<Mutex<State>><br/>- cancellation_token<br/>- pause_signal"]
    end

    subgraph "Domain Logic Layer (The Brain)"
        CP["<b>CrawlingPlanner</b><br/>ëª¨ë“  ë„ë©”ì¸ ì§€ì‹ ì§‘ì•½<br/>- ë²”ìœ„ ê³„ì‚° ë¡œì§<br/>- ì „ëµ ìˆ˜ë¦½ ë¡œì§<br/>- ë°°ì¹˜ ì„¤ì • ìµœì í™”"]
        PCA[PreCrawlingAnalyzer<br/>ë°ì´í„° ìˆ˜ì§‘ ì¡°ì •ì]
    end

    subgraph "Data Gathering Layer"
        SSC[SiteStatusChecker<br/>í†µí•© ì‚¬ì´íŠ¸ ë¶„ì„]
        DBA[DatabaseAnalyzer<br/>DB ìƒíƒœ ë¶„ì„]
        AC[AnalysisCache<br/>ë¶„ì„ ê²°ê³¼ ìºì‹±]
    end
    
    subgraph "Execution Layer"
        BM[BatchManager<br/>ë°°ì¹˜ ì²˜ë¦¬ ì´ê´„<br/>- ì ì‘ì  ë°°ì¹˜ ì„¤ì •<br/>- ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§]
        SR[StageRunner Trait<br/>ë‹¨ê³„ë³„ ì‹¤í–‰]
        AT[AsyncTask Trait<br/>ê°œë³„ ì‘ì—…]
        MM[MemoryMonitor<br/>ë¦¬ì†ŒìŠ¤ ê´€ë¦¬]
    end

    subgraph "Event System"
        EH[EventHub<br/>í†µí•© ì´ë²¤íŠ¸ í—ˆë¸Œ]
        SE[SessionEvent]
        AE[AnalysisEvent]
        PE[PlanningEvent]
        BE[BatchEvent]
    end

    subgraph "Configuration & State"
        SC[SessionConfig<br/>ë¶ˆë³€ ì„¸ì…˜ ì„¤ì •]
        ACX[AppContext<br/>ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸]
        CONST[Constants<br/>í•˜ë“œì½”ë”© ë°©ì§€]
    end

    UI <--> CF
    CMD --> CF
    CF --> SO
    CF --> SS
    CF <--> EH

    SO --> PCA
    SO --> CP
    SO --> BM
    SO --> SS
    SO --> EH

    PCA --> SSC
    PCA --> DBA
    PCA --> AC

    CP --> SC
    SC --> ACX

    BM --> SR
    BM --> MM
    SR --> AT
    AT --> SS

    EH --> SE
    EH --> AE
    EH --> PE
    EH --> BE

    style CF fill:#e3f2fd,stroke:#333,stroke-width:2px
    style CP fill:#fff3e0,stroke:#333,stroke-width:2px
    style SS fill:#fce4ec,stroke:#333,stroke-width:2px
    style EH fill:#e8f5e8,stroke:#333,stroke-width:2px
```

### 2.2 Modern Rust 2024 ê¸°ë°˜ í•µì‹¬ íŠ¸ë ˆì´íŠ¸ ì•„í‚¤í…ì²˜

```mermaid
classDiagram
    class CrawlingFacade {
        +event_hub: Arc~EventHub~
        +active_sessions: Arc~Mutex~HashMap~String, SessionHandle~~~
        +new() Result~Self~
        +start_full_crawl(config: UserConfig) Future~WorkflowResult~
        +start_incremental_crawl(config: UserConfig) Future~WorkflowResult~
        +start_recovery_crawl(config: UserConfig) Future~WorkflowResult~
        +pause_session(session_id: String) Result~()~
        +resume_session(session_id: String) Result~()~
        +cancel_session(session_id: String) Result~()~
        +subscribe_to_events() EventReceiver
    }

    class SessionOrchestrator {
        +session_id: String
        +event_hub: Arc~EventHub~
        +shared_state: Arc~SharedSessionState~
        +new(event_hub, state) Self
        +run_workflow(config: UserConfig) Future~WorkflowResult~
        +pause_workflow() Result~()~
        +resume_workflow() Result~()~
        +cancel_workflow() Result~()~
        -emit_stage_changed(from, to) Future~()~
        -emit_session_started(id) Future~()~
    }

    class CrawlingPlanner {
        +event_hub: Arc~EventHub~
        +new(event_hub) Self
        +create_comprehensive_plan(intent, site_status, db_report) Future~CrawlingPlan~
        -determine_optimal_batch_config(strategy, site_status, db_report, total_pages) BatchConfig
        -estimate_items(start, end, status) u32
        -emit_planning_progress(stage, progress) Future~()~
    }

    class SharedSessionState {
        +session_id: String
        +cancellation_token: AtomicBool
        +pause_signal: AtomicBool
        +current_stage: Arc~Mutex~WorkflowStage~~
        +status_message: Arc~Mutex~String~~
        +progress_info: Arc~Mutex~ProgressInfo~~
        +new(session_id) Self
        +is_cancellation_requested() bool
        +is_pause_requested() bool
        +update_progress(info: ProgressInfo) Result~()~
        +set_status_message(msg: String) Result~()~
    }

    class AsyncTask {
        <<trait>>
        +id() &str
        +name() &str
        +estimated_duration() Duration
        +priority() u8
        +validate(context: &AppContext) Future~Result~()~~
        +execute(context: &AppContext, events: &EventHub) Future~TaskResult~
        +cleanup(context: &AppContext) Future~Result~()~~
        +cancel() Future~Result~()~~
    }
    
    class BatchableTask {
        <<trait>>
        +BatchItem: Associated Type
        +split_into_batches(items: Vec~Self::BatchItem~, size: u32) Vec~Vec~Self::BatchItem~~
        +process_item(item: Self::BatchItem, context: &AppContext, events: &EventHub) Future~Result~()~~
        +process_item_impl(item: Self::BatchItem, context: &AppContext) Future~Result~()~~
    }
    
    class StageRunner {
        <<trait>>
        +Task: Associated Type
        +stage_name() &'static str
        +required_tasks() Vec~Box~dyn AsyncTask~~
        +validate_stage(context: &AppContext) Future~Result~()~~
        +run_stage(context: &AppContext, events: &EventHub, state: &SharedSessionState) Future~StageResult~
        +cleanup_stage(context: &AppContext) Future~Result~()~~
    }

    class EventEmitter {
        <<trait>>
        +emit_event(event: AppEvent) Future~Result~()~~
    }

    CrawlingFacade --> SessionOrchestrator
    SessionOrchestrator --> CrawlingPlanner
    SessionOrchestrator --> SharedSessionState
    CrawlingPlanner ..|> EventEmitter
    SessionOrchestrator ..|> EventEmitter
    AsyncTask <|-- BatchableTask
    
    note for CrawlingFacade "UIì™€ ì‹œìŠ¤í…œ ê°„ ìœ ì¼í•œ ì§„ì…ì "
    note for CrawlingPlanner "ëª¨ë“  ë„ë©”ì¸ ì§€ì‹ ì§‘ì•½"
    note for SharedSessionState "ìƒíƒœ ì „íŒŒ ë° ì œì–´"
```

## 3. í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ì„¤ê³„

### 3.1 CrawlingFacade: ëª…í™•í•œ ì‹œìŠ¤í…œ API

```rust
// src-tauri/src/new_architecture/facade.rs
//! UIì™€ ì‹œìŠ¤í…œ ê°„ ìœ ì¼í•œ í†µë¡œ (re-arch-plan-improved ì„¤ê³„ ì ìš©)

use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use uuid::Uuid;

/// í¬ë¡¤ë§ ì‹œìŠ¤í…œì˜ ìœ ì¼í•œ ì§„ì…ì 
/// 
/// **ì±…ì„**:
/// - UI ëª…ë ¹ ìˆ˜ì‹  ë° ì²˜ë¦¬
/// - ì„¸ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬  
/// - ì´ë²¤íŠ¸ êµ¬ë… ë° ì „ë‹¬
#[derive(Debug)]
pub struct CrawlingFacade {
    event_hub: Arc<EventHub>,
    active_sessions: Arc<Mutex<HashMap<String, SessionHandle>>>,
}

impl CrawlingFacade {
    /// ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ Facade ìƒì„±
    pub fn new() -> crate::Result<Self> {
        let event_hub = Arc::new(EventHub::new());
        let active_sessions = Arc::new(Mutex::new(HashMap::new()));
        
        Ok(Self {
            event_hub,
            active_sessions,
        })
    }
    
    /// ì „ì²´ í¬ë¡¤ë§ ì›Œí¬í”Œë¡œ ì‹œì‘
    /// 
    /// **ë°ì´í„° íë¦„** (re-arch-plan-improved ê¸°ë°˜):
    /// 1. ì‚¬ìš©ì ì„¤ì • ê²€ì¦
    /// 2. SessionOrchestrator ìƒì„± ë° ì‹¤í–‰
    /// 3. ë¶„ì„ â†’ ê³„íš â†’ ì‹¤í–‰ ë‹¨ê³„ë³„ ì§„í–‰
    pub async fn start_full_crawl(
        &self, 
        user_config: UserConfig
    ) -> crate::Result<String> {
        user_config.validate()?;
        
        let session_id = Uuid::new_v4().to_string();
        let shared_state = Arc::new(SharedSessionState::new(session_id.clone()));
        
        let orchestrator = SessionOrchestrator::new(
            session_id.clone(),
            self.event_hub.clone(),
            shared_state.clone(),
        );
        
        // ì„¸ì…˜ ë“±ë¡
        {
            let mut sessions = self.active_sessions.lock().unwrap();
            sessions.insert(session_id.clone(), SessionHandle {
                state: shared_state,
                join_handle: None, // tokio::spawn í›„ ì„¤ì •
            });
        }
        
        // ë¹„ë™ê¸° ì‹¤í–‰
        let sessions_clone = self.active_sessions.clone();
        let session_id_clone = session_id.clone();
        
        let join_handle = tokio::spawn(async move {
            let result = orchestrator.run_workflow(user_config).await;
            
            // ì„¸ì…˜ ì •ë¦¬
            {
                let mut sessions = sessions_clone.lock().unwrap();
                sessions.remove(&session_id_clone);
            }
            
            result
        });
        
        // JoinHandle ì—…ë°ì´íŠ¸
        {
            let mut sessions = self.active_sessions.lock().unwrap();
            if let Some(handle) = sessions.get_mut(&session_id) {
                handle.join_handle = Some(join_handle);
            }
        }
        
        Ok(session_id)
    }
    
    /// ì„¸ì…˜ ì¼ì‹œì •ì§€
    pub async fn pause_session(&self, session_id: &str) -> crate::Result<()> {
        let sessions = self.active_sessions.lock().unwrap();
        if let Some(handle) = sessions.get(session_id) {
            handle.state.pause_signal.store(true, std::sync::atomic::Ordering::Relaxed);
            
            // ì¼ì‹œì •ì§€ ì´ë²¤íŠ¸ ë°œí–‰
            self.event_hub.emit_event(AppEvent::Session(SessionEvent::Paused {
                session_id: session_id.to_string(),
                timestamp: std::time::SystemTime::now(),
            })).await?;
        }
        
        Ok(())
    }
    
    /// ì„¸ì…˜ ì·¨ì†Œ
    pub async fn cancel_session(&self, session_id: &str) -> crate::Result<()> {
        let sessions = self.active_sessions.lock().unwrap();
        if let Some(handle) = sessions.get(session_id) {
            handle.state.cancellation_token.store(true, std::sync::atomic::Ordering::Relaxed);
            
            // ì·¨ì†Œ ì´ë²¤íŠ¸ ë°œí–‰
            self.event_hub.emit_event(AppEvent::Session(SessionEvent::Cancelled {
                session_id: session_id.to_string(),
                reason: "User requested cancellation".to_string(),
                timestamp: std::time::SystemTime::now(),
            })).await?;
        }
        
        Ok(())
    }
    
    /// ì´ë²¤íŠ¸ ìˆ˜ì‹ ê¸° ì œê³µ (UI ì—…ë°ì´íŠ¸ìš©)
    pub fn subscribe_to_events(&self) -> EventReceiver {
        self.event_hub.subscribe()
    }
}

/// ì„¸ì…˜ í•¸ë“¤ êµ¬ì¡°ì²´
#[derive(Debug)]
struct SessionHandle {
    state: Arc<SharedSessionState>,
    join_handle: Option<tokio::task::JoinHandle<crate::Result<WorkflowResult>>>,
}
```

### 3.2 SessionOrchestrator: ì›Œí¬í”Œë¡œ ì§€íœ˜ì

```rust
// src-tauri/src/new_architecture/orchestrator.rs
//! í¬ë¡¤ë§ ì„¸ì…˜ì˜ ì „ì²´ ì›Œí¬í”Œë¡œ ì§€íœ˜ì

use std::sync::Arc;
use std::time::Instant;

/// ë‹¨ì¼ í¬ë¡¤ë§ ì„¸ì…˜ì˜ ì›Œí¬í”Œë¡œ ì´ê´„ ê´€ë¦¬ì
/// 
/// **í•µì‹¬ ì±…ì„**:
/// - ë¶„ì„ â†’ ê³„íš â†’ ì‹¤í–‰ ë‹¨ê³„ ìˆœì°¨ ì§„í–‰
/// - ê° ë‹¨ê³„ë³„ ì´ë²¤íŠ¸ ë°œí–‰
/// - ìƒíƒœ ë³€í™” ê°ì§€ ë° ëŒ€ì‘
pub struct SessionOrchestrator {
    session_id: String,
    event_hub: Arc<EventHub>,
    shared_state: Arc<SharedSessionState>,
}

impl SessionOrchestrator {
    pub fn new(
        session_id: String,
        event_hub: Arc<EventHub>,
        shared_state: Arc<SharedSessionState>,
    ) -> Self {
        Self {
            session_id,
            event_hub,
            shared_state,
        }
    }
    
    /// ì „ì²´ ì›Œí¬í”Œë¡œ ì‹¤í–‰ (re-arch-plan-improved ê¸°ë°˜ 3ë‹¨ê³„)
    /// 
    /// **ë‹¨ê³„ë³„ ì§„í–‰**:
    /// 1. ë¶„ì„ ë‹¨ê³„: SiteStatus + DBReport ìˆ˜ì§‘
    /// 2. ê³„íš ë‹¨ê³„: CrawlingPlannerë¡œ ë„ë©”ì¸ ì§€ì‹ í™œìš©
    /// 3. ì‹¤í–‰ ë‹¨ê³„: SessionConfig ê¸°ë°˜ ì¼ê´€ëœ ì‹¤í–‰
    pub async fn run_workflow(
        &self,
        user_config: UserConfig
    ) -> crate::Result<WorkflowResult> {
        let start_time = Instant::now();
        
        // ğŸ¯ ì„¸ì…˜ ì‹œì‘ ì´ë²¤íŠ¸ ë°œí–‰
        self.emit_event(AppEvent::Session(SessionEvent::Started {
            session_id: self.session_id.clone(),
            config: user_config.clone(),
            timestamp: std::time::SystemTime::now(),
        })).await?;
        
        // ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
        if self.shared_state.is_cancellation_requested() {
            return Ok(WorkflowResult::cancelled("Session cancelled before start"));
        }
        
        // 1ë‹¨ê³„: ë¶„ì„ ë‹¨ê³„
        self.emit_stage_changed(None, WorkflowStage::Analyzing).await?;
        let analysis_result = self.run_analysis_stage().await?;
        
        if self.shared_state.is_cancellation_requested() {
            return Ok(WorkflowResult::cancelled("Session cancelled during analysis"));
        }
        
        // 2ë‹¨ê³„: ê³„íš ë‹¨ê³„
        self.emit_stage_changed(WorkflowStage::Analyzing, WorkflowStage::Planning).await?;
        let crawling_plan = self.run_planning_stage(&user_config, &analysis_result).await?;
        
        // ì‘ì—…ì´ í•„ìš” ì—†ëŠ” ê²½ìš° ì¡°ê¸° ì¢…ë£Œ
        if !crawling_plan.needs_crawling() {
            let result = WorkflowResult::no_action_taken(
                "No crawling needed based on current analysis"
            );
            
            self.emit_event(AppEvent::Session(SessionEvent::Completed {
                session_id: self.session_id.clone(),
                result: result.clone(),
                total_duration: start_time.elapsed(),
            })).await?;
            
            return Ok(result);
        }
        
        if self.shared_state.is_cancellation_requested() {
            return Ok(WorkflowResult::cancelled("Session cancelled during planning"));
        }
        
        // 3ë‹¨ê³„: ì‹¤í–‰ ë‹¨ê³„
        self.emit_stage_changed(WorkflowStage::Planning, WorkflowStage::Executing).await?;
        let execution_result = self.run_execution_stage(&user_config, &crawling_plan).await?;
        
        // ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
        self.emit_event(AppEvent::Session(SessionEvent::Completed {
            session_id: self.session_id.clone(),
            result: execution_result.clone(),
            total_duration: start_time.elapsed(),
        })).await?;
        
        Ok(execution_result)
    }
    
    /// ë¶„ì„ ë‹¨ê³„ ì‹¤í–‰
    async fn run_analysis_stage(&self) -> crate::Result<AnalysisResult> {
        let analyzer = PreCrawlingAnalyzer::new(self.event_hub.clone());
        analyzer.analyze_all().await
    }
    
    /// ê³„íš ë‹¨ê³„ ì‹¤í–‰ (ë„ë©”ì¸ ì§€ì‹ ì¤‘ì‹¬)
    async fn run_planning_stage(
        &self,
        user_config: &UserConfig,
        analysis_result: &AnalysisResult
    ) -> crate::Result<CrawlingPlan> {
        let planner = CrawlingPlanner::new(self.event_hub.clone());
        planner.create_comprehensive_plan(
            user_config.crawling.crawl_type.clone(),
            &analysis_result.site_status,
            &analysis_result.db_report,
        ).await
    }
    
    /// ì‹¤í–‰ ë‹¨ê³„ ì‹¤í–‰ (ë¶ˆë³€ SessionConfig ê¸°ë°˜)
    async fn run_execution_stage(
        &self,
        user_config: &UserConfig,
        crawling_plan: &CrawlingPlan
    ) -> crate::Result<WorkflowResult> {
        // ë¶ˆë³€ SessionConfig ìƒì„±
        let session_config = SessionConfig::new(
            user_config.clone(),
            crawling_plan.clone(),
        );
        
        // AppContext ìƒì„± (ëª¨ë“  í•˜ìœ„ ì‘ì—…ì— ì „íŒŒ)
        let app_context = AppContext::new(
            self.session_id.clone(),
            Arc::new(session_config),
        );
        
        // Planning ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ BatchManager ìƒì„±
        let batch_config = crawling_plan.batch_config.clone();
        let batch_manager = BatchManager::new(batch_config);
        
        // ì‹¤ì œ í¬ë¡¤ë§ ì‹¤í–‰
        match crawling_plan.strategy {
            CrawlingStrategy::Full | CrawlingStrategy::Incremental => {
                batch_manager.execute_list_collection_workflow(
                    &crawling_plan.target_pages,
                    &app_context,
                    &self.event_hub,
                    &self.shared_state,
                ).await
            }
            CrawlingStrategy::Recovery => {
                batch_manager.execute_recovery_workflow(
                    &crawling_plan.target_pages,
                    &app_context,
                    &self.event_hub,
                    &self.shared_state,
                ).await
            }
            CrawlingStrategy::NoAction => {
                Ok(WorkflowResult::no_action_taken("No action required"))
            }
        }
    }
    
    /// ë‹¨ê³„ ë³€ê²½ ì´ë²¤íŠ¸ ë°œí–‰
    async fn emit_stage_changed(
        &self,
        from: impl Into<Option<WorkflowStage>>,
        to: WorkflowStage
    ) -> crate::Result<()> {
        self.shared_state.current_stage.lock().unwrap().clone_from(&to);
        
        self.emit_event(AppEvent::Session(SessionEvent::StageChanged {
            session_id: self.session_id.clone(),
            from_stage: from.into(),
            to_stage: to,
            timestamp: std::time::SystemTime::now(),
        })).await
    }
}

impl EventEmitter for SessionOrchestrator {
    async fn emit_event(&self, event: AppEvent) -> crate::Result<()> {
        self.event_hub.emit_event(event).await
    }
}
```

### 3.3 CrawlingPlanner: ë„ë©”ì¸ ì§€ì‹ ì§‘ì•½ì²´

```rust
// src-tauri/src/new_architecture/domain/planner.rs
//! í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½ ë„ë©”ì¸ ì„œë¹„ìŠ¤ (ëª¨ë“  ë„ë©”ì¸ ì§€ì‹ ì§‘ì•½)

use std::sync::Arc;
use std::time::Duration;

/// í¬ë¡¤ë§ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ë„ë©”ì¸ ì„œë¹„ìŠ¤
/// 
/// **í•µì‹¬ ì±…ì„**: 
/// - 3ê°€ì§€ ì •ë³´ ì¢…í•© (ì‚¬ìš©ì ì˜ë„ + ì‚¬ì´íŠ¸ ìƒíƒœ + DB ìƒíƒœ)
/// - ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ì „ëµ ê²°ì •
/// - ì ì‘ì  ë°°ì¹˜ ì„¤ì • ìµœì í™”
pub struct CrawlingPlanner {
    event_hub: Arc<EventHub>,
}

impl CrawlingPlanner {
    pub fn new(event_hub: Arc<EventHub>) -> Self {
        Self { event_hub }
    }
    
    /// ğŸ¯ 3ê°€ì§€ ì£¼ìš” ì •ë³´ë¥¼ ì¢…í•©í•œ í¬ê´„ì  í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½
    /// 
    /// **ì¢…í•© íŒë‹¨ ìš”ì†Œ**:
    /// 1. ì‚¬ìš©ì ì˜ë„ (CrawlType): ì „ì²´/ì¦ë¶„/ë³µêµ¬
    /// 2. ì‚¬ì´íŠ¸ ìƒíƒœ (SiteStatus): ì´ í˜ì´ì§€ ìˆ˜, ì‘ë‹µ ì†ë„, ë¶€í•˜ ìƒíƒœ
    /// 3. DB ìƒíƒœ (DBStateReport): ê¸°ì¡´ ë°ì´í„°, ëˆ„ë½ í˜ì´ì§€, ì˜¤ë¥˜ íŒ¨í„´
    pub async fn create_comprehensive_plan(
        &self,
        user_intent: CrawlType,
        site_status: &SiteStatus,
        db_report: &DBStateReport,
    ) -> crate::Result<CrawlingPlan> {
        
        // ê³„íš ìˆ˜ë¦½ ì‹œì‘ ì´ë²¤íŠ¸
        self.emit_event(AppEvent::Planning(PlanningEvent::Started {
            user_intent: user_intent.clone(),
            timestamp: std::time::SystemTime::now(),
        })).await?;
        
        if !site_status.is_accessible {
            return Err(PlanningError::SiteNotAccessible.into());
        }

        let (start_page, end_page, strategy) = match user_intent {
            CrawlType::Full => {
                // ë„ë©”ì¸ ì§€ì‹ 1: ì „ì²´ í¬ë¡¤ë§
                self.emit_planning_progress("ì „ì²´ í¬ë¡¤ë§ ë²”ìœ„ ê³„ì‚° ì¤‘", 25).await?;
                (1, site_status.total_pages, CrawlingStrategy::Full)
            }
            CrawlType::Incremental => {
                // ë„ë©”ì¸ ì§€ì‹ 2: ì¦ë¶„ í¬ë¡¤ë§
                self.emit_planning_progress("ì¦ë¶„ í¬ë¡¤ë§ ë²”ìœ„ ê³„ì‚° ì¤‘", 25).await?;
                let last_crawled = db_report.last_crawled_page.unwrap_or(0);
                if last_crawled >= site_status.total_pages {
                    return Ok(CrawlingPlan::no_action_needed());
                }
                (last_crawled + 1, site_status.total_pages, CrawlingStrategy::Incremental)
            }
            CrawlType::Recovery => {
                // ë„ë©”ì¸ ì§€ì‹ 3: ë³µêµ¬ í¬ë¡¤ë§
                self.emit_planning_progress("ë³µêµ¬ ëŒ€ìƒ í˜ì´ì§€ ë¶„ì„ ì¤‘", 25).await?;
                return Ok(CrawlingPlan::for_recovery(
                    db_report.missing_pages.clone(),
                    site_status,
                    db_report
                ));
            }
        };

        if start_page > end_page {
            return Ok(CrawlingPlan::no_action_needed());
        }

        // ğŸ¯ 3ê°€ì§€ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì  BatchConfig ê²°ì •
        self.emit_planning_progress("ìµœì  ë°°ì¹˜ ì„¤ì • ê³„ì‚° ì¤‘", 75).await?;
        let batch_config = self.determine_optimal_batch_config(
            &strategy,
            site_status,
            db_report,
            end_page - start_page + 1,
        );

        let plan = CrawlingPlan {
            target_pages: (start_page..=end_page).collect(),
            strategy,
            estimated_items: self.estimate_items(start_page, end_page, site_status),
            priority: PlanPriority::Normal,
            batch_config,
        };

        // ê³„íš ì™„ë£Œ ì´ë²¤íŠ¸
        self.emit_event(AppEvent::Planning(PlanningEvent::Completed {
            plan: plan.clone(),
            timestamp: std::time::SystemTime::now(),
        })).await?;

        Ok(plan)
    }

    /// ğŸ§  ë„ë©”ì¸ ì§€ì‹ ì¤‘ì‹¬: 3ê°€ì§€ ì •ë³´ ì¢…í•©ìœ¼ë¡œ ìµœì  ë°°ì¹˜ ì„¤ì • ê²°ì •
    fn determine_optimal_batch_config(
        &self,
        strategy: &CrawlingStrategy,
        site_status: &SiteStatus,
        db_report: &DBStateReport,
        total_pages: u32,
    ) -> BatchConfig {
        // 1ï¸âƒ£ ì‚¬ì´íŠ¸ ìƒíƒœ ê¸°ë°˜ ê¸°ë³¸ ë°°ì¹˜ í¬ê¸° ê²°ì •
        let base_batch_size = match site_status.average_response_time_ms {
            0..=500 => 50,      // ë¹ ë¥¸ ì‘ë‹µ: í° ë°°ì¹˜
            501..=2000 => 20,   // ë³´í†µ ì‘ë‹µ: ì¤‘ê°„ ë°°ì¹˜  
            _ => 10,            // ëŠë¦° ì‘ë‹µ: ì‘ì€ ë°°ì¹˜
        };

        // 2ï¸âƒ£ DB ì˜¤ë¥˜ íŒ¨í„´ ê¸°ë°˜ ì¬ì‹œë„ ì •ì±… ê²°ì •
        let error_rate = db_report.recent_error_count as f32 / db_report.total_attempts.max(1) as f32;
        let max_retries = match error_rate {
            0.0..=0.05 => 3,      // ë‚®ì€ ì˜¤ë¥˜ìœ¨: ê¸°ë³¸ ì¬ì‹œë„
            0.05..=0.15 => 5,     // ì¤‘ê°„ ì˜¤ë¥˜ìœ¨: ì¦ê°€ëœ ì¬ì‹œë„
            _ => 8,               // ë†’ì€ ì˜¤ë¥˜ìœ¨: ì ê·¹ì  ì¬ì‹œë„
        };

        // 3ï¸âƒ£ í¬ë¡¤ë§ ì „ëµë³„ ì„¸ë¶€ ì¡°ì •
        let (adjusted_batch_size, delay_ms) = match strategy {
            CrawlingStrategy::Full => {
                // ì „ì²´ í¬ë¡¤ë§: íš¨ìœ¨ì„± ìš°ì„ , í° ë°°ì¹˜
                (base_batch_size * 2, 1000)
            }
            CrawlingStrategy::Incremental => {
                // ì¦ë¶„ í¬ë¡¤ë§: ê· í˜• ì¡íŒ ì ‘ê·¼
                (base_batch_size, 1500)
            }
            CrawlingStrategy::Recovery => {
                // ë³µêµ¬ í¬ë¡¤ë§: ì‹ ì¤‘í•¨ ìš°ì„ , ì‘ì€ ë°°ì¹˜ + ê¸´ ì§€ì—°
                (base_batch_size / 2, 3000)
            }
            CrawlingStrategy::NoAction => {
                // ì‘ì—… ì—†ìŒ: ê¸°ë³¸ê°’
                (1, 1000)
            }
        };

        // 4ï¸âƒ£ ì´ ì‘ì—…ëŸ‰ ê¸°ë°˜ ìµœì¢… ì¡°ì •
        let final_batch_size = if total_pages > 1000 {
            adjusted_batch_size * 2  // ëŒ€ëŸ‰ ì‘ì—…: ë°°ì¹˜ í¬ê¸° ì¦ê°€
        } else if total_pages < 50 {
            (adjusted_batch_size / 2).max(1)  // ì†ŒëŸ‰ ì‘ì—…: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
        } else {
            adjusted_batch_size
        };

        BatchConfig {
            batch_size: final_batch_size,
            max_retries,
            delay_between_batches_ms: delay_ms,
            timeout_per_request_ms: site_status.average_response_time_ms * 3 + 5000,
            concurrent_requests: if site_status.server_load_level < 0.7 { 3 } else { 1 },
        }
    }

    /// í˜ì´ì§€ ë²”ìœ„ì™€ ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆìƒ ì•„ì´í…œ ìˆ˜ë¥¼ ê³„ì‚°
    fn estimate_items(&self, start: u32, end: u32, status: &SiteStatus) -> u32 {
        if start > end { return 0; }
        
        let num_pages = end - start + 1;
        let avg_items_per_page = status.products_on_last_page.max(12); // ìµœì†Œ 12ê°œ ê°€ì •
        
        // ë§ˆì§€ë§‰ í˜ì´ì§€ ì œì™¸í•˜ê³ ëŠ” í‰ê· ê°’ ì ìš©
        if num_pages == 1 {
            status.products_on_last_page
        } else {
            (num_pages - 1) * avg_items_per_page + status.products_on_last_page
        }
    }

    /// ê³„íš ìˆ˜ë¦½ ì§„í–‰ ìƒí™© ì´ë²¤íŠ¸ ë°œí–‰
    async fn emit_planning_progress(&self, message: &str, progress: u8) -> crate::Result<()> {
        self.emit_event(AppEvent::Planning(PlanningEvent::Progress {
            message: message.to_string(),
            progress_percent: progress,
            timestamp: std::time::SystemTime::now(),
        })).await
    }
}

impl EventEmitter for CrawlingPlanner {
    async fn emit_event(&self, event: AppEvent) -> crate::Result<()> {
        self.event_hub.emit_event(event).await
    }
}
```

## 4. UI ìƒí˜¸ì‘ìš© ì‹œë‚˜ë¦¬ì˜¤: ì‹¤ì‹œê°„ í”¼ë“œë°±ê³¼ ì‚¬ìš©ì ì œì–´

### 4.1 í¬ë¡¤ë§ ì‹œì‘ ë° ì‹¤ì‹œê°„ ìƒíƒœ ì¶”ì 

```mermaid
sequenceDiagram
    participant UI as CrawlingDashboard
    participant Facade as CrawlingFacade
    participant Orchestrator as SessionOrchestrator
    participant Planner as CrawlingPlanner
    participant EventHub as EventHub

    UI->>Facade: start_full_crawl(user_config)
    Facade->>Orchestrator: run_workflow(user_config)
    
    Note over Orchestrator: ì„¸ì…˜ ì‹œì‘
    Orchestrator->>EventHub: emit(Session::Started)
    EventHub-->>UI: "í¬ë¡¤ë§ ì„¸ì…˜ ì‹œì‘ë¨"

    Note over Orchestrator: ë¶„ì„ ë‹¨ê³„
    Orchestrator->>EventHub: emit(Session::StageChanged { to: Analyzing })
    EventHub-->>UI: "ì‚¬ì´íŠ¸ ë° DB ë¶„ì„ ì¤‘..."

    Note over Orchestrator: ê³„íš ë‹¨ê³„
    Orchestrator->>Planner: create_comprehensive_plan()
    Planner->>EventHub: emit(Planning::Progress { "ë²”ìœ„ ê³„ì‚° ì¤‘", 25% })
    EventHub-->>UI: "ë²”ìœ„ ê³„ì‚° ì¤‘ (25%)"
    
    Planner->>EventHub: emit(Planning::Progress { "ë°°ì¹˜ ì„¤ì • ìµœì í™” ì¤‘", 75% })
    EventHub-->>UI: "ë°°ì¹˜ ì„¤ì • ìµœì í™” ì¤‘ (75%)"
    
    Planner->>EventHub: emit(Planning::Completed)
    EventHub-->>UI: "ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: 50í˜ì´ì§€ ì²˜ë¦¬ ì˜ˆì •"

    Note over Orchestrator: ì‹¤í–‰ ë‹¨ê³„
    Orchestrator->>EventHub: emit(Session::StageChanged { to: Executing })
    EventHub-->>UI: "í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘..."

    loop ë°°ì¹˜ ì²˜ë¦¬
        Orchestrator->>EventHub: emit(Batch::Progress { 3/10 ì™„ë£Œ })
        EventHub-->>UI: "ë°°ì¹˜ 3/10 ì™„ë£Œ (30%)"
    end

    Orchestrator->>EventHub: emit(Session::Completed)
    EventHub-->>UI: "í¬ë¡¤ë§ ì™„ë£Œ: 500ê°œ ì•„ì´í…œ ìˆ˜ì§‘"
```

### 4.2 ì‚¬ìš©ì ì œì–´: ì¼ì‹œì •ì§€ ë° ì·¨ì†Œ

```mermaid
sequenceDiagram
    participant UI as CrawlingDashboard
    participant Facade as CrawlingFacade
    participant State as SharedSessionState
    participant BatchManager as BatchManager
    participant Task as AsyncTask

    Note over UI: ì‚¬ìš©ìê°€ "ì¼ì‹œì •ì§€" í´ë¦­
    UI->>Facade: pause_session(session_id)
    Facade->>State: pause_signal.store(true)
    Facade->>EventHub: emit(Session::Paused)
    EventHub-->>UI: "ì¼ì‹œì •ì§€ ìš”ì²­ë¨"

    Note over BatchManager: í˜„ì¬ ë°°ì¹˜ ì™„ë£Œ í›„ ëŒ€ê¸°
    BatchManager->>State: check pause_signal
    BatchManager->>BatchManager: complete_current_batch()
    BatchManager->>EventHub: emit(Batch::Paused)
    EventHub-->>UI: "í˜„ì¬ ë°°ì¹˜ ì™„ë£Œ í›„ ì¼ì‹œì •ì§€ë¨"

    Note over UI: ì‚¬ìš©ìê°€ "ì·¨ì†Œ" í´ë¦­  
    UI->>Facade: cancel_session(session_id)
    Facade->>State: cancellation_token.store(true)
    Facade->>EventHub: emit(Session::Cancelled)
    EventHub-->>UI: "ì·¨ì†Œ ìš”ì²­ë¨"

    Note over Task: ëª¨ë“  ì‘ì—…ì—ì„œ ì¦‰ì‹œ í™•ì¸
    Task->>State: if cancellation_token.load()
    Task->>Task: cleanup() and exit
    Task->>EventHub: emit(Task::Cancelled)
    EventHub-->>UI: "ëª¨ë“  ì‘ì—…ì´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë¨"
```

## 5. êµ¬í˜„ ê³„íš: ì™„ì „í•œ ì¬ì‘ì„± ì „ëµ

### 5.1 ì „ëµ ê°œìš”: ì¤‘ê°„ ì½”ë“œ ì–‘ì‚° ë°©ì§€

**í•µì‹¬ ì›ì¹™**: ê¸°ì¡´ ì‹œìŠ¤í…œì€ ì™„ì „íˆ ìœ ì§€í•˜ë©´ì„œ, ìƒˆ ì‹œìŠ¤í…œì„ ë…ë¦½ì ìœ¼ë¡œ ì™„ì „ êµ¬ì¶•

```mermaid
gantt
    title ì™„ì „ ì¬ì‘ì„± ê¸°ë°˜ êµ¬í˜„ ê³„íš
    dateFormat YYYY-MM-DD
    section ê¸°ì¡´ ì‹œìŠ¤í…œ
    ê¸°ì¡´ ì‹œìŠ¤í…œ ìœ ì§€        :existing, 2025-07-20, 6w
    ê¸°ì¡´ ì‹œìŠ¤í…œ ì œê±°        :remove, 2025-09-01, 1w
    section ìƒˆ ì‹œìŠ¤í…œ
    ìƒˆ ì‹œìŠ¤í…œ ì™„ì „ êµ¬ì¶•     :new, 2025-07-20, 5w
    ê¸°ëŠ¥ ê²€ì¦ ë° í…ŒìŠ¤íŠ¸     :test, 2025-08-25, 1w
    ì™„ì „ êµì²´              :switch, 2025-09-01, 1w
```

### 5.2 êµ¬í˜„ ë‹¨ê³„: 4ì£¼ ì™„ì „ êµ¬ì¶•

#### Week 1: í•µì‹¬ ì•„í‚¤í…ì²˜ êµ¬ì¶•

```rust
// ìƒˆë¡œìš´ ë…ë¦½ ëª¨ë“ˆ ìƒì„±
src-tauri/src/
â”œâ”€â”€ crawling/              // ê¸°ì¡´ ì‹œìŠ¤í…œ (ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
â”‚   â””â”€â”€ ...               
â”œâ”€â”€ new_crawling/          // ìƒˆ ì‹œìŠ¤í…œ (ì™„ì „ ë…ë¦½)
â”‚   â”œâ”€â”€ facade.rs          // CrawlingFacade
â”‚   â”œâ”€â”€ orchestrator.rs    // SessionOrchestrator  
â”‚   â”œâ”€â”€ state.rs           // SharedSessionState
â”‚   â””â”€â”€ events.rs          // EventHub
â””â”€â”€ main.rs                // ê¸°ì¡´ ì‹œìŠ¤í…œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
```

**êµ¬í˜„ ìš°ì„ ìˆœìœ„**:
1. CrawlingFacade: ëª…í™•í•œ ì‹œìŠ¤í…œ API
2. SessionOrchestrator: ì›Œí¬í”Œë¡œ ì§€íœ˜ì
3. SharedSessionState: ìƒíƒœ ê´€ë¦¬ í•µì‹¬
4. EventHub: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ

#### Week 2: ë„ë©”ì¸ ë¡œì§ ì™„ì„±

```rust
src-tauri/src/new_crawling/
â”œâ”€â”€ domain/
â”‚   â”œâ”€â”€ planner.rs         // CrawlingPlanner (ëª¨ë“  ë„ë©”ì¸ ì§€ì‹)
â”‚   â”œâ”€â”€ analyzer.rs        // SiteStatusChecker  
â”‚   â””â”€â”€ config.rs          // SessionConfig
â”œâ”€â”€ execution/
â”‚   â”œâ”€â”€ batch_manager.rs   // BatchManager
â”‚   â””â”€â”€ tasks.rs           // AsyncTask Traits
â””â”€â”€ ui/
    â””â”€â”€ components.rs      // ìƒˆ UI ì»´í¬ë„ŒíŠ¸
```

**í•µì‹¬ ê¸°ëŠ¥**:
- 3ê°€ì§€ ì •ë³´ ì¢…í•© ê³„íš ìˆ˜ë¦½
- ì ì‘ì  ë°°ì¹˜ ì„¤ì • ìµœì í™”
- ë„ë©”ì¸ ì§€ì‹ ì™„ì „ ì´ì‹

#### Week 3: ì‹¤í–‰ ê³„ì¸µ ë° UI

- BatchManager: ê³ ì„±ëŠ¥ ë°°ì¹˜ ì²˜ë¦¬
- AsyncTask êµ¬í˜„: Modern Rust íŒ¨í„´
- ìƒˆ UI ì»´í¬ë„ŒíŠ¸: ì‹¤ì‹œê°„ í”¼ë“œë°±
- ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§: ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

#### Week 4: í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

- ì „ì²´ ê¸°ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ê¸°ì¡´ ì‹œìŠ¤í…œ ëŒ€ë¹„)
- ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ ì¤€ë¹„
- ë¡¤ë°± ê³„íš ìˆ˜ë¦½

### 5.3 ì „í™˜ ì „ëµ: í•œ ë²ˆì— ì™„ì „ êµì²´

```rust
// main.rsì—ì„œ í•œ ì¤„ ë³€ê²½ìœ¼ë¡œ ì™„ì „ ì „í™˜
fn main() {
    // ê¸°ì¡´: 
    // crawling::start_system();
    
    // ìƒˆ ì‹œìŠ¤í…œ:
    new_crawling::start_system();
}
```

**ì „í™˜ ì´ì **:
- âœ… ì¤‘ê°„ ì½”ë“œ ì œë¡œ: ë²„ë ¤ì§ˆ ì½”ë“œ ì „í˜€ ì—†ìŒ
- âœ… í˜¼ë€ ìµœì†Œí™”: í•œ ë²ˆì— ê¹”ë”í•œ ì „í™˜
- âœ… ì•„í‚¤í…ì²˜ ìˆœìˆ˜ì„±: ê¸°ì¡´ ì œì•½ ì—†ëŠ” ìµœì  ì„¤ê³„
- âœ… ë¹ ë¥¸ ê°œë°œ: í˜¸í™˜ì„± ê³ ë ¤ ë¶ˆí•„ìš”

### 5.4 ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë° ë¡¤ë°± ê³„íš

#### ë¦¬ìŠ¤í¬ ìš”ì†Œ ë° ëŒ€ì‘ì±…

**1. ê¸°ëŠ¥ ëˆ„ë½ ë¦¬ìŠ¤í¬**
- **ëŒ€ì‘**: ê¸°ì¡´ ì‹œìŠ¤í…œ ê¸°ëŠ¥ ì™„ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„±
- **ê²€ì¦**: ìƒˆ ì‹œìŠ¤í…œì—ì„œ ëª¨ë“  ê¸°ëŠ¥ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

**2. ì„±ëŠ¥ ì €í•˜ ë¦¬ìŠ¤í¬**  
- **ëŒ€ì‘**: ì—„ê²©í•œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€ ì„¤ì •
- **ê¸°ì¤€**: ê¸°ì¡´ ì‹œìŠ¤í…œ ëŒ€ë¹„ ìµœì†Œ ë™ë“±, ëª©í‘œ 20% ì„±ëŠ¥ í–¥ìƒ

**3. ë°ì´í„° ì†ì‹¤ ë¦¬ìŠ¤í¬**
- **ëŒ€ì‘**: ì™„ì „í•œ ë°±ì—… ë° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬
- **ê²€ì¦**: ìŠ¤í…Œì´ì§• í™˜ê²½ì—ì„œ ì™„ì „ í…ŒìŠ¤íŠ¸

**4. ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œ**
- **ë¡¤ë°± ê³„íš**: ê¸°ì¡´ ì‹œìŠ¤í…œ ì™„ì „ ë³´ì¡´ìœ¼ë¡œ ì¦‰ì‹œ ë³µì› ê°€ëŠ¥
- **ì „í™˜ ë°©ì‹**: í•œ ì¤„ ì½”ë“œ ë³€ê²½ìœ¼ë¡œ ì¦‰ì‹œ ë¡¤ë°±

```rust
// ì¦‰ì‹œ ë¡¤ë°± ê°€ëŠ¥í•œ êµ¬ì¡°
fn main() {
    // ë¬¸ì œ ë°œìƒ ì‹œ í•œ ì¤„ ì£¼ì„ ì²˜ë¦¬ë¡œ ì¦‰ì‹œ ë¡¤ë°±
    // crawling::start_system();     // ê¸°ì¡´ ì‹œìŠ¤í…œ
    new_crawling::start_system();    // ìƒˆ ì‹œìŠ¤í…œ
}
```

## 6. ê¸°ëŒ€ íš¨ê³¼: ì™„ì „í•œ ì•„í‚¤í…ì²˜ í˜ì‹ 
- **ì œì–´ì„±**: ì‹œì‘ë§Œ ê°€ëŠ¥ â†’ ì¼ì‹œì •ì§€/ì¬ê°œ/ì·¨ì†Œ ì™„ì „ ì œì–´
- **íš¨ìœ¨ì„±**: ê³ ì • ë°°ì¹˜ â†’ ì ì‘ì  ë°°ì¹˜ ì„¤ì •ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
- **ì•ˆì •ì„±**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ â†’ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ìë™ ê´€ë¦¬

### 6.2 ê°œë°œ ìƒì‚°ì„± í–¥ìƒ

- **ëª…í™•í•œ ì±…ì„**: ê° ì»´í¬ë„ŒíŠ¸ì˜ ì—­í• ê³¼ ìƒí˜¸ì‘ìš© ëª…í™•í™”
- **í…ŒìŠ¤íŠ¸ ìš©ì´ì„±**: Trait ê¸°ë°˜ ì˜ì¡´ì„± ì£¼ì…ìœ¼ë¡œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°œì„ 
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ í¬ë¡¤ë§ ì „ëµ ì¶”ê°€ ì‹œ CrawlingPlannerë§Œ ìˆ˜ì •
- **ìœ ì§€ë³´ìˆ˜ì„±**: Modern Rust íŒ¨í„´ê³¼ ëª…í™•í•œ ì•„í‚¤í…ì²˜ ê²½ê³„

### 6.3 ì‚¬ìš©ì ê²½í—˜ í˜ì‹ 

- **ì‹¤ì‹œê°„ í”¼ë“œë°±**: ëª¨ë“  ì‘ì—… ë‹¨ê³„ì˜ ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í™•ì¸
- **ì œì–´ ê°€ëŠ¥ì„±**: ì–¸ì œë“ ì§€ ì‘ì—… ì¤‘ë‹¨/ì¬ê°œ ê°€ëŠ¥
- **ì˜ˆì¸¡ ê°€ëŠ¥ì„±**: ì •í™•í•œ ETA ë° ì§„í–‰ë¥  í‘œì‹œ
- **ì•ˆì •ì„±**: ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì‹œ ìë™ ë³µêµ¬ ë° ìƒíƒœ ë³µì›

## 7. ê²°ë¡ : ì™„ì „í•œ ì•„í‚¤í…ì²˜ í˜ì‹ 

ì´ **re-arch-plan2.md**ëŠ” ë‹¨ìˆœí•œ ê¸°ìˆ ì  ê°œì„ ì´ ì•„ë‹Œ **ì™„ì „í•œ ì•„í‚¤í…ì²˜ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜**ì„ ì œì‹œí•©ë‹ˆë‹¤:

### 7.1 í•µì‹¬ í˜ì‹  ìš”ì†Œ

1. **êµ¬ì¡°ì  ëª…í™•ì„±**: re-arch-plan-improvedì˜ ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬
2. **êµ¬ì²´ì  ì‹¤í–‰ ê³„íš**: re-arch-planì˜ ë‹¨ê³„ë³„ êµ¬í˜„ ì „ëµ
3. **ë„ë©”ì¸ ì§€ì‹ ê³„ìŠ¹**: ê²€ì¦ëœ í¬ë¡¤ë§ ë¡œì§ì˜ ì²´ê³„ì  ì´ì‹
4. **UI ì¤‘ì‹¬ ì„¤ê³„**: ì‚¬ìš©ì ê²½í—˜ì„ ì•„í‚¤í…ì²˜ í•µì‹¬ìœ¼ë¡œ ë°°ì¹˜

### 7.2 ìµœì¢… ëª©í‘œ

**"ì‚¬ìš©ìê°€ ë¯¿ê³  ì œì–´í•  ìˆ˜ ìˆëŠ” íˆ¬ëª…í•˜ê³  ì§€ëŠ¥ì ì¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ"**

- ëª¨ë“  ë™ì‘ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³´ì´ê³ 
- ëª¨ë“  ì œì–´ê°€ ì¦‰ì‹œ ë°˜ì‘í•˜ë©°  
- ëª¨ë“  ê²°ì •ì´ ë„ë©”ì¸ ì§€ì‹ì— ê¸°ë°˜í•˜ê³ 
- ëª¨ë“  ì„±ëŠ¥ì´ ìƒí™©ì— ë§ê²Œ ìµœì í™”ë˜ëŠ”

ê·¸ëŸ° ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ ì´ ì•„í‚¤í…ì²˜ ì¬êµ¬ì¶•ì˜ ìµœì¢… ëª©í‘œì…ë‹ˆë‹¤.
