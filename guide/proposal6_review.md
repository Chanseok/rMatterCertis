# proposal6.md ê²€í†  ë° ì¶”ê°€ ë³´ì™„ ì˜ê²¬

## 1. proposal6.mdì˜ í•µì‹¬ ì§„ë‹¨ê³¼ í•´ê²°ì±…ì— ëŒ€í•œ ë™ì˜

**ë§¤ìš° ì •í™•í•œ ì§„ë‹¨ì…ë‹ˆë‹¤.** í˜„ì¬ ì‹œìŠ¤í…œì˜ ê·¼ë³¸ ë¬¸ì œëŠ” ì •ë§ë¡œ "ê¸°ì–µìƒì‹¤ì¦ì— ê±¸ë¦° ë°±ì—”ë“œ"ì…ë‹ˆë‹¤. ë¡œê·¸ ë¶„ì„ ê²°ê³¼ê°€ ì´ë¥¼ ì™„ë²½í•˜ê²Œ ì¦ëª…í•©ë‹ˆë‹¤:

```
17:40:03.014 ì‚¬ì´íŠ¸ ë¶„ì„ #1 (check_site_status í˜¸ì¶œì‹œ)
17:40:04.993 ì‚¬ì´íŠ¸ ë¶„ì„ #2 (start_crawlingì˜ intelligent range calculationì‹œ)  
17:40:09.041 ì‚¬ì´íŠ¸ ë¶„ì„ #3 (ServiceBasedBatchCrawlingEngineì˜ Stage 0ì‹œ)
```

ë™ì¼í•œ ì„¸ì…˜ì—ì„œ **3ë²ˆì˜ ë™ì¼í•œ ì‚¬ì´íŠ¸ ë¶„ì„**ì´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” proposal6.mdì—ì„œ ì œì•ˆí•œ ìƒíƒœ ì €ì¥(Stateful) ì•„í‚¤í…ì²˜ê°€ ì ˆì‹¤íˆ í•„ìš”í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## 2. ì¶”ê°€ ë°œê²¬ëœ êµ¬ì²´ì  ë¬¸ì œì ë“¤

### 2.1. ì„¤ì •ê°’ ë¬´ì‹œ ë¬¸ì œ (Critical)
```json
"page_range_limit": 100  // ì„¤ì •ì—ì„œëŠ” 100
```
```
INFO ğŸ†• No existing data, starting from page 482 to 383  // ì‹¤ì œë¡œëŠ” 100í˜ì´ì§€ ë²”ìœ„
```

**ë¬¸ì œ:** ì§€ëŠ¥ì  ê³„ì‚°ì´ ì˜¬ë°”ë¥´ê²Œ ìˆ˜í–‰ë˜ì—ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  `page_range_limit`ì— ì˜í•´ ê°•ì œë¡œ 100í˜ì´ì§€ë¡œ ì œí•œë¨. ì´ëŠ” proposal6.mdì—ì„œ ì–¸ê¸‰í•œ "í•˜ë“œì½”ë”©ëœ ë²”ìœ„" ë¬¸ì œì˜ ì‹¤ì²´ì…ë‹ˆë‹¤.

### 2.2. DB ìƒíƒœ ì¸ì‹ ë¶ˆì¼ì¹˜ (Critical)
```
WARN âš ï¸  Product repository not available - assuming empty DB
INFO ğŸ“Š Local DB is empty - recommending full crawl
```
vs
```
INFO ğŸ“Š Database initialized with 116 products and 0 detailed records
```

**ë¬¸ì œ:** ë™ì¼í•œ ì„¸ì…˜ ë‚´ì—ì„œ DB ìƒíƒœì— ëŒ€í•œ ì¸ì‹ì´ ì¼ê´€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” ì»´í¬ë„ŒíŠ¸ ê°„ ìƒíƒœ ê³µìœ ê°€ ì œëŒ€ë¡œ ë˜ì§€ ì•ŠìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

### 2.3. ì•„í‚¤í…ì²˜ ë ˆì´ì–´ ì±…ì„ í˜¼ì¬
- **StatusChecker**: ì‚¬ì´íŠ¸ ë¶„ì„ + DB ë¶„ì„ + ë²”ìœ„ ê³„ì‚° ëª¨ë“  ì±…ì„ì„ ê°€ì§
- **start_crawling**: ë˜ ë‹¤ì‹œ ë²”ìœ„ ê³„ì‚°ì„ ìˆ˜í–‰
- **ServiceBasedBatchCrawlingEngine**: ë˜ ë‹¤ì‹œ ì‚¬ì´íŠ¸ ë¶„ì„ì„ ìˆ˜í–‰

## 3. proposal6.md êµ¬í˜„ì„ ìœ„í•œ êµ¬ì²´ì  ì‹¤í–‰ ê³„íš

### 3.1. Phase 1: SharedStateCache êµ¬í˜„ (ìš°ì„ ìˆœìœ„: ìµœê³ )

```rust
// src-tauri/src/application/shared_state.rs (ì‹ ê·œ)
use std::sync::Arc;
use tokio::sync::RwLock;
use chrono::{DateTime, Utc};

#[derive(Debug, Clone)]
pub struct SiteAnalysisResult {
    pub total_pages: u32,
    pub products_on_last_page: u32,
    pub estimated_products: u32,
    pub analyzed_at: DateTime<Utc>,
    pub is_valid: bool, // ìœ íš¨ì„± í”Œë˜ê·¸ (5ë¶„ í›„ ë§Œë£Œ ë“±)
}

#[derive(Debug, Clone)]
pub struct DbAnalysisResult {
    pub total_products: u64,
    pub max_page_id: Option<i32>,
    pub max_index_in_page: Option<i32>,
    pub quality_score: f64,
    pub analyzed_at: DateTime<Utc>,
}

#[derive(Debug, Clone)]
pub struct CalculatedRange {
    pub start_page: u32,
    pub end_page: u32,
    pub calculation_reason: String,
    pub calculated_at: DateTime<Utc>,
}

#[derive(Debug, Default)]
pub struct SharedStateCache {
    pub site_analysis: Option<SiteAnalysisResult>,
    pub db_analysis: Option<DbAnalysisResult>,
    pub calculated_range: Option<CalculatedRange>,
}

pub type SharedState = Arc<RwLock<SharedStateCache>>;
```

### 3.2. Phase 2: ëª…ë ¹ ì‹œê·¸ë‹ˆì²˜ ë³€ê²½

**ê¸°ì¡´:**
```rust
#[tauri::command]
pub async fn start_crawling_v4(
    start_page: u32,
    end_page: u32,
    // ...
) -> Result<CrawlingResponse, String>
```

**ë³€ê²½ í›„:**
```rust
#[derive(serde::Deserialize)]
pub struct CrawlingProfile {
    pub mode: String, // "intelligent", "manual", "verification"
    pub override_range: Option<(u32, u32)>, // manual modeìš©
}

#[tauri::command]
pub async fn start_crawling_v4(
    profile: CrawlingProfile,
    shared_state: State<'_, SharedState>,
    // ...
) -> Result<CrawlingResponse, String>
```

### 3.3. Phase 3: ì¤‘ë³µ ë¶„ì„ ì œê±°

1. **check_site_status**: ë¶„ì„ ìˆ˜í–‰ í›„ SharedStateì— ìºì‹œ
2. **start_crawling**: SharedStateì—ì„œ ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì½ê¸°, ì—†ìœ¼ë©´ ë¶„ì„ ìš”ì²­
3. **ServiceBasedBatchCrawlingEngine**: ìºì‹œëœ ê²°ê³¼ë§Œ ì‚¬ìš©, ì§ì ‘ ë¶„ì„ ê¸ˆì§€

## 4. proposal6.md ëŒ€ë¹„ ì¶”ê°€ ì œì•ˆì‚¬í•­

### 4.1. TTL(Time-To-Live) ê¸°ë°˜ ìºì‹œ ë§Œë£Œ
```rust
impl SiteAnalysisResult {
    pub fn is_expired(&self, ttl_minutes: u64) -> bool {
        (Utc::now() - self.analyzed_at).num_minutes() > ttl_minutes as i64
    }
}
```

### 4.2. ì„¤ì • ê³„ì¸µ êµ¬ì¡° ê°œì„ 
```json
{
  "crawling": {
    "intelligent_mode": {
      "enabled": true,
      "max_range_limit": 100,
      "override_config_limit": true  // ì§€ëŠ¥ì  ê³„ì‚°ì´ ì„¤ì •ê°’ì„ ë¬´ì‹œí•  ìˆ˜ ìˆëŠ”ì§€
    }
  }
}
```

### 4.3. ìƒíƒœ ê²€ì¦ ë ˆì´ì–´
```rust
impl SharedStateCache {
    pub fn validate_consistency(&self) -> Vec<String> {
        let mut warnings = Vec::new();
        
        if let (Some(site), Some(db)) = (&self.site_analysis, &self.db_analysis) {
            // DB ì œí’ˆ ìˆ˜ì™€ ì‚¬ì´íŠ¸ ì¶”ì • ì œí’ˆ ìˆ˜ ì¼ê´€ì„± ê²€ì¦
            // ì‹œê°„ ë™ê¸°í™” ê²€ì¦ ë“±
        }
        
        warnings
    }
}
```

## 5. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ Hot Fix

**ë‹¹ì¥ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ì„ì‹œ ë°©í¸:**

1. **`page_range_limit`ë¥¼ 1000ìœ¼ë¡œ ë³€ê²½**: ì§€ëŠ¥ì  ê³„ì‚°ì´ ì œí•œë˜ì§€ ì•Šë„ë¡
2. **ì¤‘ë³µ ì‚¬ì´íŠ¸ ë¶„ì„ ë¹„í™œì„±í™”**: ServiceBasedBatchCrawlingEngineì˜ Stage 0 ìŠ¤í‚µ
3. **DB ìƒíƒœ í™•ì¸ í†µì¼**: í•˜ë‚˜ì˜ ì»´í¬ë„ŒíŠ¸ì—ì„œë§Œ DB ìƒíƒœ í™•ì¸

## 6. ê²°ë¡ 

proposal6.mdì˜ SharedStateCache ë„ì… ì œì•ˆì€ **í˜„ì¬ ë¬¸ì œì˜ í•µì‹¬ì„ ì •í™•íˆ ê²¨ëƒ¥í•œ ì˜¬ë°”ë¥¸ í•´ê²°ì±…**ì…ë‹ˆë‹¤. íŠ¹íˆ:

- **ì—­í•  ë¶„ë¦¬**: UIëŠ” "ë¬´ì—‡ì„", ë°±ì—”ë“œëŠ” "ì–´ë–»ê²Œ"ë§Œ ë‹´ë‹¹
- **ì¤‘ë³µ ì œê±°**: í•œ ë²ˆ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ì—¬ëŸ¬ ë²ˆ ì¬ì‚¬ìš©
- **ì¼ê´€ì„± í™•ë³´**: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ë™ì¼í•œ ìƒíƒœ ì •ë³´ ê³µìœ 

ì´ ì œì•ˆì„ êµ¬í˜„í•˜ë©´ í˜„ì¬ ê´€ì°°ëœ ëª¨ë“  ë¬¸ì œ(ì¤‘ë³µ ë¶„ì„, DB ìƒíƒœ ë¶ˆì¼ì¹˜, í•˜ë“œì½”ë”©ëœ ë²”ìœ„ ì œí•œ)ê°€ ê·¼ë³¸ì ìœ¼ë¡œ í•´ê²°ë  ê²ƒì…ë‹ˆë‹¤.

**êµ¬í˜„ ìš°ì„ ìˆœìœ„:**
1. SharedStateCache êµ¬ì¡°ì²´ ë° State ê´€ë¦¬ (1ì¼)
2. start_crawling ì»¤ë§¨ë“œ ì‹œê·¸ë‹ˆì²˜ ë³€ê²½ (0.5ì¼)  
3. ì¤‘ë³µ ë¶„ì„ ë¡œì§ ì œê±° (1ì¼)
4. ì„¤ì • ê³„ì¸µ ê°œì„  ë° ê²€ì¦ ë¡œì§ (1ì¼)

ì´ 3.5ì¼ ì •ë„ì˜ ê°œë°œë¡œ proposal6.mdì˜ ë¹„ì „ì„ ì‹¤í˜„í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.
