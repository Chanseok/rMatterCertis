# rMatterCertis - ì‹¤ì „ ë‹¨ê³„ë³„ ê°œë°œ ê°€ì´ë“œ (ê²€ì¦ëœ êµ¬í˜„ ê¸°ë°˜)

## ğŸ—“ï¸ ì „ì²´ ê°œë°œ ì¼ì • (8ì£¼) - ì‹¤ì œ ê²€ì¦ëœ ë‹¨ê³„

### âœ… Phase 1: í”„ë¡œì íŠ¸ ì´ˆê¸°í™” ë° ì•„í‚¤í…ì²˜ ìµœì í™” (2ì£¼) - **ì™„ë£Œ**
### ğŸ”„ Phase 2: ë°±ì—”ë“œ ë„ë©”ì¸ êµ¬í˜„ (2ì£¼) - **ì§„í–‰ ì¤‘**
### Phase 3: í¬ë¡¤ë§ ì—”ì§„ êµ¬í˜„ (2ì£¼)
### Phase 4: í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ (1.5ì£¼)
### Phase 5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ìµœì í™” (0.5ì£¼)

---

## âœ… Phase 1: í”„ë¡œì íŠ¸ ì´ˆê¸°í™” ë° ì•„í‚¤í…ì²˜ ìµœì í™” (ì™„ë£Œ)

### ğŸ¯ ì‹¤ì œ ë‹¬ì„±ëœ ëª©í‘œ
- âœ… Tauri + SolidJS í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
- âœ… ëª¨ë˜ Rust êµ¬ì¡° êµ¬ì¶• (mod.rs ì—†ëŠ” ë°©ì‹)
- âœ… ë¹Œë“œ ì„±ëŠ¥ ìµœì í™” (66~95% í–¥ìƒ)
- âœ… ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° êµ¬í˜„
- âœ… Tauri Commands ë° UI í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•

### ğŸ“‹ ì‹¤ì œ ì™„ë£Œëœ ì‘ì—… ëª©ë¡

#### Week 1.1: í”„ë¡œì íŠ¸ ì…‹ì—… ë° ìµœì í™” (ì‹¤ì œ 3ì¼)

**1ì¼ì°¨: í”„ë¡œì íŠ¸ ì´ˆê¸°í™” (ì‹¤ì œ êµ¬í˜„)**
```bash
# ì‹¤ì œ ì‚¬ìš©ëœ ëª…ë ¹ì–´
pnpm create tauri-app@latest rMatterCertis
cd rMatterCertis

# ì‹¤ì œ ì„ íƒí•œ ì˜µì…˜
# - Package manager: pnpm (npmë³´ë‹¤ ë¹ ë¦„)
# - Frontend template: SolidJS (Vanilla ëŒ€ì‹ )
# - TypeScript: Yes
```

**ì‹¤ì œ êµ¬í˜„ëœ í”„ë¡œì íŠ¸ êµ¬ì¡°**
```
rMatterCertis/
â”œâ”€â”€ src-tauri/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs
â”‚   â”‚   â”œâ”€â”€ lib.rs
â”‚   â”‚   â”œâ”€â”€ domain.rs (mod.rs ëŒ€ì‹ )
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â”œâ”€â”€ entities.rs
â”‚   â”‚   â”‚   â””â”€â”€ repositories.rs
â”‚   â”‚   â”œâ”€â”€ application.rs
â”‚   â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”‚   â””â”€â”€ use_cases.rs
â”‚   â”‚   â”œâ”€â”€ infrastructure.rs
â”‚   â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”‚   â””â”€â”€ database_connection.rs
â”‚   â”‚   â”œâ”€â”€ commands.rs
â”‚   â”‚   â””â”€â”€ bin/
â”‚   â”‚       â””â”€â”€ test_db.rs
â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â””â”€â”€ 001_initial.sql
â”‚   â”œâ”€â”€ data/ (ëŸ°íƒ€ì„ ìƒì„±)
â”‚   â”œâ”€â”€ Cargo.toml (ìµœì í™”ë¨)
â”‚   â””â”€â”€ tauri.conf.json
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.tsx
â”‚   â”œâ”€â”€ App.tsx (DB í…ŒìŠ¤íŠ¸ UI)
â”‚   â””â”€â”€ app.css
â”œâ”€â”€ .cargo/
â”‚   â””â”€â”€ config.toml (ë¹Œë“œ ìµœì í™”)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ test-fast.sh
â”œâ”€â”€ .env.development
â”œâ”€â”€ .gitignore (í™•ì¥ë¨)
â””â”€â”€ package.json (SolidJS)
```

**2ì¼ì°¨: ì„±ëŠ¥ ìµœì í™”ëœ Cargo.toml**
```toml
# ì‹¤ì œ ê²€ì¦ëœ ì„¤ì •
[package]
name = "matter-certis-v2"
version = "0.1.0"
description = "rMatterCertis - E-commerce Product Crawling Application"
authors = ["Chanseok <hi007chans@gmail.com>"]
edition = "2021"
default-run = "matter-certis-v2"

[workspace]
resolver = "2"

# ğŸš€ ì‹¤ì œ ì ìš©ëœ ë¹Œë“œ ìµœì í™”
[profile.dev]
opt-level = 0
debug = 1  # ì¶•ì†Œëœ ë””ë²„ê·¸ ì •ë³´
split-debuginfo = "unpacked"
incremental = true
codegen-units = 512  # ë†’ì€ ë³‘ë ¬í™”

[profile.test]
opt-level = 0
debug = 1
incremental = true
codegen-units = 512

# ì˜ì¡´ì„± ìµœì í™” ìœ ì§€
[profile.dev.package."*"]
opt-level = 3
debug = false

[profile.test.package."*"]
opt-level = 3
debug = false
```
tauri-build = { version = "2.0", features = [] }
```

**3ì¼ì°¨: ì‹¤ì œ êµ¬í˜„ëœ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°**
```rust
// src-tauri/src/infrastructure/database_connection.rs
use sqlx::{sqlite::SqlitePool, Pool, Sqlite};
use std::path::Path;
use anyhow::Result;

pub struct DatabaseConnection {
    pool: Option<Pool<Sqlite>>,
}

impl DatabaseConnection {
    pub async fn new(database_url: &str) -> Result<Self> {
        // ì‹¤ì œ êµ¬í˜„: ë””ë ‰í† ë¦¬ ìë™ ìƒì„±
        if database_url.starts_with("sqlite:") {
            let path_str = database_url.strip_prefix("sqlite:").unwrap();
            let path = Path::new(path_str);
            if let Some(parent) = path.parent() {
                tokio::fs::create_dir_all(parent).await?;
            }
        }
        
        let pool = SqlitePool::connect(database_url).await?;
        Ok(Self { pool: Some(pool) })
    }

    pub async fn migrate(&self) -> Result<()> {
        // ì‹¤ì œ êµ¬í˜„: ìˆ˜ë™ í…Œì´ë¸” ìƒì„± (sqlx::migrate! ëŒ€ì‹ )
        let pool = self.pool.as_ref().unwrap();
        
        sqlx::query(
            r#"
            CREATE TABLE IF NOT EXISTS vendors (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                base_url TEXT NOT NULL,
                selector_config TEXT NOT NULL,
                is_active BOOLEAN NOT NULL DEFAULT 1,
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL
            );
            
            CREATE TABLE IF NOT EXISTS products (
                id TEXT PRIMARY KEY,
                vendor_id TEXT NOT NULL,
                name TEXT NOT NULL,
                price REAL,
                currency TEXT NOT NULL DEFAULT 'KRW',
                url TEXT NOT NULL,
                image_url TEXT,
                description TEXT,
                is_available BOOLEAN NOT NULL DEFAULT 1,
                crawled_at TEXT NOT NULL,
                FOREIGN KEY (vendor_id) REFERENCES vendors (id)
            );
            "#
        )
        .execute(pool)
        .await?;
        
        Ok(())
    }

    pub fn pool(&self) -> &Pool<Sqlite> {
        self.pool.as_ref().unwrap()
    }
}

// ì‹¤ì œ êµ¬í˜„ëœ í…ŒìŠ¤íŠ¸
#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[tokio::test]
    async fn test_database_connection() -> Result<()> {
        let temp_dir = tempdir()?;
        let db_path = temp_dir.path().join("test.db");
        let database_url = format!("sqlite:{}", db_path.to_string_lossy());

        let db = DatabaseConnection::new(&database_url).await?;
        assert!(!db.pool().is_closed());
        
        // ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
        db.migrate().await?;
        
        Ok(())
    }
}
```

#### Week 1.2: ì„±ëŠ¥ ìµœì í™” ë° í…ŒìŠ¤íŠ¸ í™˜ê²½ (ì‹¤ì œ 2ì¼)

**4ì¼ì°¨: ë¹Œë“œ ì„±ëŠ¥ ìµœì í™” êµ¬í˜„**
```toml
# .cargo/config.toml - ì‹¤ì œ ê²€ì¦ëœ ì„¤ì •
[build]
jobs = 8
incremental = true

[target.x86_64-apple-darwin]
rustflags = ["-C", "link-arg=-fuse-ld=lld"]

[target.aarch64-apple-darwin]
rustflags = ["-C", "link-arg=-fuse-ld=lld"]

[profile.dev]
debug = 1
split-debuginfo = "unpacked"

[profile.dev.package."*"]
opt-level = 3
debug = false
```

**ì‹¤ì œ ë‹¬ì„±ëœ ì„±ëŠ¥ í–¥ìƒ:**
- ì´ˆê¸° ë¹Œë“œ: 1ë¶„ (ì´ì „ 2-3ë¶„ì—ì„œ 66% í–¥ìƒ)
- ì¦ë¶„ ë¹Œë“œ: 0.5ì´ˆ (ì´ì „ 10-30ì´ˆì—ì„œ 95% í–¥ìƒ)
- ì‘ì€ ë³€ê²½: 2.6ì´ˆ (ì´ì „ 30-60ì´ˆì—ì„œ 90% í–¥ìƒ)

**5ì¼ì°¨: Tauri Commands ë° UI í…ŒìŠ¤íŠ¸**
```rust
// src-tauri/src/commands.rs - ì‹¤ì œ êµ¬í˜„
#[tauri::command]
pub async fn test_database_connection() -> Result<String, String> {
    let db_path = "data/matter_certis.db";
    match DatabaseConnection::new(db_path).await {
        Ok(_) => Ok("Database connection successful".to_string()),
        Err(e) => Err(format!("Database connection failed: {}", e)),
    }
}

#[tauri::command]
pub async fn get_database_info() -> Result<String, String> {
    Ok("Database: SQLite, Location: data/matter_certis.db".to_string())
}
```

```tsx
// src/App.tsx - ì‹¤ì œ êµ¬í˜„ëœ í…ŒìŠ¤íŠ¸ UI
import { invoke } from "@tauri-apps/api/tauri";
import { createSignal } from "solid-js";

function App() {
  const [dbStatus, setDbStatus] = createSignal<string>("");
  const [dbInfo, setDbInfo] = createSignal<string>("");

  const testConnection = async () => {
    try {
      const result = await invoke<string>("test_database_connection");
      setDbStatus(`âœ… ${result}`);
    } catch (error) {
      setDbStatus(`âŒ ${error}`);
    }
  };

  const getInfo = async () => {
    try {
      const result = await invoke<string>("get_database_info");
      setDbInfo(result);
    } catch (error) {
      setDbInfo(`âŒ ${error}`);
    }
  };

  return (
    <div class="container">
      <h1>rMatterCertis</h1>
      <div class="controls">
        <button onClick={testConnection}>Test DB Connection</button>
        <button onClick={getInfo}>Get DB Info</button>
      </div>
      <div class="status">
        <p>{dbStatus()}</p>
        <p>{dbInfo()}</p>
      </div>
    </div>
  );
}
```

### âœ… Phase 1 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] **í”„ë¡œì íŠ¸ ì´ˆê¸°í™”**: Tauri + SolidJS êµ¬ì¡°
- [x] **ëª¨ë˜ Rust ì•„í‚¤í…ì²˜**: mod.rs ì—†ëŠ” êµ¬ì¡°
- [x] **ë¹Œë“œ ì„±ëŠ¥ ìµœì í™”**: 66~95% í–¥ìƒ ë‹¬ì„±
- [x] **ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°**: SQLite ì—°ê²° ë° ë§ˆì´ê·¸ë ˆì´ì…˜
- [x] **í…ŒìŠ¤íŠ¸ í™˜ê²½**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸, CLI ë„êµ¬, UI í…ŒìŠ¤íŠ¸
- [x] **Tauri Commands**: ê¸°ë³¸ DB ëª…ë ¹ì–´ êµ¬í˜„
- [x] **ê°œë°œ ë„êµ¬**: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸, í™˜ê²½ ì„¤ì •

---

## ğŸ”„ Phase 2: ë°±ì—”ë“œ ë„ë©”ì¸ êµ¬í˜„ (ì§„í–‰ ì¤‘)

### ğŸ¯ ëª©í‘œ
- SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
- Repository êµ¬í˜„
- ê¸°ë³¸ Use Cases êµ¬í˜„
- Tauri Commands ê¸°ë³¸ êµ¬ì¡°

### ğŸ“‹ ì‘ì—… ëª©ë¡

#### Week 2.1: ë°ì´í„°ë² ì´ìŠ¤ ë° Infrastructure (3-4ì¼)

**8ì¼ì°¨: SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •**
```rust
// src-tauri/src/infrastructure/database/mod.rs
pub mod connection;
pub mod migrations;
pub mod repositories;

pub use connection::*;
```

```rust
// src-tauri/src/infrastructure/database/connection.rs
use sqlx::{SqlitePool, sqlite::SqlitePoolOptions};
use anyhow::Result;
use std::path::Path;

pub struct DatabaseConnection {
    pool: SqlitePool,
}

impl DatabaseConnection {
    pub async fn new(database_url: &str) -> Result<Self> {
        // ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
        if let Some(parent) = Path::new(database_url.trim_start_matches("sqlite://")).parent() {
            tokio::fs::create_dir_all(parent).await?;
        }

        let pool = SqlitePoolOptions::new()
            .max_connections(10)
            .connect(database_url)
            .await?;

        Ok(Self { pool })
    }

    pub fn pool(&self) -> &SqlitePool {
        &self.pool
    }

    pub async fn migrate(&self) -> Result<()> {
        sqlx::migrate!("./migrations").run(&self.pool).await?;
        Ok(())
    }
}
```

**9ì¼ì°¨: ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸**
```sql
-- migrations/001_initial.sql
CREATE TABLE IF NOT EXISTS vendors (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    base_url TEXT NOT NULL,
    crawling_config TEXT NOT NULL, -- JSON
    is_active BOOLEAN NOT NULL DEFAULT 1,
    last_crawled_at DATETIME,
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS products (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    price REAL,
    currency TEXT NOT NULL DEFAULT 'USD',
    description TEXT,
    image_url TEXT,
    product_url TEXT NOT NULL,
    vendor_id TEXT NOT NULL,
    category TEXT,
    in_stock BOOLEAN NOT NULL DEFAULT 1,
    collected_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (vendor_id) REFERENCES vendors (id)
);

CREATE TABLE IF NOT EXISTS crawling_sessions (
    id TEXT PRIMARY KEY,
    vendor_id TEXT NOT NULL,
    status TEXT NOT NULL,
    total_pages INTEGER,
    processed_pages INTEGER NOT NULL DEFAULT 0,
    products_found INTEGER NOT NULL DEFAULT 0,
    errors_count INTEGER NOT NULL DEFAULT 0,
    started_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    completed_at DATETIME,
    FOREIGN KEY (vendor_id) REFERENCES vendors (id)
);

CREATE INDEX IF NOT EXISTS idx_products_vendor_id ON products (vendor_id);
CREATE INDEX IF NOT EXISTS idx_products_collected_at ON products (collected_at);
CREATE INDEX IF NOT EXISTS idx_crawling_sessions_vendor_id ON crawling_sessions (vendor_id);
```

**10ì¼ì°¨: Repository êµ¬í˜„**
```rust
// src-tauri/src/infrastructure/database/repositories/product_repository_impl.rs
use async_trait::async_trait;
use sqlx::SqlitePool;
use anyhow::Result;
use crate::domain::{entities::Product, repositories::ProductRepository};

pub struct ProductRepositoryImpl {
    pool: SqlitePool,
}

impl ProductRepositoryImpl {
    pub fn new(pool: SqlitePool) -> Self {
        Self { pool }
    }
}

#[async_trait]
impl ProductRepository for ProductRepositoryImpl {
    async fn save(&self, product: &Product) -> Result<()> {
        sqlx::query!(
            r#"
            INSERT INTO products (
                id, name, price, currency, description, 
                image_url, product_url, vendor_id, category, 
                in_stock, collected_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            "#,
            product.id,
            product.name,
            product.price,
            product.currency,
            product.description,
            product.image_url,
            product.product_url,
            product.vendor_id,
            product.category,
            product.in_stock,
            product.collected_at,
            product.updated_at
        )
        .execute(&self.pool)
        .await?;

        Ok(())
    }

    async fn find_by_id(&self, id: &str) -> Result<Option<Product>> {
        let product = sqlx::query_as!(
            Product,
            "SELECT * FROM products WHERE id = ?",
            id
        )
        .fetch_optional(&self.pool)
        .await?;

        Ok(product)
    }

    async fn find_by_vendor(&self, vendor_id: &str) -> Result<Vec<Product>> {
        let products = sqlx::query_as!(
            Product,
            "SELECT * FROM products WHERE vendor_id = ? ORDER BY collected_at DESC",
            vendor_id
        )
        .fetch_all(&self.pool)
        .await?;

        Ok(products)
    }

    // ... ë‹¤ë¥¸ ë©”ì„œë“œë“¤ êµ¬í˜„
}
```

**11ì¼ì°¨: HTTP í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„**
```rust
// src-tauri/src/infrastructure/http/client.rs
use reqwest::{Client, ClientBuilder, Response};
use anyhow::Result;
use std::time::Duration;
use tokio::time;

pub struct HttpClient {
    client: Client,
    rate_limiter: RateLimiter,
}

impl HttpClient {
    pub fn new(
        timeout: Duration,
        max_requests_per_second: u32,
    ) -> Result<Self> {
        let client = ClientBuilder::new()
            .timeout(timeout)
            .user_agent("MatterCertis/2.0")
            .gzip(true)
            .build()?;

        let rate_limiter = RateLimiter::new(max_requests_per_second);

        Ok(Self {
            client,
            rate_limiter,
        })
    }

    pub async fn get(&self, url: &str) -> Result<Response> {
        self.rate_limiter.wait().await;
        
        let response = self.client
            .get(url)
            .send()
            .await?;

        if !response.status().is_success() {
            anyhow::bail!("HTTP request failed: {}", response.status());
        }

        Ok(response)
    }
}
```

#### Week 2.2: Use Cases ë° Application ê³„ì¸µ (3-4ì¼)

**12ì¼ì°¨: ê¸°ë³¸ Use Cases êµ¬í˜„**
```rust
// src-tauri/src/application/use_cases/mod.rs
pub mod manage_vendors;
pub mod start_crawling;
pub mod get_products;

pub use manage_vendors::*;
pub use start_crawling::*;
pub use get_products::*;
```

```rust
// src-tauri/src/application/use_cases/manage_vendors.rs
use crate::domain::{entities::Vendor, repositories::VendorRepository};
use anyhow::Result;
use std::sync::Arc;

pub struct ManageVendorsUseCase {
    vendor_repository: Arc<dyn VendorRepository>,
}

impl ManageVendorsUseCase {
    pub fn new(vendor_repository: Arc<dyn VendorRepository>) -> Self {
        Self { vendor_repository }
    }

    pub async fn create_vendor(&self, vendor: Vendor) -> Result<()> {
        self.vendor_repository.save(&vendor).await
    }

    pub async fn get_all_vendors(&self) -> Result<Vec<Vendor>> {
        self.vendor_repository.find_all().await
    }

    pub async fn update_vendor(&self, vendor: Vendor) -> Result<()> {
        self.vendor_repository.update(&vendor).await
    }

    pub async fn delete_vendor(&self, id: &str) -> Result<()> {
        self.vendor_repository.delete(id).await
    }
}
```

**13ì¼ì°¨: Tauri Commands ê¸°ë³¸ êµ¬ì¡°**
```rust
// src-tauri/src/commands/mod.rs
pub mod vendor_commands;
pub mod crawling_commands;
pub mod product_commands;

pub use vendor_commands::*;
pub use crawling_commands::*;
pub use product_commands::*;
```

```rust
// src-tauri/src/commands/vendor_commands.rs
use tauri::State;
use crate::application::use_cases::ManageVendorsUseCase;
use crate::domain::entities::Vendor;
use anyhow::Result;

#[tauri::command]
pub async fn create_vendor(
    vendor: Vendor,
    use_case: State<'_, ManageVendorsUseCase>,
) -> Result<(), String> {
    use_case
        .create_vendor(vendor)
        .await
        .map_err(|e| e.to_string())
}

#[tauri::command]
pub async fn get_all_vendors(
    use_case: State<'_, ManageVendorsUseCase>,
) -> Result<Vec<Vendor>, String> {
    use_case
        .get_all_vendors()
        .await
        .map_err(|e| e.to_string())
}
```

**14ì¼ì°¨: ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê´€ë¦¬ ë° ì˜ì¡´ì„± ì£¼ì…**
```rust
// src-tauri/src/lib.rs
use tauri::Manager;
use std::sync::Arc;

pub mod domain;
pub mod application;
pub mod infrastructure;
pub mod commands;

use infrastructure::database::DatabaseConnection;
use infrastructure::database::repositories::*;
use application::use_cases::*;

pub struct AppState {
    pub database: Arc<DatabaseConnection>,
    pub manage_vendors_use_case: Arc<ManageVendorsUseCase>,
    // ... ë‹¤ë¥¸ use cases
}

impl AppState {
    pub async fn new() -> anyhow::Result<Self> {
        // ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        let database = Arc::new(
            DatabaseConnection::new("sqlite://data/matter_certis.db").await?
        );
        
        // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        database.migrate().await?;

        // Repository ìƒì„±
        let vendor_repository = Arc::new(
            VendorRepositoryImpl::new(database.pool().clone())
        );

        // Use Case ìƒì„±
        let manage_vendors_use_case = Arc::new(
            ManageVendorsUseCase::new(vendor_repository)
        );

        Ok(Self {
            database,
            manage_vendors_use_case,
        })
    }
}
```

### ğŸ“‹ Week 2 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì™„ë£Œ
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] Repository êµ¬í˜„ ì™„ë£Œ
- [ ] HTTP í´ë¼ì´ì–¸íŠ¸ ê¸°ë³¸ êµ¬í˜„
- [ ] ê¸°ë³¸ Use Cases êµ¬í˜„
- [ ] Tauri Commands ê¸°ë³¸ êµ¬ì¡° ì™„ì„±
- [ ] ì˜ì¡´ì„± ì£¼ì… ì„¤ì • ì™„ë£Œ

---

## ğŸ“… Phase 3: í¬ë¡¤ë§ ì—”ì§„ êµ¬í˜„ (2ì£¼)

### ğŸ¯ ëª©í‘œ
- reqwest ê¸°ë°˜ í¬ë¡¤ë§ ì—”ì§„ êµ¬í˜„
- HTML íŒŒì‹± ë° ë°ì´í„° ì¶”ì¶œ
- ë³‘ë ¬ ì²˜ë¦¬ ë° Rate Limiting
- ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸

### ğŸ“‹ ì‘ì—… ëª©ë¡

#### Week 3.1: í¬ë¡¤ë§ ì—”ì§„ í•µì‹¬ êµ¬í˜„ (3-4ì¼)

**15ì¼ì°¨: í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ë„ë©”ì¸ êµ¬í˜„**
```rust
// src-tauri/src/domain/services/crawling_service.rs
use async_trait::async_trait;
use crate::domain::entities::{CrawlingSession, Product, Vendor};
use anyhow::Result;

#[async_trait]
pub trait CrawlingService: Send + Sync {
    async fn start_crawling(&self, vendor: &Vendor) -> Result<CrawlingSession>;
    async fn pause_crawling(&self, session_id: &str) -> Result<()>;
    async fn resume_crawling(&self, session_id: &str) -> Result<()>;
    async fn stop_crawling(&self, session_id: &str) -> Result<()>;
    async fn get_crawling_progress(&self, session_id: &str) -> Result<CrawlingProgress>;
}

#[derive(Debug, Clone)]
pub struct CrawlingProgress {
    pub session_id: String,
    pub total_pages: Option<u32>,
    pub processed_pages: u32,
    pub products_found: u32,
    pub errors_count: u32,
    pub current_url: Option<String>,
    pub status: CrawlingStatus,
}
```

**16ì¼ì°¨: HTML íŒŒì‹± êµ¬í˜„**
```rust
// src-tauri/src/infrastructure/crawling/mod.rs
pub mod html_parser;
pub mod product_extractor;
pub mod crawler_engine;

pub use html_parser::*;
pub use product_extractor::*;
pub use crawler_engine::*;
```

```rust
// src-tauri/src/infrastructure/crawling/html_parser.rs
use scraper::{Html, Selector};
use anyhow::Result;
use crate::domain::entities::{Product, CrawlingConfig};

pub struct HtmlParser {
    config: CrawlingConfig,
}

impl HtmlParser {
    pub fn new(config: CrawlingConfig) -> Self {
        Self { config }
    }

    pub fn extract_products(&self, html: &str, base_url: &str, vendor_id: &str) -> Result<Vec<Product>> {
        let document = Html::parse_document(html);
        let mut products = Vec::new();

        // ì œí’ˆ ì»¨í…Œì´ë„ˆ ì„ íƒì
        let container_selector = Selector::parse(&self.config.selectors.product_container)
            .map_err(|e| anyhow::anyhow!("Invalid container selector: {}", e))?;

        // ê° ì œí’ˆ ìš”ì†Œì— ëŒ€í•´ ë°ì´í„° ì¶”ì¶œ
        for element in document.select(&container_selector) {
            if let Ok(product) = self.extract_single_product(element, base_url, vendor_id) {
                products.push(product);
            }
        }

        Ok(products)
    }

    fn extract_single_product(
        &self,
        element: scraper::ElementRef,
        base_url: &str,
        vendor_id: &str,
    ) -> Result<Product> {
        // ì œí’ˆëª… ì¶”ì¶œ
        let name_selector = Selector::parse(&self.config.selectors.name)?;
        let name = element
            .select(&name_selector)
            .next()
            .and_then(|e| e.text().next())
            .ok_or_else(|| anyhow::anyhow!("Product name not found"))?
            .trim()
            .to_string();

        // ê°€ê²© ì¶”ì¶œ
        let price_selector = Selector::parse(&self.config.selectors.price)?;
        let price = element
            .select(&price_selector)
            .next()
            .and_then(|e| e.text().next())
            .and_then(|text| self.parse_price(text));

        // ì œí’ˆ URL ì¶”ì¶œ
        let product_url = if let Some(url_selector) = &self.config.selectors.product_url {
            let selector = Selector::parse(url_selector)?;
            element
                .select(&selector)
                .next()
                .and_then(|e| e.value().attr("href"))
                .map(|href| self.resolve_url(base_url, href))
                .unwrap_or_else(|| base_url.to_string())
        } else {
            base_url.to_string()
        };

        // ì´ë¯¸ì§€ URL ì¶”ì¶œ
        let image_url = if let Some(img_selector) = &self.config.selectors.image_url {
            let selector = Selector::parse(img_selector)?;
            element
                .select(&selector)
                .next()
                .and_then(|e| e.value().attr("src").or_else(|| e.value().attr("data-src")))
                .map(|src| self.resolve_url(base_url, src))
        } else {
            None
        };

        // ì¬ê³  ìƒíƒœ í™•ì¸
        let in_stock = if let Some(stock_selector) = &self.config.selectors.in_stock {
            let selector = Selector::parse(stock_selector)?;
            element.select(&selector).next().is_some()
        } else {
            true // ê¸°ë³¸ê°’: ì¬ê³  ìˆìŒ
        };

        let mut product = Product::new(name, product_url, vendor_id.to_string());
        product.price = price;
        product.image_url = image_url;
        product.in_stock = in_stock;

        Ok(product)
    }

    fn parse_price(&self, price_text: &str) -> Option<f64> {
        // ê°€ê²© í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ
        let cleaned = price_text
            .chars()
            .filter(|c| c.is_ascii_digit() || *c == '.' || *c == ',')
            .collect::<String>()
            .replace(',', "");

        cleaned.parse().ok()
    }

    fn resolve_url(&self, base_url: &str, relative_url: &str) -> String {
        if relative_url.starts_with("http") {
            relative_url.to_string()
        } else if relative_url.starts_with("//") {
            format!("https:{}", relative_url)
        } else if relative_url.starts_with('/') {
            let base = url::Url::parse(base_url).unwrap();
            format!("{}://{}{}", base.scheme(), base.host_str().unwrap(), relative_url)
        } else {
            format!("{}/{}", base_url.trim_end_matches('/'), relative_url)
        }
    }
}
```

**17ì¼ì°¨: í¬ë¡¤ë§ ì—”ì§„ êµ¬í˜„**
```rust
// src-tauri/src/infrastructure/crawling/crawler_engine.rs
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex};
use futures::stream::{self, StreamExt};
use anyhow::Result;

use crate::domain::{
    entities::{Vendor, Product, CrawlingSession, CrawlingStatus},
    repositories::{ProductRepository, CrawlingSessionRepository},
    services::CrawlingService,
};
use crate::infrastructure::http::HttpClient;
use super::HtmlParser;

pub struct CrawlerEngine {
    http_client: Arc<HttpClient>,
    product_repository: Arc<dyn ProductRepository>,
    session_repository: Arc<dyn CrawlingSessionRepository>,
    progress_sender: Arc<Mutex<Option<mpsc::UnboundedSender<CrawlingProgress>>>>,
}

impl CrawlerEngine {
    pub fn new(
        http_client: Arc<HttpClient>,
        product_repository: Arc<dyn ProductRepository>,
        session_repository: Arc<dyn CrawlingSessionRepository>,
    ) -> Self {
        Self {
            http_client,
            product_repository,
            session_repository,
            progress_sender: Arc::new(Mutex::new(None)),
        }
    }

    pub async fn crawl_vendor(&self, vendor: &Vendor) -> Result<CrawlingSession> {
        let mut session = CrawlingSession::new(vendor.id.clone());
        session.status = CrawlingStatus::Running;
        
        // ì„¸ì…˜ ì €ì¥
        self.session_repository.save(&session).await?;

        // í˜ì´ì§€ URL ìƒì„±
        let page_urls = self.generate_page_urls(vendor)?;
        session.total_pages = Some(page_urls.len() as u32);
        self.session_repository.update(&session).await?;

        // ë³‘ë ¬ í¬ë¡¤ë§ ì‹¤í–‰
        let max_concurrent = vendor.crawling_config.max_concurrent_requests;
        let parser = HtmlParser::new(vendor.crawling_config.clone());

        let results = stream::iter(page_urls)
            .map(|url| {
                let http_client = self.http_client.clone();
                let parser = parser.clone();
                let vendor_id = vendor.id.clone();
                
                async move {
                    self.crawl_single_page(&http_client, &parser, &url, &vendor_id).await
                }
            })
            .buffer_unordered(max_concurrent as usize)
            .collect::<Vec<_>>()
            .await;

        // ê²°ê³¼ ì²˜ë¦¬
        let mut total_products = 0;
        let mut errors = 0;

        for result in results {
            match result {
                Ok(products) => {
                    for product in products {
                        if let Err(e) = self.product_repository.save(&product).await {
                            tracing::error!("Failed to save product: {}", e);
                            errors += 1;
                        } else {
                            total_products += 1;
                        }
                    }
                }
                Err(e) => {
                    tracing::error!("Failed to crawl page: {}", e);
                    errors += 1;
                }
            }

            // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            session.processed_pages += 1;
            session.products_found = total_products;
            session.errors_count = errors;
            self.session_repository.update(&session).await?;

            // ì§„í–‰ ìƒí™© ì´ë²¤íŠ¸ ë°œì†¡
            self.send_progress_update(&session).await;
        }

        // ì„¸ì…˜ ì™„ë£Œ
        session.status = CrawlingStatus::Completed;
        session.completed_at = Some(chrono::Utc::now());
        self.session_repository.update(&session).await?;

        Ok(session)
    }

    async fn crawl_single_page(
        &self,
        http_client: &HttpClient,
        parser: &HtmlParser,
        url: &str,
        vendor_id: &str,
    ) -> Result<Vec<Product>> {
        // HTTP ìš”ì²­
        let response = http_client.get(url).await?;
        let html = response.text().await?;

        // HTML íŒŒì‹± ë° ì œí’ˆ ì¶”ì¶œ
        let products = parser.extract_products(&html, url, vendor_id)?;

        // ë”œë ˆì´ ì ìš© (Rate Limitingì€ HttpClientì—ì„œ ì²˜ë¦¬)
        Ok(products)
    }

    fn generate_page_urls(&self, vendor: &Vendor) -> Result<Vec<String>> {
        let mut urls = vec![vendor.base_url.clone()];

        // í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì •ì´ ìˆëŠ” ê²½ìš°
        if let Some(pagination) = &vendor.crawling_config.pagination {
            if let Some(max_pages) = vendor.crawling_config.max_pages {
                for page in 2..=max_pages {
                    let url = pagination.url_pattern
                        .replace("{page}", &page.to_string());
                    urls.push(url);
                }
            }
        }

        Ok(urls)
    }

    async fn send_progress_update(&self, session: &CrawlingSession) {
        let progress = CrawlingProgress {
            session_id: session.id.clone(),
            total_pages: session.total_pages,
            processed_pages: session.processed_pages,
            products_found: session.products_found,
            errors_count: session.errors_count,
            current_url: None,
            status: session.status.clone(),
        };

        if let Ok(sender_guard) = self.progress_sender.try_lock() {
            if let Some(sender) = sender_guard.as_ref() {
                let _ = sender.send(progress);
            }
        }
    }
}
```

**18ì¼ì°¨: Rate Limiter êµ¬í˜„**
```rust
// src-tauri/src/infrastructure/http/rate_limiter.rs
use std::time::{Duration, Instant};
use tokio::time;

pub struct RateLimiter {
    max_requests_per_second: u32,
    last_request_time: std::sync::Mutex<Option<Instant>>,
}

impl RateLimiter {
    pub fn new(max_requests_per_second: u32) -> Self {
        Self {
            max_requests_per_second,
            last_request_time: std::sync::Mutex::new(None),
        }
    }

    pub async fn wait(&self) {
        if self.max_requests_per_second == 0 {
            return;
        }

        let min_interval = Duration::from_millis(1000 / self.max_requests_per_second as u64);
        
        let should_wait = {
            let mut last_time = self.last_request_time.lock().unwrap();
            let now = Instant::now();
            
            let should_wait = if let Some(last) = *last_time {
                let elapsed = now.duration_since(last);
                if elapsed < min_interval {
                    Some(min_interval - elapsed)
                } else {
                    None
                }
            } else {
                None
            };
            
            *last_time = Some(now);
            should_wait
        };

        if let Some(wait_duration) = should_wait {
            time::sleep(wait_duration).await;
        }
    }
}
```

#### Week 3.2: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ë° ìµœì í™” (3-4ì¼)

**19ì¼ì°¨: Tauri ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„**
```rust
// src-tauri/src/commands/crawling_commands.rs
use tauri::{State, Window};
use tokio::sync::mpsc;
use std::sync::Arc;

use crate::application::use_cases::StartCrawlingUseCase;
use crate::domain::entities::Vendor;
use crate::infrastructure::crawling::CrawlingProgress;

#[tauri::command]
pub async fn start_crawling_session(
    vendor_id: String,
    window: Window,
    use_case: State<'_, StartCrawlingUseCase>,
) -> Result<String, String> {
    // ì§„í–‰ ìƒí™© ì±„ë„ ìƒì„±
    let (tx, mut rx) = mpsc::unbounded_channel::<CrawlingProgress>();
    
    // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ ìƒí™© ì´ë²¤íŠ¸ ì „ì†¡
    let window_clone = window.clone();
    tokio::spawn(async move {
        while let Some(progress) = rx.recv().await {
            let _ = window_clone.emit("crawling-progress", &progress);
        }
    });

    // í¬ë¡¤ë§ ì‹œì‘
    let session = use_case
        .start_crawling(&vendor_id, Some(tx))
        .await
        .map_err(|e| e.to_string())?;

    Ok(session.id)
}

#[tauri::command]
pub async fn pause_crawling_session(
    session_id: String,
    use_case: State<'_, StartCrawlingUseCase>,
) -> Result<(), String> {
    use_case
        .pause_crawling(&session_id)
        .await
        .map_err(|e| e.to_string())
}

#[tauri::command]
pub async fn get_crawling_progress(
    session_id: String,
    use_case: State<'_, StartCrawlingUseCase>,
) -> Result<CrawlingProgress, String> {
    use_case
        .get_crawling_progress(&session_id)
        .await
        .map_err(|e| e.to_string())
}
```

**20ì¼ì°¨: TypeScript ì„œë¹„ìŠ¤ ë ˆì´ì–´**
```typescript
// src/services/crawling-service.ts
import { invoke } from '@tauri-apps/api/tauri';
import { listen, UnlistenFn } from '@tauri-apps/api/event';
import { CrawlingProgress } from '../types/domain';

export class CrawlingService {
  private progressListeners: Set<(progress: CrawlingProgress) => void> = new Set();
  private unlistenFn: UnlistenFn | null = null;

  async startCrawling(vendorId: string): Promise<string> {
    return await invoke('start_crawling_session', { vendorId });
  }

  async pauseCrawling(sessionId: string): Promise<void> {
    return await invoke('pause_crawling_session', { sessionId });
  }

  async resumeCrawling(sessionId: string): Promise<void> {
    return await invoke('resume_crawling_session', { sessionId });
  }

  async getCrawlingProgress(sessionId: string): Promise<CrawlingProgress> {
    return await invoke('get_crawling_progress', { sessionId });
  }

  async subscribeToProgress(callback: (progress: CrawlingProgress) => void): Promise<void> {
    this.progressListeners.add(callback);

    if (!this.unlistenFn) {
      this.unlistenFn = await listen('crawling-progress', (event) => {
        const progress = event.payload as CrawlingProgress;
        this.progressListeners.forEach(listener => listener(progress));
      });
    }
  }

  unsubscribeFromProgress(callback: (progress: CrawlingProgress) => void): void {
    this.progressListeners.delete(callback);

    if (this.progressListeners.size === 0 && this.unlistenFn) {
      this.unlistenFn();
      this.unlistenFn = null;
    }
  }
}

export const crawlingService = new CrawlingService();
```

**21ì¼ì°¨: ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜**
```rust
// src-tauri/src/infrastructure/crawling/error_handler.rs
use std::time::Duration;
use tokio::time;
use anyhow::Result;

pub struct ErrorHandler {
    max_retries: u32,
    base_delay: Duration,
}

impl ErrorHandler {
    pub fn new(max_retries: u32, base_delay: Duration) -> Self {
        Self {
            max_retries,
            base_delay,
        }
    }

    pub async fn retry_with_backoff<F, T, E>(&self, mut operation: F) -> Result<T>
    where
        F: FnMut() -> Result<T, E>,
        E: std::fmt::Display,
    {
        let mut last_error = None;

        for attempt in 0..=self.max_retries {
            match operation() {
                Ok(result) => return Ok(result),
                Err(e) => {
                    tracing::warn!("Attempt {} failed: {}", attempt + 1, e);
                    last_error = Some(e);

                    if attempt < self.max_retries {
                        let delay = self.base_delay * (2_u32.pow(attempt));
                        time::sleep(delay).await;
                    }
                }
            }
        }

        Err(anyhow::anyhow!(
            "Operation failed after {} attempts. Last error: {}",
            self.max_retries + 1,
            last_error.map(|e| e.to_string()).unwrap_or_else(|| "Unknown error".to_string())
        ))
    }
}
```

### ğŸ“‹ Week 3 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ë„ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- [ ] HTML íŒŒì‹± ë° ë°ì´í„° ì¶”ì¶œ êµ¬í˜„
- [ ] reqwest ê¸°ë°˜ í¬ë¡¤ë§ ì—”ì§„ êµ¬í˜„
- [ ] Rate Limiter êµ¬í˜„
- [ ] ë³‘ë ¬ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„
- [ ] ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ
- [ ] TypeScript ì„œë¹„ìŠ¤ ë ˆì´ì–´ êµ¬í˜„
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜

---

ì´ì œ Phase 4 (í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„)ì™€ Phase 5 (í†µí•© í…ŒìŠ¤íŠ¸ ë° ìµœì í™”)ì— ëŒ€í•œ ê°€ì´ë“œë¥¼ ê³„ì† ì‘ì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
