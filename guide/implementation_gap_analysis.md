# 아키텍처 설계-구현 차이 분석 (Gap Analysis)

이 문서는 `event-driven-crawling-architecture` v2, v3, v4에서 설계된 내용과 현재 `src/crawling` 모듈에 구현된 코드베이스 간의 차이점을 분석하고, 목표 아키텍처 달성을 위한 구체적인 개선 방안을 제안합니다.

--- 

## 1. 종합 평가

현재 `src/crawling` 모듈의 구현은 v2.0 아키텍처의 핵심 골격을 매우 훌륭하게 따르고 있습니다. **작업(Task), 큐(Queue), 작업자(Worker), 오케스트레이터(Orchestrator)로 역할을 명확히 분리**한 구조는 설계 의도를 잘 반영하고 있으며, 확장 가능한 시스템의 훌륭한 기반을 마련했습니다.

하지만, 목표로 하는 **v3.0(지능형 적응 제어) 및 v4.0(통합 시각화)** 아키텍처에 도달하기 위해서는 몇 가지 중요한 기능들이 누락되어 있거나, 설계와 다른 방향으로 단순화되어 구현된 부분이 존재합니다.

## 2. 주요 차이점 및 개선 제안

### 2.1. 오류 처리 및 재시도 메커니즘

-   **설계 (v2.0+):**
    -   **계층적 재시도 정책:** 실패 종류에 따라 다른 재시도 전략(지수 백오프, 지터) 적용.
    -   **회로 차단기 (Circuit Breaker):** 특정 작업(예: 특정 도메인으로의 HTTP 요청)이 계속 실패할 경우, 해당 작업을 일시적으로 중단하여 시스템 전체 부하를 줄임.
    -   **Dead Letter Queue:** 최종적으로 실패한 작업을 별도 큐에 모아 추후 분석 및 수동 처리가 가능하도록 함.

-   **현재 구현 (`orchestrator.rs`):**
    -   단순 재시도 로직만 존재하며, `config.max_retries` 횟수만큼 즉시 재시도하는 형태로 구현되어 있습니다.
    -   지수 백오프, 회로 차단기, Dead Letter Queue 개념이 아직 구현되지 않았습니다.

-   **Gap 및 영향:**
    -   특정 사이트의 일시적인 문제 발생 시, 짧은 시간 동안 반복적인 요청을 보내 시스템에 불필요한 부하를 유발하고 해당 사이트로부터 차단될 위험이 있습니다.
    -   영구적으로 실패하는 작업을 식별하고 격리하는 메커니즘이 없어, 문제 해결 및 원인 분석이 어렵습니다.

-   **대안 및 개선 제안:**
    1.  **`RetryManager` 도입:** `retry_manager.rs` 모듈을 신설하고, 재시도 정책과 회로 차단기 로직을 중앙에서 관리하는 구조체를 만듭니다.
    2.  **작업자 루프 수정:** 작업 실패 시, 즉시 재시도하는 대신 `RetryManager`에게 실패한 작업을 전달합니다. `RetryManager`는 재시도 정책에 따라 적절한 지연 후 다시 원래 큐에 작업을 넣거나, 회로 차단기 정책에 따라 작업을 중단/격리시킵니다.
    3.  **`QueueManager` 확장:** `dead_letter_queue`를 추가하고, 최대 재시도 횟수를 초과한 작업을 이 큐로 보내는 로직을 `RetryManager`에 구현합니다.

### 2.2. 백프레셔 및 리소스 관리

-   **설계 (v2.0+):**
    -   **Bounded Channels:** `mpsc::channel(capacity)`를 사용하여 큐의 최대 용량을 제한하고, 큐가 가득 찼을 때 작업을 보내는 쪽(Producer)이 대기하도록 하여(백프레셔), 메모리 사용량을 제어합니다.
    -   **다층 세마포어:** HTTP, CPU, DB 등 리소스 종류별로 동시 실행 수를 제어하는 세마포어를 `ResourceManager`에 둡니다.

-   **현재 구현 (`queues.rs`, `orchestrator.rs`):**
    -   `QueueManager`가 각 큐를 `TaskQueue`로 감싸고 있지만, `tokio::sync::mpsc`의 기본 채널을 사용하며 용량 제한(capacity)이 매우 크거나(10,000) 명시적인 백프레셔 제어 로직이 부족합니다.
    -   `Orchestrator`에 `global_semaphore`가 존재하지만, 이는 전체 작업의 동시 실행 수만 제어할 뿐, HTTP 요청이나 DB 작업과 같은 특정 리소스 유형별 제어는 이루어지지 않고 있습니다.

-   **Gap 및 영향:**
    -   특정 단계(예: 파싱)의 처리 속도가 다른 단계(예: HTTP 요청)보다 현저히 느릴 경우, 중간 단계의 큐에 작업이 계속 쌓여 메모리 사용량이 무한정 증가할 수 있습니다.
    -   모든 종류의 작업을 단일 세마포어로 제어하므로, CPU 집약적인 파싱 작업 10개와 I/O 집약적인 HTTP 요청 작업 10개가 동일한 리소스 제한을 공유하여 비효율적입니다.

-   **대안 및 개선 제안:**
    1.  **`BoundedWorkQueue` 구현:** `queues.rs`의 `TaskQueue`를 수정하여, `mpsc::channel` 생성 시 `config.max_capacity`를 명시적으로 사용하고, `enqueue` 시 `try_send` 실패 시 `send`로 전환하여 백프레셔를 자연스럽게 적용하는 로직을 강화합니다.
    2.  **`ResourceManager` 도입:** `resource_manager.rs` 모듈을 신설하고, `http_semaphore`, `cpu_bound_semaphore` 등을 포함하는 구조체를 만듭니다. `SharedState`에 이를 추가합니다.
    3.  **작업자 수정:** 각 작업자는 자신의 작업 유형에 맞는 세마포어의 허가(`permit`)를 받은 후에만 실제 로직을 실행하도록 수정합니다. (예: `ListPageFetcher`는 `http_semaphore` 사용)

### 2.3. 예측 분석 및 동적 제어

-   **설계 (v3.0+):**
    -   **`PredictiveAnalyticsEngine`:** 모든 작업의 실행 시간을 측정/기록하고, 이를 바탕으로 전체 완료 시간을 예측합니다.
    -   **`UserDrivenProfileManager`:** 사용자가 선택한 운영 프로파일(성능, 균형, 절약)에 따라 시스템의 동시성, 큐 크기 등 파라미터를 동적으로 변경합니다.
    -   **`AdaptiveWorkerPool`:** 시스템 상태에 따라 작업자 수를 자동으로 조절합니다.

-   **현재 구현:**
    -   이 부분은 **전체적으로 누락**되어 있습니다. 현재 통계(`CrawlingStats`)는 수집된 작업의 수를 세는 카운터 역할만 수행하며, 예측이나 동적 제어 로직은 포함되어 있지 않습니다.

-   **Gap 및 영향:**
    -   사용자는 작업이 언제 끝날지 알 수 없으며, 시스템의 성능과 안정성 사이에서 트레이드오프를 선택할 수 없습니다. 이는 v3.0, v4.0 아키텍처의 핵심 목표와 가장 큰 차이를 보이는 부분입니다.

-   **대안 및 개선 제안:**
    1.  **v3.0 구현 로드맵 착수:** 설계 문서(v3.0)에 제안된 구현 로드맵에 따라, **Phase 1: 데이터 수집 기반 구축**부터 시작합니다.
    2.  `Task` 정의에 `started_at`, `completed_at` 필드를 추가하고, 작업자 루프에서 시간을 측정하여 `CrawlingStats`에 작업 유형별 평균 처리 시간을 기록하는 로직을 추가합니다.
    3.  이를 기반으로 가장 기본적인 ETA(남은 작업 수 * 평균 처리 시간) 계산 로직을 `Orchestrator`에 추가하고, 이 정보를 `SystemStatePayload`를 통해 UI로 전달하는 것부터 시작합니다.

### 2.4. UI 통합 인터페이스

-   **설계 (v4.0):**
    -   백엔드는 모든 시스템 상태를 종합한 단일 구조체 `SystemStatePayload`를 주기적으로 프론트엔드에 `emit`합니다.
    -   프론트엔드는 이 단일 객체에만 의존하여 모든 UI를 렌더링합니다.

-   **현재 구현 (`crawling_v4.rs`):**
    -   `SystemStatePayload` 구조체가 정의되어 있고, `broadcast_real_time_stats` 함수를 통해 주기적으로 이벤트를 보내는 구조가 구현되어 있습니다. **이 부분은 설계와 매우 유사하게 잘 구현되어 있습니다.**
    -   다만, `SystemStatePayload`에 담기는 내용이 아직은 단순 카운터 값이며, 예측이나 동적 설정 상태와 같은 v3.0+의 정보는 빠져있습니다.

-   **Gap 및 영향:**
    -   현재 인터페이스로는 설계된 `CrawlingCityDashboard`의 동적인 모습(작업자 수 변경, ETA 표시 등)을 완전히 표현할 수 없습니다.

-   **대안 및 개선 제안:**
    1.  **Payload 확장:** 위의 2.3 개선 제안이 진행됨에 따라, `SystemStatePayload`에 `prediction`, `activeProfile`, `resourceUsage` 등의 필드를 점진적으로 추가합니다.
    2.  **커맨드 추가:** `set_operating_profile`과 같은 사용자 제어 커맨드를 `crawling_v4.rs`에 추가하여, UI에서 시스템 동작을 변경할 수 있는 통로를 마련합니다.

--- 

## 3. 결론 및 다음 단계 제안

현재 구현은 이벤트 기반 아키텍처의 훌륭한 출발점입니다. 이제 시스템을 **더욱 견고하고(Robust), 지능적으로(Intelligent)** 만들기 위한 다음 단계로 나아갈 때입니다.

**권장 다음 단계:**

1.  **1순위 (견고성 강화):** **오류 처리 및 재시도 메커니즘**을 설계에 맞게 고도화합니다. `RetryManager`와 회로 차단기, Dead Letter Queue의 기본 개념을 도입하여 시스템의 안정성을 대폭 향상시킵니다.
2.  **2순위 (안정성 확보):** **백프레셔 및 리소스 관리**를 강화합니다. Bounded Channel의 용량을 명확히 설정하고, 리소스 종류별 세마포어를 도입하여 메모리 문제를 예방하고 리소스 사용을 최적화합니다.
3.  **3순위 (지능화 시작):** **예측 분석 기능의 첫 단계를 구현**합니다. 작업별 실행 시간을 측정하고 기록하는 것부터 시작하여, v3.0 아키텍처 구현의 초석을 다집니다.
