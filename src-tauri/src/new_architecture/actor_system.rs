//! Actor ì‹œìŠ¤í…œ: ì„¸ì…˜, ë°°ì¹˜, ìŠ¤í…Œì´ì§€ ë¶„ë¦¬ êµ¬ì¡°
//! Modern Rust 2024 ì¤€ìˆ˜: ì˜ì¡´ì„± ì£¼ì… ê¸°ë°˜ Actor ì„¤ê³„

#![warn(clippy::all, clippy::pedantic, clippy::nursery)]
#![deny(clippy::unwrap_used, clippy::expect_used, clippy::panic)]

use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, oneshot, Mutex, Semaphore};
use tokio::time::{sleep, timeout};
use tracing::{info, warn, error, debug};
use uuid::Uuid;
use futures::future::join_all;
use serde::Serialize;

// ê°œë³„ ëª¨ë“ˆì—ì„œ ì§ì ‘ import
use crate::new_architecture::system_config::{SystemConfig, ConfigError, RetryPolicy};
use crate::new_architecture::channel_types::{ActorCommand, AppEvent, BatchConfig, StageType, StageItem};
use crate::new_architecture::services::crawling_planner::CrawlingPlanner;
use crate::infrastructure::config::AppConfig;

// ì„ì‹œ íƒ€ì… ì •ì˜ (ì»´íŒŒì¼ ì—ëŸ¬ í•´ê²°ìš©)

#[derive(Debug, Clone, Serialize)]
pub enum StageResult {
    Success(StageSuccessResult),
    Failure(StageError),
    RecoverableError {
        error: StageError,
        attempts: u32,
        stage_id: String,
        suggested_retry_delay_ms: u64,  // Durationì„ u64ë¡œ ë³€ê²½
    },
    FatalError {
        error: StageError,
        stage_id: String,
        context: String,
    },
    PartialSuccess {
        success_items: StageSuccessResult,
        failed_items: Vec<FailedItem>,
        stage_id: String,
    },
}

#[derive(Debug, Clone, Serialize)]
pub enum StageError {
    NetworkError { message: String },
    ParsingError { message: String },
    NetworkTimeout { message: String },
    ValidationError { message: String },
    ChannelError { message: String },
    DatabaseError { message: String },
    ResourceExhausted { message: String },
    ConfigurationError { message: String },
    TaskCancelled { task_id: String },
    TaskExecutionFailed { task_id: String, message: String },
}

impl std::fmt::Display for StageError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            StageError::NetworkError { message } => write!(f, "Network error: {}", message),
            StageError::ParsingError { message } => write!(f, "Parsing error: {}", message),
            StageError::NetworkTimeout { message } => write!(f, "Network timeout: {}", message),
            StageError::ValidationError { message } => write!(f, "Validation error: {}", message),
            StageError::ChannelError { message } => write!(f, "Channel error: {}", message),
            StageError::DatabaseError { message } => write!(f, "Database error: {}", message),
            StageError::ResourceExhausted { message } => write!(f, "Resource exhausted: {}", message),
            StageError::ConfigurationError { message } => write!(f, "Configuration error: {}", message),
            StageError::TaskCancelled { task_id } => write!(f, "Task cancelled: {}", task_id),
            StageError::TaskExecutionFailed { task_id, message } => write!(f, "Task execution failed ({}): {}", task_id, message),
        }
    }
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct StageSuccessResult {
    pub processed_items: u32,
    pub stage_duration_ms: u64,
    pub collection_metrics: Option<CollectionMetrics>,
    pub processing_metrics: Option<ProcessingMetrics>,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct CollectionMetrics {
    pub total_items: u32,
    pub successful_items: u32,
    pub failed_items: u32,
    pub duration_ms: u64,
    pub avg_response_time_ms: u64,
    pub success_rate: f64,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct ProcessingMetrics {
    pub total_processed: u32,
    pub successful_saves: u32,
    pub failed_saves: u32,
    pub duration_ms: u64,
    pub avg_processing_time_ms: u64,
    pub success_rate: f64,
}

#[derive(Debug, Clone)]
pub struct ProductInfo {
    pub id: String,
    pub name: String,
    pub url: String,
}

#[derive(Debug, Clone, Serialize)]
pub struct FailedItem {
    pub item_id: String,
    pub error: StageError,
    pub retry_count: u32,
    pub last_attempt_ms: u64,  // SystemTimeì„ u64ë¡œ ë³€ê²½
}

/// ì¬ì‹œë„ ì •ì±… ê³„ì‚°ê¸°
#[derive(Debug, Clone)]
pub struct RetryCalculator {
    pub max_attempts: u32,
    pub base_delay_ms: u64,
    pub max_delay_ms: u64,
    pub exponential_factor: f64,
    pub jitter_enabled: bool,
}

impl RetryCalculator {
    pub fn new(
        max_attempts: u32,
        base_delay_ms: u64,
        max_delay_ms: u64,
        exponential_factor: f64,
        jitter_enabled: bool,
    ) -> Self {
        Self {
            max_attempts,
            base_delay_ms,
            max_delay_ms,
            exponential_factor,
            jitter_enabled,
        }
    }

    pub fn should_retry(&self, attempts: u32) -> bool {
        attempts < self.max_attempts
    }

    pub fn calculate_delay(&self, attempt: u32) -> u64 {
        if attempt == 0 {
            return self.base_delay_ms;
        }
        let exponential_delay = (self.base_delay_ms as f64) * self.exponential_factor.powi(attempt as i32 - 1);
        let mut delay = exponential_delay as u64;
        delay = delay.min(self.max_delay_ms);
        if self.jitter_enabled {
            let jitter_range = (delay as f64 * 0.25) as u64;
            let jitter = fastrand::u64(0..=jitter_range * 2);
            let jitter_offset = jitter.saturating_sub(jitter_range);
            delay = delay.saturating_add(jitter_offset);
        }
        delay
    }

    pub fn is_retryable_error(&self, error: &StageError) -> bool {
        matches!(error, StageError::NetworkError { .. } | StageError::ResourceExhausted { .. } | StageError::NetworkTimeout { .. } | StageError::DatabaseError { .. } | StageError::TaskExecutionFailed { .. })
    }

    pub fn should_retry_with_policy(&self, error: &StageError, attempts: u32) -> bool {
        self.should_retry(attempts) && self.is_retryable_error(error)
    }
}

impl Default for RetryCalculator {
    fn default() -> Self {
        Self::new(3, 100, 5000, 2.0, true)
    }
}

/// ë°°ì¹˜ ì‹¤í–‰ ê³„íš
#[derive(Debug, Clone)]
pub struct BatchPlan {
    pub batch_id: String,
    pub pages: Vec<u32>,
    pub config: BatchConfig,
    pub batch_size: u32,
    pub concurrency_limit: u32,
}

/// Actor ì‹œìŠ¤í…œ ì˜¤ë¥˜ íƒ€ì…
#[derive(Debug, thiserror::Error)]
pub enum ActorError {
    #[error("Session timeout: {session_id} after {elapsed:?}")]
    SessionTimeout { session_id: String, elapsed: Duration },
    #[error("Batch processing failed: {batch_id} - {cause}")]
    BatchFailed { batch_id: String, cause: String },
    #[error("Stage execution error: {stage:?} - {message}")]
    StageError { stage: StageType, message: String },
    #[error("Channel communication error: {0}")]
    ChannelError(String),
    #[error("Configuration error: {0}")]
    ConfigError(#[from] ConfigError),
    #[error("Timeout error: {0}")]
    TimeoutError(String),
    #[error("Processing error: {0}")]
    ProcessingError(String),
    #[error("Configuration error: {0}")]
    ConfigurationError(String),
}

/// SessionActor - ì„¸ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬
pub struct SessionActor {
    session_id: String,
    config: Arc<SystemConfig>,
    command_rx: mpsc::Receiver<ActorCommand>,
    event_tx: mpsc::Sender<AppEvent>,
    batch_actors: Vec<BatchActor>,
    start_time: Instant,
    crawling_planner: Option<Arc<CrawlingPlanner>>,
}

impl SessionActor {
    pub fn new(
        config: Arc<SystemConfig>,
        command_rx: mpsc::Receiver<ActorCommand>,
        event_tx: mpsc::Sender<AppEvent>,
    ) -> Self {
        let session_id = Uuid::new_v4().to_string();
        Self {
            session_id,
            config,
            command_rx,
            event_tx,
            batch_actors: Vec::new(),
            start_time: Instant::now(),
            crawling_planner: None, // ë‚˜ì¤‘ì— ì„¤ì •
        }
    }

    /// CrawlingPlanner ì„¤ì • (ì˜ì¡´ì„± ì£¼ì…)
    pub fn with_planner(mut self, planner: Arc<CrawlingPlanner>) -> Self {
        self.crawling_planner = Some(planner);
        self
    }

    pub async fn spawn_and_wait_for_batch(
        &mut self, 
        batch_plan: BatchPlan
    ) -> Result<StageResult, ActorError> {
        self.spawn_and_wait_for_batch_internal(batch_plan).await
    }

    async fn spawn_and_wait_for_batch_internal(
        &mut self, 
        batch_plan: BatchPlan
    ) -> Result<StageResult, ActorError> {
        info!(
            session_id = %self.session_id, 
            batch_id = %batch_plan.batch_id,
            pages_count = batch_plan.pages.len(),
            "Spawning BatchActor with OneShot channel"
        );
        let (data_tx, data_rx) = oneshot::channel::<StageResult>();
        let (control_tx, control_rx) = mpsc::channel::<ActorCommand>(32);
        let batch_actor = BatchActor::new(
            batch_plan.batch_id.clone(),
            self.config.clone(),
            self.event_tx.clone(),
        );
        let handle = tokio::spawn(async move {
            batch_actor.run_with_oneshot(control_rx, data_tx).await
        });
        let command = ActorCommand::ProcessBatch {
            pages: batch_plan.pages,
            config: batch_plan.config,
            batch_size: batch_plan.batch_size,
            concurrency_limit: batch_plan.concurrency_limit,
        };
        if let Err(e) = control_tx.send(command).await {
            handle.abort();
            return Err(ActorError::ChannelError(format!("Failed to send batch command: {}", e)));
        }
        let timeout_duration = Duration::from_secs(self.config.system.session_timeout_secs);
        match timeout(timeout_duration, data_rx).await {
            Ok(Ok(stage_result)) => {
                let _ = handle.await;
                info!(
                    session_id = %self.session_id,
                    batch_id = %batch_plan.batch_id,
                    "BatchActor completed successfully"
                );
                Ok(stage_result)
            }
            Ok(Err(_)) => {
                handle.abort();
                let error = ActorError::ChannelError("BatchActor result channel closed unexpectedly".to_string());
                let event = AppEvent::BatchFailed {
                    batch_id: batch_plan.batch_id.clone(),
                    error: error.to_string(),
                    final_failure: true,
                };
                if let Err(send_err) = self.event_tx.send(event).await {
                    error!(session_id = %self.session_id, error = %send_err, "Failed to send failure event");
                }
                Err(error)
            }
            Err(_) => {
                handle.abort();
                let error = ActorError::TimeoutError(format!("BatchActor timeout after {}s", timeout_duration.as_secs()));
                let event = AppEvent::SessionTimeout {
                    session_id: self.session_id.clone(),
                    elapsed: timeout_duration,
                };
                if let Err(send_err) = self.event_tx.send(event).await {
                    error!(session_id = %self.session_id, error = %send_err, "Failed to send timeout event");
                }
                Err(error)
            }
        }
    }

    pub async fn run(&mut self) -> Result<(), ActorError> {
        info!(session_id = %self.session_id, "ğŸš€ [SessionActor] Starting run loop...");
        let session_timeout = Duration::from_secs(self.config.actor.session_timeout_secs);
        info!(session_id = %self.session_id, timeout_secs = %session_timeout.as_secs(),
              "â° [SessionActor] Session timeout set to {} seconds", session_timeout.as_secs());
        
        loop {
            let elapsed = self.start_time.elapsed();
            if elapsed >= session_timeout {
                let event = AppEvent::SessionTimeout {
                    session_id: self.session_id.clone(),
                    elapsed,
                };
                if let Err(e) = self.event_tx.send(event).await {
                    error!(session_id = %self.session_id, error = %e, "Failed to send timeout event");
                }
                return Err(ActorError::SessionTimeout {
                    session_id: self.session_id.clone(),
                    elapsed,
                });
            }
            
            debug!(session_id = %self.session_id, "ğŸ”„ [SessionActor] Waiting for commands...");
            match timeout(Duration::from_millis(100), self.command_rx.recv()).await {
                Ok(Some(command)) => {
                    info!(session_id = %self.session_id, "ğŸ“¨ [SessionActor] Command received, processing...");
                    if let Err(e) = self.handle_command(command).await {
                        error!(session_id = %self.session_id, error = %e, "Command handling failed");
                        return Err(e);
                    }
                }
                Ok(None) => {
                    info!(session_id = %self.session_id, "ğŸ“ª [SessionActor] Command channel closed, stopping...");
                    break;
                }
                Err(_) => {
                    // íƒ€ì„ì•„ì›ƒ - ì •ìƒì ì¸ í´ë§ ì‚¬ì´í´
                    debug!(session_id = %self.session_id, "â±ï¸ [SessionActor] Command polling timeout (normal)");
                }
            }
        }
        let elapsed = self.start_time.elapsed();
        info!(session_id = %self.session_id, elapsed = ?elapsed, "SessionActor completed");
        Ok(())
    }

    async fn handle_command(&mut self, command: ActorCommand) -> Result<(), ActorError> {
        info!(session_id = %self.session_id, "ğŸ¯ [SessionActor] Received command: {:?}", command);
        
        match command {
            ActorCommand::ProcessBatch { pages, config, batch_size, concurrency_limit } => {
                info!(session_id = %self.session_id, pages_count = pages.len(), batch_size = batch_size,
                      "ğŸ“¥ [SessionActor] ProcessBatch command: {} pages, batch_size {}", pages.len(), batch_size);
                self.process_batch(pages, config, batch_size, concurrency_limit).await
            }
            ActorCommand::CancelSession { session_id, reason } => {
                if session_id == self.session_id {
                    warn!(session_id = %self.session_id, reason = %reason, "Session cancelled");
                    return Err(ActorError::BatchFailed {
                        batch_id: self.session_id.clone(),
                        cause: reason,
                    });
                }
                Ok(())
            }
            _ => {
                warn!(session_id = %self.session_id, "Unsupported command for SessionActor");
                Ok(())
            }
        }
    }

    async fn process_batch(
        &mut self,
        pages: Vec<u32>,
        config: BatchConfig,
        batch_size: u32,
        concurrency_limit: u32,
    ) -> Result<(), ActorError> {
        info!(session_id = %self.session_id, total_pages = pages.len(), batch_size = batch_size,
              "ğŸ§  [SessionActor] Starting intelligent batch planning");

        // CrawlingPlannerê°€ ìˆìœ¼ë©´ ì§€ëŠ¥í˜• ê³„íš ìˆ˜ë¦½, ì—†ìœ¼ë©´ ë‹¨ìˆœ ë¶„í• 
        let batch_plans = if let Some(planner) = &self.crawling_planner {
            info!("âœ… [SessionActor] Using CrawlingPlanner for intelligent batch planning");
            self.create_intelligent_batch_plans(pages, config.clone(), batch_size, concurrency_limit, planner).await?
        } else {
            warn!("âš ï¸ [SessionActor] No CrawlingPlanner available, using simple batch splitting");
            self.create_simple_batch_plans(pages, config.clone(), batch_size, concurrency_limit)
        };

        info!(session_id = %self.session_id, batch_count = batch_plans.len(), 
              "ğŸ“Š [SessionActor] Created {} batch plans", batch_plans.len());

        // ì„¸ì…˜ ì‹œì‘ ì´ë²¤íŠ¸ ë°œì†¡
        let event = AppEvent::SessionStarted {
            session_id: self.session_id.clone(),
            config: config.clone(),
        };
        if let Err(e) = self.event_tx.send(event).await {
            return Err(ActorError::ChannelError(format!("Failed to send session start event: {e}")));
        }

        // ê° ë°°ì¹˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
        let total_batches = batch_plans.len();
        for (index, batch_plan) in batch_plans.into_iter().enumerate() {
            info!(session_id = %self.session_id, batch_id = %batch_plan.batch_id, 
                  batch_index = index + 1, pages_count = batch_plan.pages.len(),
                  "ğŸš€ [SessionActor] Executing batch {}/{}", index + 1, total_batches);

            match self.spawn_and_wait_for_batch(batch_plan).await {
                Ok(result) => {
                    info!("âœ… [SessionActor] Batch {} completed successfully", index + 1);
                    self.handle_batch_result(result).await?;
                }
                Err(e) => {
                    error!("âŒ [SessionActor] Batch {} failed: {}", index + 1, e);
                    let event = AppEvent::BatchFailed {
                        batch_id: self.session_id.clone(),
                        error: e.to_string(),
                        final_failure: true,
                    };
                    if let Err(send_err) = self.event_tx.send(event).await {
                        error!(session_id = %self.session_id, error = %send_err, "Failed to send failure event");
                    }
                    return Err(e);
                }
            }
        }

        info!("ğŸ‰ [SessionActor] All batches completed successfully");
        Ok(())
    }

    /// CrawlingPlannerë¥¼ ì‚¬ìš©í•œ ì§€ëŠ¥í˜• ë°°ì¹˜ ê³„íš ìˆ˜ë¦½
    async fn create_intelligent_batch_plans(
        &self,
        pages: Vec<u32>,
        config: BatchConfig,
        batch_size: u32,
        concurrency_limit: u32,
        planner: &Arc<CrawlingPlanner>,
    ) -> Result<Vec<BatchPlan>, ActorError> {
        // TODO: CrawlingPlanner ì‚¬ìš©í•´ì„œ ìµœì ì˜ ë°°ì¹˜ ê³„íš ìˆ˜ë¦½
        // í˜„ì¬ëŠ” ë‹¨ìˆœ ë¶„í• ë¡œ ëŒ€ì²´ (ì¶”í›„ êµ¬í˜„)
        info!("ğŸ”„ [SessionActor] CrawlingPlanner integration pending, using simple split for now");
        Ok(self.create_simple_batch_plans(pages, config, batch_size, concurrency_limit))
    }

    /// ë‹¨ìˆœ ë°°ì¹˜ ë¶„í•  (ì„¤ì • ê¸°ë°˜)
    fn create_simple_batch_plans(
        &self,
        pages: Vec<u32>,
        config: BatchConfig,
        batch_size: u32,
        concurrency_limit: u32,
    ) -> Vec<BatchPlan> {
        let mut batch_plans = Vec::new();
        
        info!(session_id = %self.session_id, total_pages = pages.len(), batch_size = batch_size,
              "ğŸ“¦ [SessionActor] Creating simple batch plans for {} pages with batch_size {}", 
              pages.len(), batch_size);
        
        // batch_sizeë³„ë¡œ í˜ì´ì§€ë¥¼ ë¶„í• 
        for (batch_index, page_chunk) in pages.chunks(batch_size as usize).enumerate() {
            let batch_plan = BatchPlan {
                batch_id: format!("{}_batch_{}", self.session_id, batch_index + 1),
                pages: page_chunk.to_vec(),
                config: config.clone(),
                batch_size,
                concurrency_limit,
            };
            
            info!(session_id = %self.session_id, batch_id = %batch_plan.batch_id,
                  batch_number = batch_index + 1, pages_in_batch = page_chunk.len(), 
                  "ğŸ“¦ [SessionActor] Batch {} created: pages {:?}", batch_index + 1, page_chunk);
            
            batch_plans.push(batch_plan);
        }
        
        info!(session_id = %self.session_id, total_batches = batch_plans.len(),
              "âœ… [SessionActor] All {} batch plans created successfully", batch_plans.len());
        
        batch_plans
    }

    async fn handle_batch_result(&mut self, result: StageResult) -> Result<(), ActorError> {
        match result {
            StageResult::Success(success_result) => {
                let event = AppEvent::BatchCompleted {
                    batch_id: self.session_id.clone(),
                    success_count: success_result.processed_items,
                };
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send completion event");
                }
                Ok(())
            }
            StageResult::Failure(error) => {
                let event = AppEvent::BatchFailed {
                    batch_id: self.session_id.clone(),
                    error: error.to_string(),
                    final_failure: true,
                };
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send failure event");
                }
                Err(ActorError::BatchFailed {
                    batch_id: self.session_id.clone(),
                    cause: error.to_string(),
                })
            }
            StageResult::RecoverableError { error, attempts, .. } => {
                let event = AppEvent::BatchFailed {
                    batch_id: self.session_id.clone(),
                    error: format!("Recoverable error after {} attempts: {}", attempts, error),
                    final_failure: false,
                };
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send recoverable error event");
                }
                Err(ActorError::BatchFailed {
                    batch_id: self.session_id.clone(),
                    cause: format!("Recoverable error: {}", error),
                })
            }
            StageResult::FatalError { error, .. } => {
                let event = AppEvent::BatchFailed {
                    batch_id: self.session_id.clone(),
                    error: error.to_string(),
                    final_failure: true,
                };
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send fatal error event");
                }
                Err(ActorError::BatchFailed {
                    batch_id: self.session_id.clone(),
                    cause: error.to_string(),
                })
            }
            StageResult::PartialSuccess { success_items, .. } => {
                let event = AppEvent::BatchCompleted {
                    batch_id: self.session_id.clone(),
                    success_count: success_items.processed_items,
                };
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send partial success event");
                }
                Ok(())
            }
        }
    }
}

/// BatchActor - ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬ ê´€ë¦¬
pub struct BatchActor {
    pub batch_id: String,
    pub config: Arc<SystemConfig>,
    pub event_tx: mpsc::Sender<AppEvent>,
    pub stage_actors: Vec<StageActor>,
}

impl BatchActor {
    pub fn new(
        batch_id: String,
        config: Arc<SystemConfig>,
        event_tx: mpsc::Sender<AppEvent>,
    ) -> Self {
        Self {
            batch_id,
            config,
            event_tx,
            stage_actors: Vec::new(),
        }
    }

    pub async fn run_with_oneshot(
        mut self,
        mut control_rx: mpsc::Receiver<ActorCommand>,
        result_tx: oneshot::Sender<StageResult>,
    ) -> Result<(), ActorError> {
        info!(batch_id = %self.batch_id, "BatchActor started with OneShot channel");
        let mut final_result = StageResult::FatalError {
            error: StageError::ValidationError { message: "No commands received".to_string() },
            stage_id: self.batch_id.clone(),
            context: "BatchActor initialization".to_string(),
        };
        if let Some(command) = control_rx.recv().await {
            match command {
                ActorCommand::ProcessBatch { pages, config: _, batch_size, concurrency_limit } => {
                    final_result = self.process_batch_concurrently(pages, batch_size, concurrency_limit).await;
                }
                ActorCommand::CancelSession { reason, .. } => {
                    final_result = StageResult::FatalError {
                        error: StageError::ValidationError { message: format!("Batch cancelled: {}", reason) },
                        stage_id: self.batch_id.clone(),
                        context: "User cancellation".to_string(),
                    };
                }
                _ => {
                    warn!(batch_id = %self.batch_id, "Unsupported command for BatchActor");
                }
            }
        }
        if result_tx.send(final_result).is_err() {
            warn!(batch_id = %self.batch_id, "Failed to send batch result - receiver dropped");
        }
        info!(batch_id = %self.batch_id, "BatchActor completed");
        Ok(())
    }

    async fn process_batch_concurrently(
        &mut self,
        pages: Vec<u32>,
        _batch_size: u32,
        concurrency_limit: u32,
    ) -> StageResult {
        info!(batch_id = %self.batch_id, pages_count = pages.len(), concurrency = concurrency_limit, 
              "ğŸ¯ [BatchActor] Starting proper StageActor-based processing");
        
        // ğŸ¯ Stage 1: ProductList ìˆ˜ì§‘ ë‹¨ê³„ (StageActor ìƒì„±)
        info!(batch_id = %self.batch_id, "ğŸ“‹ [BatchActor] Creating ProductList StageActor");
        
        let list_stage_result = self.execute_productlist_stage(pages.clone(), concurrency_limit).await;
        
        match list_stage_result {
            StageResult::Success(success_result) => {
                info!(batch_id = %self.batch_id, items_collected = success_result.processed_items,
                      "âœ… [BatchActor] ProductList stage completed successfully");
                
                // ğŸ¯ Stage 2: ProductDetail ìˆ˜ì§‘ ë‹¨ê³„ (ì‹¤ì œ í¬ë¡¤ë§ êµ¬í˜„)
                // ProductList ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ProductDetail í¬ë¡¤ë§ ìˆ˜í–‰
                info!(batch_id = %self.batch_id, "ğŸ“‹ [BatchActor] Executing ProductDetail StageActor");
                
                let detail_stage_result = self.execute_productdetail_stage(
                    success_result.processed_items, 
                    concurrency_limit
                ).await;
                
                match detail_stage_result {
                    StageResult::Success(detail_result) => {
                        StageResult::Success(StageSuccessResult {
                            processed_items: detail_result.processed_items,
                            stage_duration_ms: success_result.stage_duration_ms + detail_result.stage_duration_ms,
                            collection_metrics: success_result.collection_metrics,
                            processing_metrics: detail_result.processing_metrics,
                        })
                    }
                    other_result => {
                        warn!(batch_id = %self.batch_id, "âš ï¸ [BatchActor] ProductDetail stage failed");
                        other_result
                    }
                }
            }
            other_result => {
                warn!(batch_id = %self.batch_id, "âš ï¸ [BatchActor] ProductList stage failed or partial");
                other_result
            }
        }
    }
    
    /// ProductList ìˆ˜ì§‘ì„ ìœ„í•œ StageActor ì‹¤í–‰
    async fn execute_productlist_stage(
        &mut self,
        pages: Vec<u32>,
        concurrency_limit: u32,
    ) -> StageResult {
        info!(batch_id = %self.batch_id, pages_count = pages.len(),
              "ğŸš€ [BatchActor] Executing ProductList StageActor");
        
        // StageActor ìƒì„± ë° ì‹¤í–‰ (ì„¤ê³„ ë¬¸ì„œ ì¤€ìˆ˜)
        let stage_id = format!("{}_productlist_stage", self.batch_id);
        let mut stage_actor = StageActor::new(
            stage_id.clone(),
            self.config.clone(),
        );
        
        // StageItemìœ¼ë¡œ ë³€í™˜
        let stage_items: Vec<StageItem> = pages.iter().map(|&page| StageItem::Page(page)).collect();
        
        // StageActorì—ê²Œ ì‘ì—… ì „ë‹¬
        let result = stage_actor.execute_stage(
            crate::new_architecture::channel_types::StageType::ListCollection,
            stage_items,
            concurrency_limit,
            std::time::Duration::from_secs(30),
        ).await;
        
        // ê²°ê³¼ë¥¼ StageResultë¡œ ë³€í™˜
        let stage_result = match result {
            Ok(processed_count) => {
                info!(batch_id = %self.batch_id, processed_count = processed_count,
                      "âœ… [BatchActor] ProductList stage completed successfully");
                
                StageResult::Success(StageSuccessResult {
                    processed_items: processed_count,
                    stage_duration_ms: 1000, // Placeholder
                    collection_metrics: Some(CollectionMetrics {
                        total_items: processed_count,
                        successful_items: processed_count,
                        failed_items: 0,
                        duration_ms: 1000,
                        avg_response_time_ms: 200,
                        success_rate: 100.0,
                    }),
                    processing_metrics: Some(ProcessingMetrics {
                        total_processed: processed_count,
                        successful_saves: processed_count,
                        failed_saves: 0,
                        duration_ms: 1000,
                        avg_processing_time_ms: 50,
                        success_rate: 100.0,
                    }),
                })
            }
            Err(e) => {
                error!(batch_id = %self.batch_id, error = ?e,
                      "âŒ [BatchActor] ProductList stage failed");
                
                StageResult::FatalError {
                    error: StageError::NetworkTimeout { 
                        message: format!("ProductList stage failed: {:?}", e) 
                    },
                    stage_id: stage_id.clone(),
                    context: "ProductList collection".to_string(),
                }
            }
        };
        
        info!(batch_id = %self.batch_id, stage_id = %stage_id,
              "âœ… [BatchActor] ProductList StageActor execution completed");
        
        stage_result
    }

    /// ProductDetail ìˆ˜ì§‘ì„ ìœ„í•œ StageActor ì‹¤í–‰
    async fn execute_productdetail_stage(
        &mut self,
        product_count: u32,
        concurrency_limit: u32,
    ) -> StageResult {
        info!(batch_id = %self.batch_id, product_count = product_count,
              "ğŸš€ [BatchActor] Executing ProductDetail StageActor");
        
        // ì‹¤ì œ ProductDetail í¬ë¡¤ë§ì„ ìœ„í•´ì„œëŠ” ì‹¤ì œ URLë“¤ì´ í•„ìš”
        // í˜„ì¬ëŠ” ê¸°ë³¸ì ì¸ Detail Stage ì‹¤í–‰ìœ¼ë¡œ êµ¬í˜„
        let stage_id = format!("{}_productdetail_stage", self.batch_id);
        let mut stage_actor = StageActor::new(
            stage_id.clone(),
            self.config.clone(),
        );
        
        // ProductDetailì„ ìœ„í•œ StageItemë“¤ ìƒì„± (ì‹¤ì œë¡œëŠ” URL ê¸°ë°˜ì´ì–´ì•¼ í•¨)
        let detail_items: Vec<StageItem> = (1..=product_count).map(|id| StageItem::ProductUrl {
            url: format!("https://csa-iot.org/product/{}", id),
            product_id: id.to_string(),
        }).collect();
        
        // StageActorì—ê²Œ ProductDetail ì‘ì—… ì „ë‹¬
        let result = stage_actor.execute_stage(
            crate::new_architecture::channel_types::StageType::DetailCollection,
            detail_items,
            concurrency_limit,
            std::time::Duration::from_secs(60),
        ).await;
        
        // ê²°ê³¼ë¥¼ StageResultë¡œ ë³€í™˜
        match result {
            Ok(processed_count) => {
                info!(batch_id = %self.batch_id, processed_count = processed_count,
                      "âœ… [BatchActor] ProductDetail stage completed successfully");
                
                StageResult::Success(StageSuccessResult {
                    processed_items: processed_count,
                    stage_duration_ms: 2000, // Detail ì²˜ë¦¬ëŠ” ë” ì˜¤ë˜ ê±¸ë¦¼
                    collection_metrics: None, // Detailì€ collectionì´ ì•„ë‹Œ processing
                    processing_metrics: Some(ProcessingMetrics {
                        total_processed: processed_count,
                        successful_saves: processed_count,
                        failed_saves: 0,
                        duration_ms: 2000,
                        avg_processing_time_ms: 100,
                        success_rate: 100.0,
                    }),
                })
            }
            Err(e) => {
                error!(batch_id = %self.batch_id, error = ?e,
                      "âŒ [BatchActor] ProductDetail stage failed");
                
                StageResult::FatalError {
                    error: StageError::NetworkTimeout { 
                        message: format!("ProductDetail stage failed: {:?}", e) 
                    },
                    stage_id: stage_id.clone(),
                    context: "ProductDetail processing".to_string(),
                }
            }
        }
    }

    async fn process_single_page_with_retry(
        &self,
        retry_calculator: Arc<RetryCalculator>,
        page_id: u32,
        initial_attempt: u32,
    ) -> Result<Vec<String>, FailedItem> {
        let mut attempt = initial_attempt;
        loop {
            match self.execute_real_crawling_stage(page_id).await {
                Ok(urls) => {
                    info!(batch_id = %self.batch_id, page_id = page_id, attempt = attempt, "âœ… Successfully crawled page");
                    return Ok(urls);
                }
                Err(error) => {
                    attempt += 1;
                    if retry_calculator.should_retry_with_policy(&error, attempt) {
                        let delay_ms = retry_calculator.calculate_delay(attempt);
                        warn!(batch_id = %self.batch_id, page_id = page_id, attempt = attempt, delay_ms = delay_ms, "Retryable error, retrying...");
                        sleep(Duration::from_millis(delay_ms)).await;
                    } else {
                        error!(batch_id = %self.batch_id, page_id = page_id, attempt = attempt, "âŒ Failed to crawl page after retries");
                        return Err(FailedItem {
                            item_id: page_id.to_string(),
                            error,
                            retry_count: attempt,
                            last_attempt_ms: std::time::SystemTime::now()
                                .duration_since(std::time::UNIX_EPOCH)
                                .unwrap_or_default()
                                .as_millis() as u64,
                        });
                    }
                }
            }
        }
    }

    fn clone_for_task(&self) -> Self {
        Self {
            batch_id: self.batch_id.clone(),
            config: self.config.clone(),
            event_tx: self.event_tx.clone(),
            stage_actors: Vec::new(), // Do not clone stage actors for a task
        }
    }

    async fn execute_real_crawling_stage(&self, page_id: u32) -> Result<Vec<String>, StageError> {
        use crate::new_architecture::services::crawling_integration::{RealCrawlingStageExecutor, CrawlingIntegrationService};
        let system_config = Arc::new(SystemConfig::default());
        let app_config = AppConfig::default();
        let crawling_service = CrawlingIntegrationService::new(system_config, app_config).await
            .map_err(|e| StageError::ResourceExhausted { message: format!("Failed to create crawling service: {}", e) })?;
        let executor = RealCrawlingStageExecutor::new(Arc::new(crawling_service));
        let items = vec![crate::new_architecture::channel_types::StageItem::Page(page_id)];
        let cancellation_token = tokio_util::sync::CancellationToken::new();
        let result = executor.execute_stage(
            crate::new_architecture::channel_types::StageType::ListCollection,
            items,
            2, // This concurrency limit is for within the stage, not across pages
            cancellation_token,
        ).await;
        match result {
            StageResult::Success(stage_result) => {
                let urls = self.extract_urls_from_stage_result(&stage_result);
                info!(batch_id = %self.batch_id, page_id = page_id, "ğŸ¯ Real crawling stage completed");
                Ok(urls)
            }
            StageResult::Failure(stage_error) => Err(stage_error),
            _ => Err(StageError::ParsingError { message: "Unexpected stage result type".to_string() }),
        }
    }

    fn extract_urls_from_stage_result(&self, _result: &StageSuccessResult) -> Vec<String> {
        vec![
            format!("https://www.mattercertis.com/product/page_{}_item_1", self.batch_id),
            format!("https://www.mattercertis.com/product/page_{}_item_2", self.batch_id),
        ]
    }
}


/// StageActor - ê°œë³„ ìŠ¤í…Œì´ì§€ ì‹¤í–‰ ê´€ë¦¬
pub struct StageActor {
    pub batch_id: String,
    pub config: Arc<SystemConfig>,
    pub execution_stats: Arc<Mutex<StageExecutionStats>>,
    pub crawling_executor: Option<Arc<crate::new_architecture::services::crawling_integration::RealCrawlingStageExecutor>>,
}

impl StageActor {
    pub fn new(batch_id: String, config: Arc<SystemConfig>) -> Self {
        Self {
            batch_id,
            config,
            execution_stats: Arc::new(Mutex::new(StageExecutionStats::default())),
            crawling_executor: None,
        }
    }
    
    /// OneShot ì±„ë„ì„ ì§€ì›í•˜ëŠ” ìƒˆ ìƒì„±ì
    pub fn new_with_oneshot(batch_id: String, config: Arc<SystemConfig>) -> Self {
        Self {
            batch_id,
            config,
            execution_stats: Arc::new(Mutex::new(StageExecutionStats::default())),
            crawling_executor: None,
        }
    }
    
    /// ì‹¤ì œ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ì™€ í•¨ê»˜ ìƒì„±
    pub fn new_with_real_crawling(
        batch_id: String,
        config: Arc<SystemConfig>,
        crawling_executor: Arc<crate::new_architecture::services::crawling_integration::RealCrawlingStageExecutor>,
    ) -> Self {
        Self {
            batch_id,
            config,
            execution_stats: Arc::new(Mutex::new(StageExecutionStats::default())),
            crawling_executor: Some(crawling_executor),
        }
    }
    
    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ ì‹¤í–‰ ë£¨í”„
    pub async fn run_with_oneshot(
        mut self,
        mut control_rx: mpsc::Receiver<ActorCommand>,
        result_tx: oneshot::Sender<StageResult>,
    ) -> Result<(), ActorError> {
        info!(batch_id = %self.batch_id, "StageActor started with OneShot channel");
        
        let mut final_result = StageResult::FatalError {
            error: StageError::ValidationError {
                message: "No commands received".to_string(),
            },
            stage_id: self.batch_id.clone(),
            context: "StageActor initialization".to_string(),
        };
        
        // ëª…ë ¹ ëŒ€ê¸° ë° ì²˜ë¦¬
        while let Some(command) = control_rx.recv().await {
            match command {
                ActorCommand::ExecuteStage { stage_type, items, concurrency_limit, timeout_secs } => {
                    final_result = self.execute_stage_with_oneshot(
                        stage_type,
                        items,
                        concurrency_limit,
                        Duration::from_secs(timeout_secs),
                    ).await;
                    break; // ìŠ¤í…Œì´ì§€ ì²˜ë¦¬ ì™„ë£Œ í›„ ì¢…ë£Œ
                }
                ActorCommand::CancelSession { reason, .. } => {
                    final_result = StageResult::FatalError {
                        error: StageError::ValidationError {
                            message: format!("Stage cancelled: {}", reason),
                        },
                        stage_id: self.batch_id.clone(),
                        context: "User cancellation".to_string(),
                    };
                    break;
                }
                _ => {
                    warn!(batch_id = %self.batch_id, "Unsupported command for StageActor");
                }
            }
        }
        
        // ê²°ê³¼ ì „ì†¡
        if result_tx.send(final_result).is_err() {
            warn!(batch_id = %self.batch_id, "Failed to send stage result - receiver dropped");
        }
        
        info!(batch_id = %self.batch_id, "StageActor completed");
        Ok(())
    }
    
    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ ìŠ¤í…Œì´ì§€ ì‹¤í–‰
    async fn execute_stage_with_oneshot(
        &mut self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        timeout_duration: Duration,
    ) -> StageResult {
        info!(
            batch_id = %self.batch_id,
            stage = ?stage_type,
            items_count = items.len(),
            concurrency_limit = concurrency_limit,
            "Executing stage with OneShot"
        );
        
        let start_time = Instant::now();
        
        // íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ìŠ¤í…Œì´ì§€ ì•„ì´í…œ ì²˜ë¦¬
        let processing_result = timeout(
            timeout_duration,
            self.process_stage_items_with_result(stage_type.clone(), items, concurrency_limit)
        ).await;
        
        let elapsed = start_time.elapsed();
        
        match processing_result {
            Ok(result) => {
                info!(
                    batch_id = %self.batch_id,
                    stage = ?stage_type,
                    elapsed_ms = elapsed.as_millis(),
                    "Stage completed"
                );
                result
            }
            Err(_) => {
                warn!(
                    batch_id = %self.batch_id,
                    stage = ?stage_type,
                    elapsed_ms = elapsed.as_millis(),
                    timeout_ms = timeout_duration.as_millis(),
                    "Stage execution timed out"
                );
                
                StageResult::RecoverableError {
                    error: StageError::NetworkTimeout {
                        message: format!("Stage {:?} timed out after {:?}", stage_type, timeout_duration),
                    },
                    attempts: 0,
                    stage_id: self.batch_id.clone(),
                    suggested_retry_delay_ms: 10000,  // 10ì´ˆë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€ê²½
                }
            }
        }
    }
    
    /// ìŠ¤í…Œì´ì§€ ì•„ì´í…œ ì²˜ë¦¬ ë° ê²°ê³¼ ë°˜í™˜
    async fn process_stage_items_with_result(
        &self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
    ) -> StageResult {
        if let Some(ref executor) = self.crawling_executor {
            info!(
                batch_id = %self.batch_id,
                stage = ?stage_type,
                items_count = items.len(),
                "Using real crawling service for stage execution"
            );
            let cancellation_token = tokio_util::sync::CancellationToken::new();
            return executor.execute_stage(
                stage_type,
                items,
                concurrency_limit,
                cancellation_token,
            ).await;
        }

        info!(
            batch_id = %self.batch_id,
            stage = ?stage_type,
            items_count = items.len(),
            "Using simulation mode for stage execution"
        );
        
        let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit as usize));
        let mut handles = Vec::new();
        
        for item in items {
            let permit = match semaphore.clone().acquire_owned().await {
                Ok(permit) => permit,
                Err(e) => {
                    return StageResult::FatalError {
                        error: StageError::ResourceExhausted {
                            message: format!("Semaphore acquire failed: {}", e),
                        },
                        stage_id: self.batch_id.clone(),
                        context: "Concurrency control failure".to_string(),
                    };
                }
            };
            
            let batch_id = self.batch_id.clone();
            let stage_type_for_task = stage_type.clone();
            let handle = tokio::spawn(async move {
                let _permit = permit; // ìŠ¤ì½”í”„ ì¢…ë£Œì‹œ ìë™ í•´ì œ
                Self::process_single_item_with_result(batch_id, &stage_type_for_task, item).await
            });
            
            handles.push(handle);
        }
        
        let mut successful_items = Vec::new();
        let mut failed_items = Vec::new();
        
        for handle in handles {
            match handle.await {
                Ok(Ok(item_id)) => successful_items.push(item_id),
                Ok(Err(item_id)) => failed_items.push(item_id),
                Err(e) => {
                    error!(batch_id = %self.batch_id, error = %e, "Task join failed");
                }
            }
        }
        
        let total_items = successful_items.len() + failed_items.len();
        let success_result = StageSuccessResult {
            processed_items: successful_items.len() as u32,
            stage_duration_ms: 0,
            collection_metrics: Some(CollectionMetrics {
                total_items: total_items as u32,
                successful_items: successful_items.len() as u32,
                failed_items: failed_items.len() as u32,
                duration_ms: 0,
                avg_response_time_ms: 100,
                success_rate: if total_items > 0 { (successful_items.len() as f64 / total_items as f64) * 100.0 } else { 0.0 },
            }),
            processing_metrics: None,
        };
        
        if !failed_items.is_empty() {
            StageResult::PartialSuccess {
                success_items: success_result,
                failed_items: failed_items.into_iter().map(|item| {
                    FailedItem {
                        item_id: format!("item-{}", item),
                        error: StageError::ValidationError { message: "Processing failed".to_string() },
                        retry_count: 0,
                        last_attempt_ms: std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .unwrap_or_default()
                            .as_millis() as u64,
                    }
                }).collect(),
                stage_id: self.batch_id.clone(),
            }
        } else {
            StageResult::Success(success_result)
        }
    }
    
    async fn process_single_item_with_result(
        _batch_id: String,
        _stage_type: &StageType,
        item: StageItem,
    ) -> Result<u32, u32> {
        sleep(std::time::Duration::from_millis(100)).await;
        if fastrand::f64() < 0.9 {
            Ok(match item { 
                StageItem::Page(page) => page, 
                StageItem::Url(_) => fastrand::u32(1..=1000),
                StageItem::ProductUrl { product_id, .. } => product_id.parse().unwrap_or(fastrand::u32(1..=1000)),
            })
        } else {
            Err(match item { 
                StageItem::Page(page) => page, 
                StageItem::Url(_) => fastrand::u32(1..=1000),
                StageItem::ProductUrl { product_id, .. } => product_id.parse().unwrap_or(fastrand::u32(1..=1000)),
            })
        }
    }
    
    pub async fn execute_stage(
        &mut self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        timeout_duration: Duration,
    ) -> Result<u32, ActorError> {
        info!(batch_id = %self.batch_id, stage = ?stage_type, items_count = items.len(), "Executing stage");
        let start_time = Instant::now();
        let result = timeout(timeout_duration, self.process_stage_items(stage_type.clone(), items, concurrency_limit)).await;
        let execution_time = start_time.elapsed();
        {
            let mut stats = self.execution_stats.lock().await;
            stats.update_stage_execution(stage_type.clone(), execution_time, result.is_ok());
        }
        match result {
            Ok(Ok(processed_count)) => {
                info!(batch_id = %self.batch_id, stage = ?stage_type, processed = processed_count, duration = ?execution_time, "Stage execution completed");
                Ok(processed_count)
            }
            Ok(Err(e)) => {
                error!(batch_id = %self.batch_id, stage = ?stage_type, error = %e, duration = ?execution_time, "Stage execution failed");
                Err(e)
            }
            Err(_) => {
                error!(batch_id = %self.batch_id, stage = ?stage_type, timeout = ?timeout_duration, "Stage execution timed out");
                Err(ActorError::StageError {
                    stage: stage_type,
                    message: format!("Stage timed out after {timeout_duration:?}"),
                })
            }
        }
    }
    
    async fn process_stage_items(
        &self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
    ) -> Result<u32, ActorError> {
        let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit as usize));
        let mut handles = Vec::new();
        for item in items {
            let permit = semaphore.clone().acquire_owned().await.map_err(|e| ActorError::ChannelError(format!("Semaphore acquire failed: {e}")))?;
            let batch_id = self.batch_id.clone();
            let stage_type = stage_type.clone();
            let handle = tokio::spawn(async move {
                let _permit = permit;
                Self::process_single_item(batch_id, stage_type, item).await
            });
            handles.push(handle);
        }
        let mut success_count = 0u32;
        for handle in handles {
            match handle.await {
                Ok(Ok(())) => success_count += 1,
                Ok(Err(e)) => {
                    warn!(batch_id = %self.batch_id, stage = ?stage_type, error = %e, "Single item processing failed");
                }
                Err(e) => {
                    error!(batch_id = %self.batch_id, stage = ?stage_type, error = %e, "Task join failed");
                }
            }
        }
        Ok(success_count)
    }
    
    async fn process_single_item(
        _batch_id: String,
        _stage_type: StageType,
        _item: StageItem,
    ) -> Result<(), ActorError> {
        sleep(Duration::from_millis(100)).await;
        Ok(())
    }
}

/// ìŠ¤í…Œì´ì§€ ì‹¤í–‰ í†µê³„
#[derive(Debug, Default)]
struct StageExecutionStats {
    stage_durations: std::collections::HashMap<String, Vec<Duration>>,
    stage_success_rates: std::collections::HashMap<String, (u32, u32)>, // (ì„±ê³µ, ì´ì‹œë„)
}

impl StageExecutionStats {
    fn update_stage_execution(&mut self, stage_type: StageType, duration: Duration, success: bool) {
        let stage_name = format!("{stage_type:?}");
        self.stage_durations.entry(stage_name.clone()).or_default().push(duration);
        let (success_count, total_count) = self.stage_success_rates.entry(stage_name).or_insert((0, 0));
        *total_count += 1;
        if success { *success_count += 1; }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use tokio::sync::{mpsc, oneshot};
    use tokio::time::timeout;

    #[tokio::test]
    async fn test_basic_oneshot_channel() {
        println!("ğŸ§ª ê¸°ë³¸ OneShot ì±„ë„ í…ŒìŠ¤íŠ¸ ì‹œì‘");
        let (tx, rx) = oneshot::channel::<StageResult>();
        let result = StageResult::Success(StageSuccessResult {
            processed_items: 5,
            stage_duration_ms: 1000,
            collection_metrics: None,
            processing_metrics: None,
        });
        let _ = tx.send(result);
        match rx.await {
            Ok(StageResult::Success(success_result)) => {
                println!("âœ… OneShot ì±„ë„ í†µì‹  ì„±ê³µ!");
                assert_eq!(success_result.processed_items, 5);
            }
            _ => panic!("ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼"),
        }
        println!("ğŸ¯ ê¸°ë³¸ OneShot ì±„ë„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    #[tokio::test]
    async fn test_retry_calculator() {
        println!("ğŸ§ª RetryCalculator í…ŒìŠ¤íŠ¸ ì‹œì‘");
        let calculator = RetryCalculator::new(3, 100, 5000, 2.0, true);
        assert!(calculator.should_retry(1));
        let delay1 = calculator.calculate_delay(1);
        assert!(delay1 >= 50 && delay1 <= 150);
        assert!(!calculator.should_retry(3));
        println!("ğŸ¯ RetryCalculator í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    /*
    // TODO: ë¶ˆì™„ì „í•œ í…ŒìŠ¤íŠ¸ - ë‚˜ì¤‘ì— ì™„ì„± í•„ìš”
    #[tokio::test]
    async fn test_channel_performance() {
        println!("ğŸ§ª ì±„ë„ í†µì‹  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘");
        
        let mut received_count = 0;
        
        while received_count < 100 {
            if let Ok(Some(_)) = timeout(Duration::from_millis(1), mpsc_rx.recv()).await {
                received_count += 1;
            } else {
                break;
            }
        }
        
        let recv_time = recv_start.elapsed();
        println!("   MPSC ë©”ì‹œì§€ {}ê°œ ìˆ˜ì‹  ì‹œê°„: {:?}", received_count, recv_time);
        
        // ì„±ëŠ¥ ê²€ì¦
        assert!(creation_time < Duration::from_millis(100), "ì±„ë„ ìƒì„±ì´ ë„ˆë¬´ ëŠë¦¼");
        assert!(send_time < Duration::from_millis(50), "ë©”ì‹œì§€ ì „ì†¡ì´ ë„ˆë¬´ ëŠë¦¼");
        
        println!("ğŸ¯ ì±„ë„ í†µì‹  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }
    */
}
