//! Actor ì‹œìŠ¤í…œ: ì„¸ì…˜, ë°°ì¹˜, ìŠ¤í…Œì´ì§€ ë¶„ë¦¬ êµ¬ì¡°
//! Modern Rust 2024 ì¤€ìˆ˜: ì˜ì¡´ì„± ì£¼ì… ê¸°ë°˜ Actor ì„¤ê³„

#![warn(clippy::all, clippy::pedantic, clippy::nursery)]
#![deny(clippy::unwrap_used, clippy::expect_used, clippy::panic)]

use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, oneshot, Mutex};
use tokio::time::{sleep, timeout};
use tracing::{info, warn, error, debug};
use uuid::Uuid;

// ê°œë³„ ëª¨ë“ˆì—ì„œ ì§ì ‘ import
use crate::new_architecture::system_config::{SystemConfig, ConfigError, RetryPolicy};
use crate::new_architecture::channel_types::{ActorCommand, AppEvent, BatchConfig, StageType, StageItem};
use crate::infrastructure::config::AppConfig;

// ì„ì‹œ íƒ€ì… ì •ì˜ (ì»´íŒŒì¼ ì—ëŸ¬ í•´ê²°ìš©)

#[derive(Debug, Clone)]
pub enum StageResult {
    Success(StageSuccessResult),
    Failure(StageError),
    RecoverableError {
        error: StageError,
        attempts: u32,
        stage_id: String,
        suggested_retry_delay: Duration,
    },
    FatalError {
        error: StageError,
        stage_id: String,
        context: String,
    },
    PartialSuccess {
        success_items: StageSuccessResult,
        failed_items: Vec<FailedItem>,
        stage_id: String,
    },
}

#[derive(Debug, Clone)]
pub enum StageError {
    NetworkError { message: String },
    ParsingError { message: String },
    NetworkTimeout { message: String },
    ValidationError { message: String },
    ChannelError { message: String },
    DatabaseError { message: String },
    ResourceExhausted { message: String },
    ConfigurationError { message: String },
    // Phase 3: TaskActor ê´€ë ¨ ì—ëŸ¬ ì¶”ê°€
    TaskCancelled { task_id: String },
    TaskExecutionFailed { task_id: String, message: String },
}

impl std::fmt::Display for StageError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            StageError::NetworkError { message } => write!(f, "Network error: {}", message),
            StageError::ParsingError { message } => write!(f, "Parsing error: {}", message),
            StageError::NetworkTimeout { message } => write!(f, "Network timeout: {}", message),
            StageError::ValidationError { message } => write!(f, "Validation error: {}", message),
            StageError::ChannelError { message } => write!(f, "Channel error: {}", message),
            StageError::DatabaseError { message } => write!(f, "Database error: {}", message),
            StageError::ResourceExhausted { message } => write!(f, "Resource exhausted: {}", message),
            StageError::ConfigurationError { message } => write!(f, "Configuration error: {}", message),
            // Phase 3: TaskActor ê´€ë ¨ ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
            StageError::TaskCancelled { task_id } => write!(f, "Task cancelled: {}", task_id),
            StageError::TaskExecutionFailed { task_id, message } => write!(f, "Task execution failed ({}): {}", task_id, message),
        }
    }
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct StageSuccessResult {
    pub processed_items: u32,
    pub stage_duration_ms: u64,
    pub collection_metrics: Option<CollectionMetrics>,
    pub processing_metrics: Option<ProcessingMetrics>,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct CollectionMetrics {
    pub total_items: u32,
    pub successful_items: u32,
    pub failed_items: u32,
    pub duration_ms: u64,
    pub avg_response_time_ms: u64,
    pub success_rate: f64,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct ProcessingMetrics {
    pub total_processed: u32,
    pub successful_saves: u32,
    pub failed_saves: u32,
    pub duration_ms: u64,
    pub avg_processing_time_ms: u64,
    pub success_rate: f64,
}

#[derive(Debug, Clone)]
pub struct ProductInfo {
    pub id: String,
    pub name: String,
    pub url: String,
}

#[derive(Debug, Clone)]
pub struct FailedItem {
    pub item_id: String,
    pub error: StageError,
    pub retry_count: u32,
    pub last_attempt: std::time::SystemTime,
}

/// ì¬ì‹œë„ ì •ì±… ê³„ì‚°ê¸°
#[derive(Debug, Clone)]
pub struct RetryCalculator {
    pub max_attempts: u32,
    pub base_delay_ms: u64,
    pub max_delay_ms: u64,
    pub exponential_factor: f64,
    pub jitter_enabled: bool,
}

impl RetryCalculator {
    pub fn new(
        max_attempts: u32,
        base_delay_ms: u64,
        max_delay_ms: u64,
        exponential_factor: f64,
        jitter_enabled: bool,
    ) -> Self {
        Self {
            max_attempts,
            base_delay_ms,
            max_delay_ms,
            exponential_factor,
            jitter_enabled,
        }
    }

    /// ì—ëŸ¬ì™€ ì‹œë„ íšŸìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •
    pub fn should_retry(&self, attempts: u32) -> bool {
        attempts < self.max_attempts
    }

    /// ì‹œë„ íšŸìˆ˜ì— ë”°ë¥¸ ì§€ì—° ì‹œê°„ ê³„ì‚° (ì§€ìˆ˜ ë°±ì˜¤í”„ + ì§€í„°)
    pub fn calculate_delay(&self, attempt: u32) -> u64 {
        if attempt == 0 {
            return self.base_delay_ms;
        }

        // ì§€ìˆ˜ ë°±ì˜¤í”„ ê³„ì‚°
        let exponential_delay = (self.base_delay_ms as f64) * self.exponential_factor.powi(attempt as i32 - 1);
        let mut delay = exponential_delay as u64;

        // ìµœëŒ€ ì§€ì—° ì‹œê°„ ì œí•œ
        delay = delay.min(self.max_delay_ms);

        // ì§€í„° ì ìš© (Â±25% ë²”ìœ„)
        if self.jitter_enabled {
            let jitter_range = (delay as f64 * 0.25) as u64;
            let jitter = fastrand::u64(0..=jitter_range * 2);
            let jitter_offset = jitter.saturating_sub(jitter_range);
            delay = delay.saturating_add(jitter_offset);
        }

        delay
    }

    /// íŠ¹ì • ì—ëŸ¬ íƒ€ì…ì— ëŒ€í•´ ì¬ì‹œë„ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    pub fn is_retryable_error(&self, error: &StageError) -> bool {
        match error {
            StageError::NetworkError { .. } => true,       // ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ê°€ëŠ¥
            StageError::ParsingError { .. } => false,      // íŒŒì‹± ì—ëŸ¬ëŠ” ì¬ì‹œë„ ë¶ˆê°€
            StageError::ResourceExhausted { .. } => true,  // ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ì€ ì¬ì‹œë„ ê°€ëŠ¥
            StageError::NetworkTimeout { .. } => true,     // ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒì€ ì¬ì‹œë„ ê°€ëŠ¥
            StageError::ValidationError { .. } => false,   // ê²€ì¦ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ë¶ˆê°€
            StageError::ChannelError { .. } => false,      // ì±„ë„ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ë¶ˆê°€
            StageError::DatabaseError { .. } => true,      // ë°ì´í„°ë² ì´ìŠ¤ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ê°€ëŠ¥
            StageError::ConfigurationError { .. } => false, // ì„¤ì • ì—ëŸ¬ëŠ” ì¬ì‹œë„ ë¶ˆê°€
            // Phase 3: TaskActor ê´€ë ¨ ì—ëŸ¬ ì¬ì‹œë„ ì •ì±…
            StageError::TaskCancelled { .. } => false,     // ì·¨ì†Œëœ íƒœìŠ¤í¬ëŠ” ì¬ì‹œë„ ë¶ˆê°€
            StageError::TaskExecutionFailed { .. } => true, // íƒœìŠ¤í¬ ì‹¤í–‰ ì‹¤íŒ¨ëŠ” ì¬ì‹œë„ ê°€ëŠ¥
        }
    }

    /// ì •ì±… ê¸°ë°˜ ì¬ì‹œë„ ì—¬ë¶€ ê²°ì • (ì—ëŸ¬ íƒ€ì…ê³¼ ì‹œë„ íšŸìˆ˜ ëª¨ë‘ ê³ ë ¤)
    pub fn should_retry_with_policy(&self, error: &StageError, attempts: u32) -> bool {
        self.should_retry(attempts) && self.is_retryable_error(error)
    }
}

impl Default for RetryCalculator {
    fn default() -> Self {
        Self::new(3, 100, 5000, 2.0, true)
    }
}

/// ë°°ì¹˜ ì‹¤í–‰ ê³„íš
#[derive(Debug, Clone)]
pub struct BatchPlan {
    pub batch_id: String,
    pub pages: Vec<u32>,
    pub config: BatchConfig,
    pub batch_size: u32,
    pub concurrency_limit: u32,
}

/// Actor ì‹œìŠ¤í…œ ì˜¤ë¥˜ íƒ€ì…
#[derive(Debug, thiserror::Error)]
pub enum ActorError {
    #[error("Session timeout: {session_id} after {elapsed:?}")]
    SessionTimeout { session_id: String, elapsed: Duration },
    
    #[error("Batch processing failed: {batch_id} - {cause}")]
    BatchFailed { batch_id: String, cause: String },
    
    #[error("Stage execution error: {stage:?} - {message}")]
    StageError { stage: StageType, message: String },
    
    #[error("Channel communication error: {0}")]
    ChannelError(String),
    
    #[error("Configuration error: {0}")]
    ConfigError(#[from] ConfigError),
    
    #[error("Timeout error: {0}")]
    TimeoutError(String),
    
    #[error("Processing error: {0}")]
    ProcessingError(String),
    
    #[error("Configuration error: {0}")]
    ConfigurationError(String),
}

/// SessionActor - ì„¸ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬
pub struct SessionActor {
    session_id: String,
    config: Arc<SystemConfig>,
    command_rx: mpsc::Receiver<ActorCommand>,
    event_tx: mpsc::Sender<AppEvent>,
    batch_actors: Vec<BatchActor>,
    start_time: Instant,
}

impl SessionActor {
    pub fn new(
        config: Arc<SystemConfig>,
        command_rx: mpsc::Receiver<ActorCommand>,
        event_tx: mpsc::Sender<AppEvent>,
    ) -> Self {
        let session_id = Uuid::new_v4().to_string();
        
        Self {
            session_id,
            config,
            command_rx,
            event_tx,
            batch_actors: Vec::new(),
            start_time: Instant::now(),
        }
    }
    
    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ BatchActor ìŠ¤í° ë° ê²°ê³¼ ëŒ€ê¸° (BatchPlan ë²„ì „)
    pub async fn spawn_and_wait_for_batch(
        &mut self, 
        batch_plan: BatchPlan
    ) -> Result<StageResult, ActorError> {
        // ê¸°ì¡´ spawn_and_wait_for_batch í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
        self.spawn_and_wait_for_batch_internal(batch_plan).await
    }

    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ BatchActor ìŠ¤í° ë° ê²°ê³¼ ëŒ€ê¸° (ë‚´ë¶€ êµ¬í˜„)
    async fn spawn_and_wait_for_batch_internal(
        &mut self, 
        batch_plan: BatchPlan
    ) -> Result<StageResult, ActorError> {
        info!(
            session_id = %self.session_id, 
            batch_id = %batch_plan.batch_id,
            pages_count = batch_plan.pages.len(),
            "Spawning BatchActor with OneShot channel"
        );
        
        // 1. OneShot ë°ì´í„° ì±„ë„ ìƒì„±
        let (data_tx, data_rx) = oneshot::channel::<StageResult>();
        
        // 2. BatchActorìš© Control ì±„ë„ ìƒì„±
        let (control_tx, control_rx) = mpsc::channel::<ActorCommand>(32);
        
        // 3. BatchActor ìƒì„± ë° ìŠ¤í°
        let batch_actor = BatchActor::new(
            batch_plan.batch_id.clone(),
            self.config.clone(),
            self.event_tx.clone(),
        );
        
        let handle = tokio::spawn(async move {
            batch_actor.run_with_oneshot(control_rx, data_tx).await
        });
        
        // 4. ë°°ì¹˜ ì²˜ë¦¬ ëª…ë ¹ ì „ì†¡
        let command = ActorCommand::ProcessBatch {
            pages: batch_plan.pages,
            config: batch_plan.config,
            batch_size: batch_plan.batch_size,
            concurrency_limit: batch_plan.concurrency_limit,
        };
        
        if let Err(e) = control_tx.send(command).await {
            handle.abort();
            return Err(ActorError::ChannelError(format!("Failed to send batch command: {}", e)));
        }
        
        // 5. íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ê²°ê³¼ ëŒ€ê¸°
        let timeout_duration = Duration::from_secs(self.config.system.session_timeout_secs);
        match timeout(timeout_duration, data_rx).await {
            Ok(Ok(stage_result)) => {
                // BatchActor handle ì •ë¦¬
                let _ = handle.await;
                
                info!(
                    session_id = %self.session_id,
                    batch_id = %batch_plan.batch_id,
                    "BatchActor completed successfully"
                );
                
                Ok(stage_result)
            }
            Ok(Err(_)) => {
                handle.abort();
                let error = ActorError::ChannelError("BatchActor result channel closed unexpectedly".to_string());
                
                let event = AppEvent::BatchFailed {
                    batch_id: batch_plan.batch_id.clone(),
                    error: error.to_string(),
                    final_failure: true,
                };
                
                if let Err(send_err) = self.event_tx.send(event).await {
                    error!(session_id = %self.session_id, error = %send_err, "Failed to send failure event");
                }
                
                Err(error)
            }
            Err(_) => {
                handle.abort();
                let error = ActorError::TimeoutError(format!("BatchActor timeout after {}s", timeout_duration.as_secs()));
                
                let event = AppEvent::SessionTimeout {
                    session_id: self.session_id.clone(),
                    elapsed: timeout_duration,
                };
                
                if let Err(send_err) = self.event_tx.send(event).await {
                    error!(session_id = %self.session_id, error = %send_err, "Failed to send timeout event");
                }
                
                Err(error)
            }
        }
    }
    
    /// ì„¸ì…˜ ì‹¤í–‰ ì‹œì‘
    pub async fn run(&mut self) -> Result<(), ActorError> {
        info!(session_id = %self.session_id, "SessionActor started");
        
        let session_timeout = Duration::from_secs(self.config.actor.session_timeout_secs);
        
        loop {
            let elapsed = self.start_time.elapsed();
            
            // ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬
            if elapsed >= session_timeout {
                let event = AppEvent::SessionTimeout {
                    session_id: self.session_id.clone(),
                    elapsed,
                };
                
                if let Err(e) = self.event_tx.send(event).await {
                    error!(session_id = %self.session_id, error = %e, "Failed to send timeout event");
                }
                
                return Err(ActorError::SessionTimeout {
                    session_id: self.session_id.clone(),
                    elapsed,
                });
            }
            
            // ëª…ë ¹ ì²˜ë¦¬
            match timeout(Duration::from_millis(100), self.command_rx.recv()).await {
                Ok(Some(command)) => {
                    if let Err(e) = self.handle_command(command).await {
                        error!(session_id = %self.session_id, error = %e, "Command handling failed");
                        return Err(e);
                    }
                }
                Ok(None) => {
                    debug!(session_id = %self.session_id, "Command channel closed");
                    break;
                }
                Err(_) => {
                    // íƒ€ì„ì•„ì›ƒ - ë‹¤ìŒ ë£¨í”„ ê³„ì†
                }
            }
        }
        
        let elapsed = self.start_time.elapsed();
        info!(session_id = %self.session_id, elapsed = ?elapsed, "SessionActor completed");
        Ok(())
    }
    
    /// ëª…ë ¹ ì²˜ë¦¬
    async fn handle_command(&mut self, command: ActorCommand) -> Result<(), ActorError> {
        match command {
            ActorCommand::ProcessBatch { pages, config, batch_size, concurrency_limit } => {
                self.process_batch(pages, config, batch_size, concurrency_limit).await
            }
            ActorCommand::CancelSession { session_id, reason } => {
                if session_id == self.session_id {
                    warn!(session_id = %self.session_id, reason = %reason, "Session cancelled");
                    return Err(ActorError::BatchFailed {
                        batch_id: self.session_id.clone(),
                        cause: reason,
                    });
                }
                Ok(())
            }
            _ => {
                warn!(session_id = %self.session_id, "Unsupported command for SessionActor");
                Ok(())
            }
        }
    }
    
    /// ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (OneShot ì±„ë„ ì‚¬ìš©)
    async fn process_batch(
        &mut self,
        pages: Vec<u32>,
        config: BatchConfig,
        batch_size: u32,
        concurrency_limit: u32,
    ) -> Result<(), ActorError> {
        let batch_plan = BatchPlan {
            batch_id: Uuid::new_v4().to_string(),
            pages,
            config: config.clone(),
            batch_size,
            concurrency_limit,
        };
        
        info!(session_id = %self.session_id, batch_id = %batch_plan.batch_id, "Starting batch processing");
        
        let event = AppEvent::SessionStarted {
            session_id: self.session_id.clone(),
            config,
        };
        
        if let Err(e) = self.event_tx.send(event).await {
            return Err(ActorError::ChannelError(format!("Failed to send session start event: {e}")));
        }
        
        // OneShot ì±„ë„ì„ ì‚¬ìš©í•œ ë°°ì¹˜ ì‹¤í–‰ ë° ê²°ê³¼ ëŒ€ê¸°
        match self.spawn_and_wait_for_batch(batch_plan).await {
            Ok(result) => {
                self.handle_batch_result(result).await
            }
            Err(e) => {
                let event = AppEvent::BatchFailed {
                    batch_id: self.session_id.clone(),
                    error: e.to_string(),
                    final_failure: true,
                };
                
                if let Err(send_err) = self.event_tx.send(event).await {
                    error!(session_id = %self.session_id, error = %send_err, "Failed to send failure event");
                }
                
                Err(e)
            }
        }
    }
    
    /// ë°°ì¹˜ ê²°ê³¼ ì²˜ë¦¬
    async fn handle_batch_result(&mut self, result: StageResult) -> Result<(), ActorError> {
        match result {
            StageResult::Success(success_result) => {
                let event = AppEvent::BatchCompleted {
                    batch_id: self.session_id.clone(),
                    success_count: success_result.processed_items,
                };
                
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send completion event");
                }
                Ok(())
            }
            StageResult::Failure(error) => {
                let event = AppEvent::BatchFailed {
                    batch_id: self.session_id.clone(),
                    error: error.to_string(),
                    final_failure: true,
                };
                
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send failure event");
                }
                
                Err(ActorError::BatchFailed {
                    batch_id: self.session_id.clone(),
                    cause: error.to_string(),
                })
            }
            StageResult::RecoverableError { error, attempts, .. } => {
                // ì„¸ì…˜ ë ˆë²¨ì—ì„œëŠ” ë³µêµ¬ ê°€ëŠ¥í•œ ì˜¤ë¥˜ë„ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬ (ì¬ì‹œë„ëŠ” í•˜ìœ„ ë ˆë²¨ì—ì„œ ìˆ˜í–‰ë¨)
                let event = AppEvent::BatchFailed {
                    batch_id: self.session_id.clone(),
                    error: format!("Recoverable error after {} attempts: {}", attempts, error),
                    final_failure: false,
                };
                
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send recoverable error event");
                }
                
                Err(ActorError::BatchFailed {
                    batch_id: self.session_id.clone(),
                    cause: format!("Recoverable error: {}", error),
                })
            }
            StageResult::FatalError { error, .. } => {
                let event = AppEvent::BatchFailed {
                    batch_id: self.session_id.clone(),
                    error: error.to_string(),
                    final_failure: true,
                };
                
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send fatal error event");
                }
                
                Err(ActorError::BatchFailed {
                    batch_id: self.session_id.clone(),
                    cause: error.to_string(),
                })
            }
            StageResult::PartialSuccess { success_items, .. } => {
                let event = AppEvent::BatchCompleted {
                    batch_id: self.session_id.clone(),
                    success_count: success_items.processed_items,
                };
                
                if let Err(e) = self.event_tx.send(event).await {
                    warn!(session_id = %self.session_id, error = %e, "Failed to send partial success event");
                }
                Ok(())
            }
        }
    }
}

/// BatchActor - ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬ ê´€ë¦¬
pub struct BatchActor {
    pub batch_id: String,
    pub config: Arc<SystemConfig>,
    pub event_tx: mpsc::Sender<AppEvent>,
    pub stage_actors: Vec<StageActor>,
}

impl BatchActor {
    pub fn new(
        batch_id: String,
        config: Arc<SystemConfig>,
        event_tx: mpsc::Sender<AppEvent>,
    ) -> Self {
        Self {
            batch_id,
            config,
            event_tx,
            stage_actors: Vec::new(),
        }
    }
    
    /// OneShot ì±„ë„ì„ ì§€ì›í•˜ëŠ” ìƒˆ ìƒì„±ì
    pub fn new_with_oneshot(
        batch_id: String,
        config: Arc<SystemConfig>,
        event_tx: mpsc::Sender<AppEvent>,
    ) -> Self {
        Self {
            batch_id,
            config,
            event_tx,
            stage_actors: Vec::new(),
        }
    }
    
    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ ì‹¤í–‰ ë£¨í”„
    pub async fn run_with_oneshot(
        mut self,
        mut control_rx: mpsc::Receiver<ActorCommand>,
        result_tx: oneshot::Sender<StageResult>,
    ) -> Result<(), ActorError> {
        info!(batch_id = %self.batch_id, "BatchActor started with OneShot channel");
        
        let mut final_result = StageResult::FatalError {
            error: StageError::ValidationError {
                message: "No commands received".to_string(),
            },
            stage_id: self.batch_id.clone(),
            context: "BatchActor initialization".to_string(),
        };
        
        // ëª…ë ¹ ëŒ€ê¸° ë° ì²˜ë¦¬
        while let Some(command) = control_rx.recv().await {
            match command {
                ActorCommand::ProcessBatch { pages, config: _, batch_size, concurrency_limit } => {
                    final_result = self.process_batch_with_oneshot(pages, batch_size, concurrency_limit).await;
                    break; // ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ í›„ ì¢…ë£Œ
                }
                ActorCommand::CancelSession { reason, .. } => {
                    final_result = StageResult::FatalError {
                        error: StageError::ValidationError {
                            message: format!("Batch cancelled: {}", reason),
                        },
                        stage_id: self.batch_id.clone(),
                        context: "User cancellation".to_string(),
                    };
                    break;
                }
                _ => {
                    warn!(batch_id = %self.batch_id, "Unsupported command for BatchActor");
                }
            }
        }
        
        // ê²°ê³¼ ì „ì†¡
        if result_tx.send(final_result).is_err() {
            warn!(batch_id = %self.batch_id, "Failed to send batch result - receiver dropped");
        }
        
        info!(batch_id = %self.batch_id, "BatchActor completed");
        Ok(())
    }
    
    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ ë°°ì¹˜ ì²˜ë¦¬ (ì¬ì‹œë„ ì •ì±… ì ìš©)
    async fn process_batch_with_oneshot(
        &mut self,
        pages: Vec<u32>,
        batch_size: u32,
        _concurrency_limit: u32,
    ) -> StageResult {
        info!(batch_id = %self.batch_id, pages_count = pages.len(), "Processing batch with OneShot and retry policy");
        
        let mut collected_urls: Vec<String> = Vec::new();
        let mut total_processed = 0u32;
        let mut total_failures = 0u32;
        let mut failed_items: Vec<FailedItem> = Vec::new();
        
        // ì„¤ì • ê¸°ë°˜ ì¬ì‹œë„ ì •ì±… ì‚¬ìš© (ì„ì‹œë¡œ ê¸°ì¡´ RetryCalculator ì‚¬ìš©)
        let retry_calculator = RetryCalculator::default();
        
        // í˜ì´ì§€ë¥¼ ë°°ì¹˜ í¬ê¸°ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬
        for chunk in pages.chunks(batch_size as usize) {
            // ì²« ë²ˆì§¸ ì‹œë„
            let mut items_to_retry: Vec<(u32, u32)> = Vec::new(); // (page_id, attempt_count)
            
            // ì´ˆê¸° ì²˜ë¦¬
            for &page_id in chunk {
                match self.process_single_page_with_retry(&retry_calculator, page_id, 0).await {
                    Ok(urls) => {
                        collected_urls.extend(urls);
                        total_processed += 1;
                    }
                    Err(error) => {
                        if retry_calculator.should_retry_with_policy(&error, 1) {
                            items_to_retry.push((page_id, 1));
                            info!(
                                batch_id = %self.batch_id,
                                page_id = page_id,
                                attempt = 1,
                                "Scheduling retry for failed page"
                            );
                        } else {
                            failed_items.push(FailedItem {
                                item_id: page_id.to_string(),
                                error,
                                retry_count: 0,
                                last_attempt: std::time::SystemTime::now(),
                            });
                            total_failures += 1;
                        }
                    }
                }
            }
            
            // ì¬ì‹œë„ ì²˜ë¦¬
            while !items_to_retry.is_empty() {
                let mut next_retry_batch = Vec::new();
                
                for (page_id, attempt_count) in items_to_retry {
                    // ì¬ì‹œë„ ì§€ì—° ì ìš©
                    let delay_ms = retry_calculator.calculate_delay(attempt_count);
                    tokio::time::sleep(Duration::from_millis(delay_ms)).await;
                    
                    match self.process_single_page_with_retry(&retry_calculator, page_id, attempt_count).await {
                        Ok(urls) => {
                            collected_urls.extend(urls);
                            total_processed += 1;
                            info!(
                                batch_id = %self.batch_id,
                                page_id = page_id,
                                attempt = attempt_count,
                                delay_ms = delay_ms,
                                "Retry succeeded"
                            );
                        }
                        Err(error) => {
                            let next_attempt = attempt_count + 1;
                            if retry_calculator.should_retry_with_policy(&error, next_attempt) {
                                next_retry_batch.push((page_id, next_attempt));
                                info!(
                                    batch_id = %self.batch_id,
                                    page_id = page_id,
                                    attempt = attempt_count,
                                    next_attempt = next_attempt,
                                    "Retry failed, scheduling next attempt"
                                );
                            } else {
                                failed_items.push(FailedItem {
                                    item_id: page_id.to_string(),
                                    error,
                                    retry_count: attempt_count,
                                    last_attempt: std::time::SystemTime::now(),
                                });
                                total_failures += 1;
                                warn!(
                                    batch_id = %self.batch_id,
                                    page_id = page_id,
                                    attempt = attempt_count,
                                    "Retry exhausted, marking as failed"
                                );
                            }
                        }
                    }
                }
                
                items_to_retry = next_retry_batch;
            }
        }
        
        // ìµœì¢… ê²°ê³¼ ë°˜í™˜
        if total_failures == 0 {
            StageResult::Success(StageSuccessResult {
                processed_items: pages.len() as u32,
                stage_duration_ms: 0, // ì¶”í›„ êµ¬í˜„
                collection_metrics: Some(CollectionMetrics {
                    total_items: pages.len() as u32,
                    successful_items: pages.len() as u32,
                    failed_items: 0,
                    duration_ms: 0, // ì¶”í›„ êµ¬í˜„
                    avg_response_time_ms: 0,
                    success_rate: 100.0,
                }),
                processing_metrics: None,
            })
        } else {
            StageResult::PartialSuccess {
                success_items: StageSuccessResult {
                    processed_items: total_processed,
                    stage_duration_ms: 0,
                    collection_metrics: Some(CollectionMetrics {
                        total_items: total_processed + total_failures,
                        successful_items: total_processed,
                        failed_items: total_failures,
                        duration_ms: 0,
                        avg_response_time_ms: 0,
                        success_rate: if total_processed + total_failures > 0 {
                            (total_processed as f64 / (total_processed + total_failures) as f64) * 100.0
                        } else { 0.0 },
                    }),
                    processing_metrics: None,
                },
                failed_items,
                stage_id: self.batch_id.clone(),
            }
        }
    }

    /// ì¬ì‹œë„ ì •ì±…ì´ ì ìš©ëœ ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬
    async fn process_single_page_with_retry(
        &self,
        _retry_calculator: &RetryCalculator,
        page_id: u32,
        attempt_count: u32,
    ) -> Result<Vec<String>, StageError> {
        info!(
            batch_id = %self.batch_id,
            page_id = page_id,
            attempt = attempt_count,
            "ğŸ” Starting real crawling for page"
        );
        
        // ì‹¤ì œ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì‚¬ìš©
        match self.execute_real_crawling_stage(page_id).await {
            Ok(urls) => {
                info!(
                    batch_id = %self.batch_id,
                    page_id = page_id,
                    urls_count = urls.len(),
                    "âœ… Successfully crawled page"
                );
                Ok(urls)
            }
            Err(e) => {
                error!(
                    batch_id = %self.batch_id,
                    page_id = page_id,
                    attempt = attempt_count,
                    error = %e,
                    "âŒ Failed to crawl page"
                );
                Err(e)
            }
        }
    }
    
    /// ì‹¤ì œ í¬ë¡¤ë§ ìŠ¤í…Œì´ì§€ ì‹¤í–‰
    async fn execute_real_crawling_stage(&self, page_id: u32) -> Result<Vec<String>, StageError> {
        use crate::new_architecture::services::crawling_integration::{RealCrawlingStageExecutor, CrawlingIntegrationService};
        use crate::new_architecture::system_config::SystemConfig;
        
        // ê¸°ë³¸ ì„¤ì • ìƒì„±
        let system_config = Arc::new(SystemConfig::default());
        let app_config = AppConfig::default();
        
        // CrawlingIntegrationService ìƒì„±
        let crawling_service = match CrawlingIntegrationService::new(
            system_config,
            app_config
        ).await {
            Ok(service) => service,
            Err(e) => {
                return Err(StageError::ResourceExhausted {
                    message: format!("Failed to create crawling service: {}", e)
                });
            }
        };
        
        // RealCrawlingStageExecutor ìƒì„±
        let executor = RealCrawlingStageExecutor::new(Arc::new(crawling_service));
        
        // í˜ì´ì§€ URL ìƒì„±
        let base_url = "https://www.mattercertis.com";
        let target_url = format!("{}/search?page={}", base_url, page_id);
        
        // StageType::ListCollection ì‹¤í–‰
        let items = vec![crate::new_architecture::channel_types::StageItem::Page(page_id)];
        let cancellation_token = tokio_util::sync::CancellationToken::new();
        
        let result = executor.execute_stage(
            crate::new_architecture::channel_types::StageType::ListCollection,
            items,
            2, // concurrency_limit
            cancellation_token
        ).await;
        
        match result {
            crate::new_architecture::actor_system::StageResult::Success(stage_result) => {
                // ì„±ê³µ ê²°ê³¼ì—ì„œ URL ì¶”ì¶œ
                let urls = self.extract_urls_from_stage_result(&stage_result);
                info!(
                    batch_id = %self.batch_id,
                    page_id = page_id,
                    stage_duration_ms = stage_result.stage_duration_ms,
                    processed_items = stage_result.processed_items,
                    "ğŸ¯ Real crawling stage completed"
                );
                Ok(urls)
            }
            crate::new_architecture::actor_system::StageResult::Failure(stage_error) => {
                Err(stage_error)
            }
            _ => {
                Err(StageError::ParsingError {
                    message: "Unexpected stage result type".to_string()
                })
            }
        }
    }
    
    /// StageSuccessResultì—ì„œ URL ëª©ë¡ ì¶”ì¶œ
    fn extract_urls_from_stage_result(&self, _result: &StageSuccessResult) -> Vec<String> {
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” resultì˜ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ URLì„ ì¶”ì¶œ
        // í˜„ì¬ëŠ” ê¸°ë³¸ê°’ ë°˜í™˜
        vec![
            format!("https://www.mattercertis.com/product/page_{}_item_1", self.batch_id),
            format!("https://www.mattercertis.com/product/page_{}_item_2", self.batch_id),
        ]
    }
    
    /// ê¸°ì¡´ ë°°ì¹˜ ì²˜ë¦¬ ë©”ì„œë“œ (í˜¸í™˜ì„± ìœ ì§€)
    async fn process_batch_legacy(
        &mut self,
        pages: Vec<u32>,
        batch_size: u32,
        _concurrency_limit: u32,
    ) -> StageResult {
        info!(batch_id = %self.batch_id, pages_count = pages.len(), "Processing batch (legacy mode)");
        
        // ê°„ë‹¨í•œ ì„±ê³µ ê²°ê³¼ ë°˜í™˜ (êµ¬í˜„ ê°„ì†Œí™”)
        StageResult::Success(StageSuccessResult {
            processed_items: pages.len() as u32,
            stage_duration_ms: 100,
            collection_metrics: Some(CollectionMetrics {
                total_items: pages.len() as u32,
                successful_items: pages.len() as u32,
                failed_items: 0,
                duration_ms: 100,
                avg_response_time_ms: 50,
                success_rate: 100.0,
            }),
            processing_metrics: None,
        })
    }

    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ ìŠ¤í…Œì´ì§€ ì‹¤í–‰
    async fn execute_stage_with_oneshot(&mut self, stage_type: StageType, items: Vec<StageItem>) -> StageResult {
        info!(batch_id = %self.batch_id, stage = ?stage_type, items_count = items.len(), "Executing stage with OneShot");
        
        // 1. OneShot ë°ì´í„° ì±„ë„ ìƒì„±
        let (stage_data_tx, stage_data_rx) = oneshot::channel::<StageResult>();
        
        // 2. ì œì–´ ì±„ë„ ìƒì„±
        let (stage_control_tx, stage_control_rx) = mpsc::channel(self.config.channels.control_buffer_size);
        
        // 3. StageActor ìƒì„± ë° ìŠ¤í°
        let stage_actor = StageActor::new_with_oneshot(
            self.batch_id.clone(),
            self.config.clone(),
        );
        
        let handle = tokio::spawn(async move {
            stage_actor.run_with_oneshot(stage_control_rx, stage_data_tx).await
        });
        
        // 4. ìŠ¤í…Œì´ì§€ ëª…ë ¹ ì „ì†¡
        let stage_timeout = Duration::from_secs(self.config.actor.stage_timeout_secs);
        let command = ActorCommand::ExecuteStage {
            stage_type: stage_type.clone(),
            items,
            concurrency_limit: self.config.performance.concurrency.stage_concurrency_limits
                .get(&format!("{:?}", stage_type))
                .copied()
                .unwrap_or(10),
            timeout_secs: stage_timeout.as_secs(),
        };
        
        if let Err(e) = stage_control_tx.send(command).await {
            return StageResult::FatalError {
                error: StageError::ValidationError {
                    message: format!("Failed to send stage command: {}", e),
                },
                stage_id: self.batch_id.clone(),
                context: "Stage command sending".to_string(),
            };
        }
        
        // 5. ê²°ê³¼ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜)
        let result = match timeout(stage_timeout, stage_data_rx).await {
            Ok(Ok(stage_result)) => stage_result,
            Ok(Err(_)) => StageResult::FatalError {
                error: StageError::ValidationError {
                    message: "Stage data channel closed".to_string(),
                },
                stage_id: self.batch_id.clone(),
                context: "Stage communication failure".to_string(),
            },
            Err(_) => StageResult::RecoverableError {
                error: StageError::NetworkTimeout {
                    message: "Stage execution timeout".to_string(),
                },
                attempts: 0,
                stage_id: self.batch_id.clone(),
                suggested_retry_delay: Duration::from_secs(5),
            },
        };
        
        // 6. StageActor ì •ë¦¬
        if let Err(e) = handle.await {
            warn!(batch_id = %self.batch_id, error = %e, "StageActor join failed");
        }
        
        // 7. ì¬ì‹œë„ ì •ì±… ì ìš©
        self.apply_retry_policy(result, stage_type).await
    }
    
    /// ì¬ì‹œë„ ì •ì±… ì ìš©
    async fn apply_retry_policy(&mut self, result: StageResult, stage_type: StageType) -> StageResult {
        match result {
            StageResult::RecoverableError { error, attempts, .. } => {
                let retry_calculator = RetryCalculator::default();
                
                if retry_calculator.should_retry_with_policy(&error, attempts) {
                    let delay_ms = retry_calculator.calculate_delay(attempts);
                    info!(
                        batch_id = %self.batch_id,
                        stage = ?stage_type,
                        attempts = attempts,
                        delay_ms = delay_ms,
                        "Retrying stage after delay"
                    );
                    
                    tokio::time::sleep(Duration::from_millis(delay_ms)).await;
                    
                    // TODO: ì¬ì‹œë„ ì‹¤í–‰ - í˜„ì¬ëŠ” ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ë˜, attemptsë¥¼ ì¦ê°€ì‹œí‚´
                    StageResult::RecoverableError {
                        error,
                        attempts: attempts + 1,
                        stage_id: format!("{}-retry-{}", self.batch_id, attempts + 1),
                        suggested_retry_delay: Duration::from_millis(delay_ms),
                    }
                } else {
                    // ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼
                    StageResult::FatalError {
                        error: StageError::ValidationError {
                            message: format!("Max retries exceeded for stage {:?}: {}", stage_type, error),
                        },
                        stage_id: self.batch_id.clone(),
                        context: format!("Retry exhausted after {} attempts", attempts),
                    }
                }
            }
            other => other,
        }
    }
    
    /// ìŠ¤í…Œì´ì§€ë³„ ì¬ì‹œë„ ì •ì±… ê°€ì ¸ì˜¤ê¸°
    fn get_retry_policy_for_stage(&self, stage_type: &StageType) -> RetryPolicy {
        match stage_type {
            StageType::Collection => self.config.retry_policies.list_collection.clone(),
            StageType::Processing => self.config.retry_policies.detail_collection.clone(),
            StageType::ListCollection => self.config.retry_policies.list_collection.clone(),
            StageType::DetailCollection => self.config.retry_policies.detail_collection.clone(),
            StageType::DataValidation => self.config.retry_policies.data_validation.clone(),
            StageType::DatabaseSave => self.config.retry_policies.database_save.clone(),
        }
    }
    
    /// í˜ì´ì§€ ì²˜ë¦¬
    pub async fn process_pages(
        &mut self,
        pages: Vec<u32>,
        batch_size: u32,
        concurrency_limit: u32,
    ) -> Result<u32, ActorError> {
        info!(batch_id = %self.batch_id, pages_count = pages.len(), "Processing pages");
        
        let mut success_count = 0u32;
        
        // í˜ì´ì§€ë¥¼ ë°°ì¹˜ í¬ê¸°ë¡œ ë¶„í• 
        for chunk in pages.chunks(batch_size as usize) {
            let stage_items: Vec<StageItem> = chunk.iter().map(|&page| StageItem::Page(page)).collect();
            
            // StageActor ìƒì„± ë° ì‹¤í–‰
            let mut stage_actor = StageActor::new(
                self.batch_id.clone(),
                self.config.clone(),
            );
            
            // ê° ìŠ¤í…Œì´ì§€ ìˆœì°¨ ì‹¤í–‰
            let stages = [
                StageType::ListCollection,
                StageType::DetailCollection,
                StageType::DataValidation,
                StageType::DatabaseSave,
            ];
            
            for stage_type in &stages {
                let stage_timeout = Duration::from_secs(self.config.actor.stage_timeout_secs);
                
                let stage_result = stage_actor.execute_stage(
                    stage_type.clone(),
                    stage_items.clone(),
                    concurrency_limit,
                    stage_timeout,
                ).await;
                
                match stage_result {
                    Ok(processed_count) => {
                        debug!(
                            batch_id = %self.batch_id,
                            stage = ?stage_type,
                            processed = processed_count,
                            "Stage completed"
                        );
                        success_count += processed_count;
                    }
                    Err(e) => {
                        error!(
                            batch_id = %self.batch_id,
                            stage = ?stage_type,
                            error = %e,
                            "Stage failed"
                        );
                        return Err(e);
                    }
                }
            }
            
            self.stage_actors.push(stage_actor);
        }
        
        info!(batch_id = %self.batch_id, success_count = success_count, "Batch processing completed");
        Ok(success_count)
    }
}

/// StageActor - ê°œë³„ ìŠ¤í…Œì´ì§€ ì‹¤í–‰ ê´€ë¦¬
pub struct StageActor {
    pub batch_id: String,
    pub config: Arc<SystemConfig>,
    pub execution_stats: Arc<Mutex<StageExecutionStats>>,
    pub crawling_executor: Option<Arc<crate::new_architecture::services::crawling_integration::RealCrawlingStageExecutor>>,
}

impl StageActor {
    pub fn new(batch_id: String, config: Arc<SystemConfig>) -> Self {
        Self {
            batch_id,
            config,
            execution_stats: Arc::new(Mutex::new(StageExecutionStats::default())),
            crawling_executor: None,
        }
    }
    
    /// OneShot ì±„ë„ì„ ì§€ì›í•˜ëŠ” ìƒˆ ìƒì„±ì
    pub fn new_with_oneshot(batch_id: String, config: Arc<SystemConfig>) -> Self {
        Self {
            batch_id,
            config,
            execution_stats: Arc::new(Mutex::new(StageExecutionStats::default())),
            crawling_executor: None,
        }
    }
    
    /// ì‹¤ì œ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ì™€ í•¨ê»˜ ìƒì„±
    pub fn new_with_real_crawling(
        batch_id: String,
        config: Arc<SystemConfig>,
        crawling_executor: Arc<crate::new_architecture::services::crawling_integration::RealCrawlingStageExecutor>,
    ) -> Self {
        Self {
            batch_id,
            config,
            execution_stats: Arc::new(Mutex::new(StageExecutionStats::default())),
            crawling_executor: Some(crawling_executor),
        }
    }
    
    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ ì‹¤í–‰ ë£¨í”„
    pub async fn run_with_oneshot(
        mut self,
        mut control_rx: mpsc::Receiver<ActorCommand>,
        result_tx: oneshot::Sender<StageResult>,
    ) -> Result<(), ActorError> {
        info!(batch_id = %self.batch_id, "StageActor started with OneShot channel");
        
        let mut final_result = StageResult::FatalError {
            error: StageError::ValidationError {
                message: "No commands received".to_string(),
            },
            stage_id: self.batch_id.clone(),
            context: "StageActor initialization".to_string(),
        };
        
        // ëª…ë ¹ ëŒ€ê¸° ë° ì²˜ë¦¬
        while let Some(command) = control_rx.recv().await {
            match command {
                ActorCommand::ExecuteStage { stage_type, items, concurrency_limit, timeout_secs } => {
                    final_result = self.execute_stage_with_oneshot(
                        stage_type,
                        items,
                        concurrency_limit,
                        Duration::from_secs(timeout_secs),
                    ).await;
                    break; // ìŠ¤í…Œì´ì§€ ì²˜ë¦¬ ì™„ë£Œ í›„ ì¢…ë£Œ
                }
                ActorCommand::CancelSession { reason, .. } => {
                    final_result = StageResult::FatalError {
                        error: StageError::ValidationError {
                            message: format!("Stage cancelled: {}", reason),
                        },
                        stage_id: self.batch_id.clone(),
                        context: "User cancellation".to_string(),
                    };
                    break;
                }
                _ => {
                    warn!(batch_id = %self.batch_id, "Unsupported command for StageActor");
                }
            }
        }
        
        // ê²°ê³¼ ì „ì†¡
        if result_tx.send(final_result).is_err() {
            warn!(batch_id = %self.batch_id, "Failed to send stage result - receiver dropped");
        }
        
        info!(batch_id = %self.batch_id, "StageActor completed");
        Ok(())
    }
    
    /// OneShot ì±„ë„ì„ ì‚¬ìš©í•œ ìŠ¤í…Œì´ì§€ ì‹¤í–‰
    async fn execute_stage_with_oneshot(
        &mut self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        timeout_duration: Duration,
    ) -> StageResult {
        info!(
            batch_id = %self.batch_id,
            stage = ?stage_type,
            items_count = items.len(),
            concurrency_limit = concurrency_limit,
            "Executing stage with OneShot"
        );
        
        let start_time = Instant::now();
        
        // íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ìŠ¤í…Œì´ì§€ ì•„ì´í…œ ì²˜ë¦¬
        let processing_result = timeout(
            timeout_duration,
            self.process_stage_items_with_result(stage_type.clone(), items, concurrency_limit)
        ).await;
        
        let elapsed = start_time.elapsed();
        
        match processing_result {
            Ok(result) => {
                info!(
                    batch_id = %self.batch_id,
                    stage = ?stage_type,
                    elapsed_ms = elapsed.as_millis(),
                    "Stage completed"
                );
                result
            }
            Err(_) => {
                warn!(
                    batch_id = %self.batch_id,
                    stage = ?stage_type,
                    elapsed_ms = elapsed.as_millis(),
                    timeout_ms = timeout_duration.as_millis(),
                    "Stage execution timed out"
                );
                
                StageResult::RecoverableError {
                    error: StageError::NetworkTimeout {
                        message: format!("Stage {:?} timed out after {:?}", stage_type, timeout_duration),
                    },
                    attempts: 0,
                    stage_id: self.batch_id.clone(),
                    suggested_retry_delay: Duration::from_secs(10),
                }
            }
        }
    }
    
    /// ìŠ¤í…Œì´ì§€ ì•„ì´í…œ ì²˜ë¦¬ ë° ê²°ê³¼ ë°˜í™˜
    async fn process_stage_items_with_result(
        &self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
    ) -> StageResult {
        // ì‹¤ì œ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜
        if let Some(ref executor) = self.crawling_executor {
            info!(
                batch_id = %self.batch_id,
                stage = ?stage_type,
                items_count = items.len(),
                "Using real crawling service for stage execution"
            );
            
            // ì·¨ì†Œ í† í° ìƒì„±
            let cancellation_token = tokio_util::sync::CancellationToken::new();
            
            // ì‹¤ì œ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì‹¤í–‰
            return executor.execute_stage(
                stage_type,
                items,
                concurrency_limit,
                cancellation_token,
            ).await;
        }
        
        // í¬ë¡¤ë§ ì„œë¹„ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ì‹œë®¬ë ˆì´ì…˜ ë¡œì§ ì‹¤í–‰
        info!(
            batch_id = %self.batch_id,
            stage = ?stage_type,
            items_count = items.len(),
            "Using simulation mode for stage execution"
        );
        
        // ë™ì‹œì„± ì œì–´
        let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit as usize));
        let mut handles = Vec::new();
        
        for item in items {
            let permit = match semaphore.clone().acquire_owned().await {
                Ok(permit) => permit,
                Err(e) => {
                    return StageResult::FatalError {
                        error: StageError::ResourceExhausted {
                            message: format!("Semaphore acquire failed: {}", e),
                        },
                        stage_id: self.batch_id.clone(),
                        context: "Concurrency control failure".to_string(),
                    };
                }
            };
            
            let batch_id = self.batch_id.clone();
            let stage_type_for_task = stage_type.clone();
            let handle = tokio::spawn(async move {
                let _permit = permit; // ìŠ¤ì½”í”„ ì¢…ë£Œì‹œ ìë™ í•´ì œ
                Self::process_single_item_with_result(batch_id, &stage_type_for_task, item).await
            });
            
            handles.push(handle);
        }
        
        // ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        let mut successful_items = Vec::new();
        let mut failed_items = Vec::new();
        
        for handle in handles {
            match handle.await {
                Ok(Ok(item_id)) => successful_items.push(item_id),
                Ok(Err(item_id)) => failed_items.push(item_id),
                Err(e) => {
                    error!(batch_id = %self.batch_id, error = %e, "Task join failed");
                    // Join ì—ëŸ¬ëŠ” failed_itemsì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ (ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ)
                }
            }
        }
        
        let total_items = successful_items.len() + failed_items.len();
        let success_result = StageSuccessResult {
            processed_items: successful_items.len() as u32,
            stage_duration_ms: 0, // í˜¸ì¶œìì—ì„œ ì„¤ì •
            collection_metrics: Some(CollectionMetrics {
                total_items: total_items as u32,
                successful_items: successful_items.len() as u32,
                failed_items: failed_items.len() as u32,
                duration_ms: 0,
                avg_response_time_ms: 100,
                success_rate: if total_items > 0 {
                    (successful_items.len() as f64 / total_items as f64) * 100.0
                } else { 0.0 },
            }),
            processing_metrics: None,
        };
        
        if !failed_items.is_empty() {
            StageResult::PartialSuccess {
                success_items: success_result,
                failed_items: failed_items.into_iter().map(|item| {
                    FailedItem {
                        item_id: format!("item-{}", item),
                        error: StageError::ValidationError {
                            message: "Processing failed".to_string(),
                        },
                        retry_count: 0,
                        last_attempt: std::time::SystemTime::now(),
                    }
                }).collect(),
                stage_id: self.batch_id.clone(),
            }
        } else {
            StageResult::Success(success_result)
        }
    }
    
    /// ê°œë³„ ì•„ì´í…œ ì²˜ë¦¬ (ì„±ê³µ ì‹œ ì•„ì´í…œ ID, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜)
    async fn process_single_item_with_result(
        _batch_id: String,
        _stage_type: &StageType,
        item: StageItem,
    ) -> Result<u32, u32> {
        // ì‹¤ì œ ì²˜ë¦¬ ë¡œì§ì„ ì‹œë®¬ë ˆì´ì…˜
        tokio::time::sleep(std::time::Duration::from_millis(100)).await;
        
        // 90% ì„±ê³µë¥ ë¡œ ì‹œë®¬ë ˆì´ì…˜
        if fastrand::f64() < 0.9 {
            let item_id = match item {
                StageItem::Page(page) => page,
                StageItem::Url(_) => fastrand::u32(1..=1000),
            };
            Ok(item_id)
        } else {
            let item_id = match item {
                StageItem::Page(page) => page,
                StageItem::Url(_) => fastrand::u32(1..=1000),
            };
            Err(item_id)
        }
    }
    
    /// ìŠ¤í…Œì´ì§€ ì‹¤í–‰
    pub async fn execute_stage(
        &mut self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        timeout_duration: Duration,
    ) -> Result<u32, ActorError> {
        info!(
            batch_id = %self.batch_id,
            stage = ?stage_type,
            items_count = items.len(),
            "Executing stage"
        );
        
        let start_time = Instant::now();
        
        // íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ìŠ¤í…Œì´ì§€ ì‹¤í–‰
        let result = timeout(timeout_duration, self.process_stage_items(stage_type.clone(), items, concurrency_limit)).await;
        
        let execution_time = start_time.elapsed();
        
        // í†µê³„ ì—…ë°ì´íŠ¸
        {
            let mut stats = self.execution_stats.lock().await;
            stats.update_stage_execution(stage_type.clone(), execution_time, result.is_ok());
        }
        
        match result {
            Ok(Ok(processed_count)) => {
                info!(
                    batch_id = %self.batch_id,
                    stage = ?stage_type,
                    processed = processed_count,
                    duration = ?execution_time,
                    "Stage execution completed"
                );
                Ok(processed_count)
            }
            Ok(Err(e)) => {
                error!(
                    batch_id = %self.batch_id,
                    stage = ?stage_type,
                    error = %e,
                    duration = ?execution_time,
                    "Stage execution failed"
                );
                Err(e)
            }
            Err(_) => {
                error!(
                    batch_id = %self.batch_id,
                    stage = ?stage_type,
                    timeout = ?timeout_duration,
                    "Stage execution timed out"
                );
                Err(ActorError::StageError {
                    stage: stage_type,
                    message: format!("Stage timed out after {timeout_duration:?}"),
                })
            }
        }
    }
    
    /// ìŠ¤í…Œì´ì§€ ì•„ì´í…œ ì²˜ë¦¬
    async fn process_stage_items(
        &self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
    ) -> Result<u32, ActorError> {
        // ë™ì‹œì„± ì œì–´
        let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit as usize));
        let mut handles = Vec::new();
        
        for item in items {
            let permit = semaphore.clone().acquire_owned().await
                .map_err(|e| ActorError::ChannelError(format!("Semaphore acquire failed: {e}")))?;
            
            let batch_id = self.batch_id.clone();
            let stage_type = stage_type.clone();
            
            let handle = tokio::spawn(async move {
                let _permit = permit; // ìŠ¤ì½”í”„ ìœ ì§€
                Self::process_single_item(batch_id, stage_type, item).await
            });
            
            handles.push(handle);
        }
        
        // ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        let mut success_count = 0u32;
        for handle in handles {
            match handle.await {
                Ok(Ok(())) => success_count += 1,
                Ok(Err(e)) => {
                    warn!(
                        batch_id = %self.batch_id,
                        stage = ?stage_type,
                        error = %e,
                        "Single item processing failed"
                    );
                }
                Err(e) => {
                    error!(
                        batch_id = %self.batch_id,
                        stage = ?stage_type,
                        error = %e,
                        "Task join failed"
                    );
                }
            }
        }
        
        Ok(success_count)
    }
    
    /// ê°œë³„ ì•„ì´í…œ ì²˜ë¦¬ (í˜„ì¬ëŠ” ëª©ì—…)
    async fn process_single_item(
        _batch_id: String,
        _stage_type: StageType,
        _item: StageItem,
    ) -> Result<(), ActorError> {
        // ì‹¤ì œ ì²˜ë¦¬ ë¡œì§ì„ ì‹œë®¬ë ˆì´ì…˜
        sleep(Duration::from_millis(100)).await;
        Ok(())
    }
}

/// ìŠ¤í…Œì´ì§€ ì‹¤í–‰ í†µê³„
#[derive(Debug, Default)]
struct StageExecutionStats {
    stage_durations: std::collections::HashMap<String, Vec<Duration>>,
    stage_success_rates: std::collections::HashMap<String, (u32, u32)>, // (ì„±ê³µ, ì´ì‹œë„)
}

impl StageExecutionStats {
    fn update_stage_execution(&mut self, stage_type: StageType, duration: Duration, success: bool) {
        let stage_name = format!("{stage_type:?}");
        
        // ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
        self.stage_durations
            .entry(stage_name.clone())
            .or_default()
            .push(duration);
        
        // ì„±ê³µë¥  ê¸°ë¡
        let (success_count, total_count) = self.stage_success_rates
            .entry(stage_name)
            .or_insert((0, 0));
        
        *total_count += 1;
        if success {
            *success_count += 1;
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use tokio::sync::{mpsc, oneshot};

    #[tokio::test]
    async fn test_basic_oneshot_channel() {
        println!("ğŸ§ª ê¸°ë³¸ OneShot ì±„ë„ í…ŒìŠ¤íŠ¸ ì‹œì‘");

        // ê°„ë‹¨í•œ OneShot ì±„ë„ í†µì‹  í…ŒìŠ¤íŠ¸
        let (tx, rx) = oneshot::channel::<StageResult>();

        // ì„±ê³µ ê²°ê³¼ ì „ì†¡
        let result = StageResult::Success(StageSuccessResult {
            processed_items: 5,
            stage_duration_ms: 1000,
            collection_metrics: None,
            processing_metrics: None,
        });

        let _ = tx.send(result);

        // ê²°ê³¼ ìˆ˜ì‹  í™•ì¸
        match rx.await {
            Ok(StageResult::Success(success_result)) => {
                println!("âœ… OneShot ì±„ë„ í†µì‹  ì„±ê³µ!");
                println!("   ì²˜ë¦¬ëœ ì•„ì´í…œ: {}", success_result.processed_items);
                println!("   ì‹¤í–‰ ì‹œê°„: {}ms", success_result.stage_duration_ms);
                assert_eq!(success_result.processed_items, 5);
                assert_eq!(success_result.stage_duration_ms, 1000);
            },
            Ok(StageResult::Failure(error)) => {
                panic!("ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ê²°ê³¼: {}", error);
            },
            Ok(StageResult::RecoverableError { error, .. }) => {
                panic!("ì˜ˆìƒì¹˜ ëª»í•œ ë³µêµ¬ ê°€ëŠ¥í•œ ì—ëŸ¬: {}", error);
            },
            Ok(StageResult::FatalError { error, .. }) => {
                panic!("ì˜ˆìƒì¹˜ ëª»í•œ ì¹˜ëª…ì  ì—ëŸ¬: {}", error);
            },
            Ok(StageResult::PartialSuccess { success_items, .. }) => {
                println!("âœ… ë¶€ë¶„ ì„±ê³µ: {}", success_items.processed_items);
            },
            Err(_) => {
                panic!("OneShot ì±„ë„ ìˆ˜ì‹  ì‹¤íŒ¨");
            }
        }

        println!("ğŸ¯ ê¸°ë³¸ OneShot ì±„ë„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    #[tokio::test]
    async fn test_retry_calculator() {
        println!("ğŸ§ª RetryCalculator í…ŒìŠ¤íŠ¸ ì‹œì‘");

        let calculator = RetryCalculator::new(3, 100, 5000, 2.0, true);

        // ì²« ë²ˆì§¸ ì‹œë„
        assert!(calculator.should_retry(1));
        let delay1 = calculator.calculate_delay(1);
        println!("   1ì°¨ ì¬ì‹œë„ ì§€ì—°: {}ms", delay1);
        assert!(delay1 >= 50 && delay1 <= 150); // ì§€í„° í¬í•¨ ë²”ìœ„

        // ë‘ ë²ˆì§¸ ì‹œë„
        assert!(calculator.should_retry(2));
        let delay2 = calculator.calculate_delay(2);
        println!("   2ì°¨ ì¬ì‹œë„ ì§€ì—°: {}ms", delay2);
        assert!(delay2 >= 100 && delay2 <= 300); // ì§€í„° í¬í•¨ ë²”ìœ„

        // ìµœëŒ€ ì‹œë„ ì´ˆê³¼
        assert!(!calculator.should_retry(3));
        assert!(!calculator.should_retry(4));

        println!("ğŸ¯ RetryCalculator í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    #[tokio::test]
    async fn test_stage_execution_stats() {
        println!("ğŸ§ª StageExecutionStats í…ŒìŠ¤íŠ¸ ì‹œì‘");

        let mut stats = StageExecutionStats::default();

        // ì—¬ëŸ¬ ìŠ¤í…Œì´ì§€ ì‹¤í–‰ ê¸°ë¡
        stats.update_stage_execution(StageType::Collection, Duration::from_millis(500), true);
        stats.update_stage_execution(StageType::Collection, Duration::from_millis(600), true);
        stats.update_stage_execution(StageType::Collection, Duration::from_millis(400), false);

        stats.update_stage_execution(StageType::Processing, Duration::from_millis(200), true);
        stats.update_stage_execution(StageType::Processing, Duration::from_millis(250), true);

        // í†µê³„ í™•ì¸
        assert_eq!(stats.stage_durations.len(), 2);
        assert!(stats.stage_durations.contains_key("Collection"));
        assert!(stats.stage_durations.contains_key("Processing"));

        // Collection ìŠ¤í…Œì´ì§€: 3ë²ˆ ì‹œë„, 2ë²ˆ ì„±ê³µ
        let collection_stats = stats.stage_success_rates.get("Collection").unwrap();
        assert_eq!(collection_stats.0, 2); // ì„±ê³µ íšŸìˆ˜
        assert_eq!(collection_stats.1, 3); // ì´ ì‹œë„ íšŸìˆ˜

        // Processing ìŠ¤í…Œì´ì§€: 2ë²ˆ ì‹œë„, 2ë²ˆ ì„±ê³µ
        let processing_stats = stats.stage_success_rates.get("Processing").unwrap();
        assert_eq!(processing_stats.0, 2); // ì„±ê³µ íšŸìˆ˜
        assert_eq!(processing_stats.1, 2); // ì´ ì‹œë„ íšŸìˆ˜

        println!("âœ… Collection ì„±ê³µë¥ : {}/{}", collection_stats.0, collection_stats.1);
        println!("âœ… Processing ì„±ê³µë¥ : {}/{}", processing_stats.0, processing_stats.1);

        println!("ğŸ¯ StageExecutionStats í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    #[tokio::test]
    async fn test_actor_error_display() {
        println!("ğŸ§ª ActorError Display í…ŒìŠ¤íŠ¸ ì‹œì‘");

        let errors = vec![
            ActorError::ChannelError("ì±„ë„ ì—ëŸ¬ í…ŒìŠ¤íŠ¸".to_string()),
            ActorError::TimeoutError("íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ í…ŒìŠ¤íŠ¸".to_string()),
            ActorError::ProcessingError("ì²˜ë¦¬ ì—ëŸ¬ í…ŒìŠ¤íŠ¸".to_string()),
            ActorError::ConfigurationError("ì„¤ì • ì—ëŸ¬ í…ŒìŠ¤íŠ¸".to_string()),
        ];

        for (i, error) in errors.iter().enumerate() {
            let error_str = format!("{}", error);
            println!("   ì—ëŸ¬ {}: {}", i + 1, error_str);
            assert!(!error_str.is_empty());
        }

        println!("ğŸ¯ ActorError Display í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    #[tokio::test]
    async fn test_stage_error_display() {
        println!("ğŸ§ª StageError Display í…ŒìŠ¤íŠ¸ ì‹œì‘");

        let errors = vec![
            StageError::NetworkError { message: "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨".to_string() },
            StageError::ParsingError { message: "HTML íŒŒì‹± ì‹¤íŒ¨".to_string() },
            StageError::ResourceExhausted { message: "ë¦¬ì†ŒìŠ¤ ë¶€ì¡±".to_string() },
        ];

        for (i, error) in errors.iter().enumerate() {
            let error_str = format!("{}", error);
            println!("   ì—ëŸ¬ {}: {}", i + 1, error_str);
            assert!(!error_str.is_empty());
            
            // ì‹¤ì œ ì—ëŸ¬ ë©”ì‹œì§€ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            match error {
                StageError::NetworkError { message } => assert!(error_str.contains(message)),
                StageError::ParsingError { message } => assert!(error_str.contains(message)),
                StageError::NetworkTimeout { message } => assert!(error_str.contains(message)),
                StageError::ValidationError { message } => assert!(error_str.contains(message)),
                StageError::ChannelError { message } => assert!(error_str.contains(message)),
                StageError::DatabaseError { message } => assert!(error_str.contains(message)),
                StageError::ResourceExhausted { message } => assert!(error_str.contains(message)),
                StageError::ConfigurationError { message } => assert!(error_str.contains(message)),
                // Phase 3: TaskActor ê´€ë ¨ ì—ëŸ¬ í…ŒìŠ¤íŠ¸ ì¶”ê°€
                StageError::TaskCancelled { task_id } => assert!(error_str.contains(task_id)),
                StageError::TaskExecutionFailed { task_id, message } => {
                    assert!(error_str.contains(task_id));
                    assert!(error_str.contains(message));
                },
            }
        }

        println!("ğŸ¯ StageError Display í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    #[tokio::test]
    async fn test_mpsc_channel_communication() {
        println!("ğŸ§ª MPSC ì±„ë„ í†µì‹  í…ŒìŠ¤íŠ¸ ì‹œì‘");

        let (tx, mut rx) = mpsc::channel::<AppEvent>(10);

        // ì—¬ëŸ¬ ì´ë²¤íŠ¸ ì „ì†¡
        let events = vec![
            AppEvent::BatchStarted { batch_id: "batch-001".to_string() },
            AppEvent::StageCompleted { 
                stage: StageType::Collection,
                result: StageResult::Success(StageSuccessResult {
                    processed_items: 3,
                    stage_duration_ms: 500,
                    collection_metrics: None,
                    processing_metrics: None,
                })
            },
            AppEvent::BatchCompleted { 
                batch_id: "batch-001".to_string(),
                success_count: 0,
            },
        ];

        // ì´ë²¤íŠ¸ ì „ì†¡
        for event in events {
            tx.send(event).await.expect("ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨");
        }

        // ì´ë²¤íŠ¸ ìˆ˜ì‹  í™•ì¸
        let mut received_count = 0;
        while let Some(event) = rx.recv().await {
            received_count += 1;
            println!("   ìˆ˜ì‹ ëœ ì´ë²¤íŠ¸ {}: {:?}", received_count, event);
            
            if received_count >= 3 {
                break;
            }
        }

        assert_eq!(received_count, 3);
        println!("ğŸ¯ MPSC ì±„ë„ í†µì‹  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    /// **ğŸš€ OneShot í†µí•© í…ŒìŠ¤íŠ¸: ì „ì²´ Actor ì‹œìŠ¤í…œ ê²€ì¦**
    #[tokio::test]
    async fn test_comprehensive_oneshot_integration() {
        println!("ğŸ§ª **í¬ê´„ì  OneShot í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘** ğŸ§ª");
        
        // 1. í…ŒìŠ¤íŠ¸ ì„¤ì •
        let config = Arc::new(SystemConfig::default());
        let (event_tx, mut event_rx) = mpsc::channel::<AppEvent>(100);
        let (command_tx, command_rx) = mpsc::channel::<ActorCommand>(100);
        
        println!("   âœ… 1ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì±„ë„ ë° ì„¤ì • ì´ˆê¸°í™” ì™„ë£Œ");
        
        // 2. SessionActor ìƒì„± ë° ìŠ¤í°
        let mut session_actor = SessionActor::new(
            config.clone(),
            command_rx,
            event_tx.clone(),
        );
        
        let session_handle = tokio::spawn(async move {
            session_actor.run().await
        });
        
        println!("   âœ… 2ë‹¨ê³„: SessionActor ìŠ¤í° ì™„ë£Œ");
        
        // 3. BatchPlan ìƒì„± (í˜ì´ì§€ 3ê°œ ì²˜ë¦¬)
        let batch_plan = BatchPlan {
            batch_id: "test-batch-oneshot".to_string(),
            pages: vec![1, 2, 3],
            config: BatchConfig {
                target_url: "https://example.com".to_string(),
                max_pages: Some(10),
            },
            batch_size: 2,
            concurrency_limit: 3,
        };
        
        println!("   âœ… 3ë‹¨ê³„: BatchPlan ì„¤ì • ì™„ë£Œ (3ê°œ í˜ì´ì§€, ë°°ì¹˜í¬ê¸° 2)");
        
        // 4. ProcessBatch ëª…ë ¹ ì „ì†¡
        let process_command = ActorCommand::ProcessBatch {
            pages: batch_plan.pages.clone(),
            config: batch_plan.config.clone(),
            batch_size: batch_plan.batch_size,
            concurrency_limit: batch_plan.concurrency_limit,
        };
        
        command_tx.send(process_command).await.expect("ëª…ë ¹ ì „ì†¡ ì‹¤íŒ¨");
        println!("   âœ… 4ë‹¨ê³„: ProcessBatch ëª…ë ¹ ì „ì†¡ ì™„ë£Œ");
        
        // 5. ì´ë²¤íŠ¸ ìˆ˜ì‹  ë° ê²€ì¦
        let mut session_started = false;
        let mut batch_completed = false;
        
        // ìµœëŒ€ 3ì´ˆ ë™ì•ˆ ì´ë²¤íŠ¸ ëŒ€ê¸°
        let event_timeout = Duration::from_secs(3);
        let start_time = Instant::now();
        
        while start_time.elapsed() < event_timeout {
            match timeout(Duration::from_millis(300), event_rx.recv()).await {
                Ok(Some(event)) => {
                    match event {
                        AppEvent::SessionStarted { .. } => {
                            session_started = true;
                            println!("   âœ… 5-aë‹¨ê³„: SessionStarted ì´ë²¤íŠ¸ ìˆ˜ì‹ ");
                        }
                        AppEvent::BatchCompleted { batch_id, success_count } => {
                            batch_completed = true;
                            println!("   âœ… 5-bë‹¨ê³„: BatchCompleted ì´ë²¤íŠ¸ ìˆ˜ì‹  (ë°°ì¹˜: {}, ì„±ê³µ: {})", batch_id, success_count);
                            break; // ì™„ë£Œ ì´ë²¤íŠ¸ ìˆ˜ì‹  ì‹œ ì¢…ë£Œ
                        }
                        AppEvent::BatchFailed { batch_id, error, final_failure } => {
                            println!("   âš ï¸  BatchFailed ì´ë²¤íŠ¸: {} - {} (ìµœì¢…ì‹¤íŒ¨: {})", batch_id, error, final_failure);
                            if final_failure {
                                break;
                            }
                        }
                        AppEvent::SessionTimeout { .. } => {
                            println!("   âš ï¸  SessionTimeout ì´ë²¤íŠ¸ ìˆ˜ì‹ ");
                            break;
                        }
                        _ => {
                            println!("   ğŸ“¢ ê¸°íƒ€ ì´ë²¤íŠ¸ ìˆ˜ì‹ : {:?}", event);
                        }
                    }
                }
                Ok(None) => {
                    println!("   âš ï¸  ì´ë²¤íŠ¸ ì±„ë„ ì¢…ë£Œ");
                    break;
                }
                Err(_) => {
                    // íƒ€ì„ì•„ì›ƒ - ê³„ì† ëŒ€ê¸°
                }
            }
        }
        
        // 6. ì„¸ì…˜ ì •ë¦¬
        drop(command_tx); // ëª…ë ¹ ì±„ë„ ë‹«ê¸°
        
        // SessionActor ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 1ì´ˆ)
        match timeout(Duration::from_secs(1), session_handle).await {
            Ok(result) => {
                match result {
                    Ok(Ok(())) => println!("   âœ… 6ë‹¨ê³„: SessionActor ì •ìƒ ì¢…ë£Œ"),
                    Ok(Err(e)) => println!("   âš ï¸  SessionActor ì˜¤ë¥˜ ì¢…ë£Œ: {}", e),
                    Err(e) => println!("   âš ï¸  SessionActor íŒ¨ë‹‰: {}", e),
                }
            }
            Err(_) => {
                println!("   âš ï¸  SessionActor ì¢…ë£Œ íƒ€ì„ì•„ì›ƒ");
            }
        }
        
        // 7. ê²°ê³¼ ê²€ì¦
        println!("   ğŸ“Š **OneShot í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê²€ì¦**");
        
        if session_started {
            println!("   âœ… SessionStarted ì´ë²¤íŠ¸ ìˆ˜ì‹  í™•ì¸");
        } else {
            println!("   âŒ SessionStarted ì´ë²¤íŠ¸ ëˆ„ë½");
        }
        
        if batch_completed {
            println!("   âœ… BatchCompleted ì´ë²¤íŠ¸ ìˆ˜ì‹  í™•ì¸");
        } else {
            println!("   âš ï¸  BatchCompleted ì´ë²¤íŠ¸ ëˆ„ë½ (ì¬ì‹œë„ ë˜ëŠ” ë¶€ë¶„ ì„±ê³µ ê°€ëŠ¥)");
        }
        
        println!("ğŸ¯ **í¬ê´„ì  OneShot í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!** ğŸ¯");
        
        // ì ì–´ë„ ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆì–´ì•¼ í•¨
        assert!(session_started, "SessionStarted ì´ë²¤íŠ¸ê°€ ìˆ˜ì‹ ë˜ì§€ ì•ŠìŒ");
    }

    /// **ğŸ”„ ì¬ì‹œë„ ì •ì±… í†µí•© í…ŒìŠ¤íŠ¸**
    #[tokio::test]
    async fn test_retry_policy_integration() {
        println!("ğŸ§ª ì¬ì‹œë„ ì •ì±… í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘");
        
        let retry_calculator = RetryCalculator::new(3, 100, 2000, 2.0, true);
        
        // ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ í…ŒìŠ¤íŠ¸
        let network_error = StageError::NetworkError {
            message: "Connection timeout".to_string(),
        };
        
        assert!(retry_calculator.should_retry_with_policy(&network_error, 0));
        assert!(retry_calculator.should_retry_with_policy(&network_error, 1));
        assert!(retry_calculator.should_retry_with_policy(&network_error, 2));
        assert!(!retry_calculator.should_retry_with_policy(&network_error, 3));
        
        // ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬ í…ŒìŠ¤íŠ¸
        let parsing_error = StageError::ParsingError {
            message: "Invalid JSON".to_string(),
        };
        
        assert!(!retry_calculator.should_retry_with_policy(&parsing_error, 0));
        assert!(!retry_calculator.should_retry_with_policy(&parsing_error, 1));
        
        // ì§€ì—° ì‹œê°„ í…ŒìŠ¤íŠ¸
        let delay1 = retry_calculator.calculate_delay(1);
        let delay2 = retry_calculator.calculate_delay(2);
        let delay3 = retry_calculator.calculate_delay(3);
        
        println!("   ì¬ì‹œë„ ì§€ì—°ì‹œê°„: 1ì°¨={}ms, 2ì°¨={}ms, 3ì°¨={}ms", delay1, delay2, delay3);
        
        // ì§€ìˆ˜ ë°±ì˜¤í”„ í™•ì¸ (ì§€í„° ë•Œë¬¸ì— ì •í™•í•œ ê°’ì€ í™•ì¸í•  ìˆ˜ ì—†ì§€ë§Œ ì¦ê°€ ê²½í–¥ì€ í™•ì¸ ê°€ëŠ¥)
        assert!(delay2 >= delay1 / 2); // ì§€í„°ë¥¼ ê³ ë ¤í•œ ìµœì†Œ ì¦ê°€
        assert!(delay3 >= delay2 / 2); // ì§€í„°ë¥¼ ê³ ë ¤í•œ ìµœì†Œ ì¦ê°€
        
        println!("ğŸ¯ ì¬ì‹œë„ ì •ì±… í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }

    /// **ğŸ“¡ ì±„ë„ í†µì‹  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**
    #[tokio::test]
    async fn test_channel_performance() {
        println!("ğŸ§ª ì±„ë„ í†µì‹  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘");
        
        // OneShot ì±„ë„ ìƒì„± ì‹œê°„ ì¸¡ì •
        let start_time = Instant::now();
        
        let mut oneshot_channels = Vec::new();
        for _ in 0..100 {
            let (tx, rx) = oneshot::channel::<StageResult>();
            oneshot_channels.push((tx, rx));
        }
        
        let creation_time = start_time.elapsed();
        println!("   OneShot ì±„ë„ 100ê°œ ìƒì„± ì‹œê°„: {:?}", creation_time);
        
        // MPSC ì±„ë„ í†µì‹  ì‹œê°„ ì¸¡ì •
        let (mpsc_tx, mut mpsc_rx) = mpsc::channel(100);
        
        let send_start = Instant::now();
        for i in 0..100 {
            let command = ActorCommand::ProcessBatch {
                pages: vec![i],
                config: BatchConfig {
                    target_url: "https://example.com".to_string(),
                    max_pages: Some(10),
                },
                batch_size: 1,
                concurrency_limit: 1,
            };
            mpsc_tx.send(command).await.expect("ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨");
        }
        
        let send_time = send_start.elapsed();
        println!("   MPSC ë©”ì‹œì§€ 100ê°œ ì „ì†¡ ì‹œê°„: {:?}", send_time);
        
        // ìˆ˜ì‹  ì‹œê°„ ì¸¡ì •
        let recv_start = Instant::now();
        let mut received_count = 0;
        
        while received_count < 100 {
            if let Ok(Some(_)) = timeout(Duration::from_millis(1), mpsc_rx.recv()).await {
                received_count += 1;
            } else {
                break;
            }
        }
        
        let recv_time = recv_start.elapsed();
        println!("   MPSC ë©”ì‹œì§€ {}ê°œ ìˆ˜ì‹  ì‹œê°„: {:?}", received_count, recv_time);
        
        // ì„±ëŠ¥ ê²€ì¦
        assert!(creation_time < Duration::from_millis(100), "ì±„ë„ ìƒì„±ì´ ë„ˆë¬´ ëŠë¦¼");
        assert!(send_time < Duration::from_millis(50), "ë©”ì‹œì§€ ì „ì†¡ì´ ë„ˆë¬´ ëŠë¦¼");
        
        println!("ğŸ¯ ì±„ë„ í†µì‹  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    }
}
