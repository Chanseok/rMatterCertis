//! DataConsistencyChecker
//! DBì˜ products í…Œì´ë¸”ì— ì €ì¥ëœ page_id, index_in_page ê°’ì´
//! í˜„ì¬ ì‚¬ì´íŠ¸ êµ¬ì¡°( total_pages, last page ì œí’ˆ ìˆ˜ )ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦.
//!
//! ê²€ì¦ ë°©ì‹:
//! 1) ì‚¬ì´íŠ¸ ìƒíƒœ(StatusChecker)ë¡œ total_pages, products_on_last_page íšë“
//! 2) ëª¨ë“  products (page_id, index_in_page, page_id NULL ì œì™¸) ì¡°íšŒ
//! 3) ì—­ì‚°(reverse_calculate)ì„ í†µí•´ (ë¬¼ë¦¬ì  í˜ì´ì§€, ë¬¼ë¦¬ì  ì¸ë±ìŠ¤) -> ë‹¤ì‹œ ì •ë°©í–¥ calculate í›„ ë™ì¼ì„± í™•ì¸
//! 4) ë¶ˆì¼ì¹˜/ê²½ê³„ ì˜¤ë¥˜/ë²”ìœ„ ì´ˆê³¼ ë“±ì„ ì§‘ê³„
//! 5) JSON í˜•íƒœ ìš”ì•½ ë°˜í™˜ (ëª…ì„¸: DataConsistencyReport)
use std::sync::Arc;
use serde::{Serialize, Deserialize};
use anyhow::Result;
use tracing::info;

use crate::domain::pagination::CanonicalPageIdCalculator;
use sqlx::Row; // trait for row.get
use crate::domain::services::StatusChecker;
use crate::infrastructure::IntegratedProductRepository;

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct InconsistentRecord {
    pub url: String,
    pub stored_page_id: i32,
    pub stored_index_in_page: i32,
    pub recomputed_page_id: i32,
    pub recomputed_index_in_page: i32,
    pub physical_page: u32,
    pub physical_index: usize,
    pub reason: String,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct DataConsistencyReport {
    pub total_checked: u64,
    pub valid: u64,
    pub invalid: u64,
    pub skipped_null_page_id: u64,
    pub total_pages_site: u32,
    pub products_on_last_page_site: u32,
    pub sample_inconsistencies: Vec<InconsistentRecord>,
    pub max_samples: usize,
}

pub struct DataConsistencyChecker {
    status_checker: Arc<dyn StatusChecker>,
    product_repo: Arc<IntegratedProductRepository>,
    max_samples: usize,
}

impl DataConsistencyChecker {
    pub fn new(status_checker: Arc<dyn StatusChecker>, product_repo: Arc<IntegratedProductRepository>) -> Self {
        Self { status_checker, product_repo, max_samples: 50 }
    }

    pub fn with_max_samples(mut self, samples: usize) -> Self { self.max_samples = samples; self }

    pub async fn run_check(&self) -> Result<DataConsistencyReport> {
        // 1. ì‚¬ì´íŠ¸ ìƒíƒœ íšë“
        let site_status = self.status_checker.check_site_status().await?;
    let total_pages = if site_status.total_pages == 0 { 1 } else { site_status.total_pages };
    let products_on_last_page = site_status.products_on_last_page; // u32
    let calculator = CanonicalPageIdCalculator::new(total_pages, products_on_last_page as usize);

        // 2. products í…Œì´ë¸”ì—ì„œ í•„ìš”í•œ í•„ë“œ ì¡°íšŒ
        // NOTE: compile-time query macros (query!) require offline DB schema; fallback to dynamic query + manual extraction
        let rows = sqlx::query(
            "SELECT url, page_id, index_in_page FROM products"
        )
        .fetch_all(&*self.product_repo.pool())
        .await?;

        let mut valid = 0u64;
        let mut invalid = 0u64;
        let mut skipped_null = 0u64;
        let mut samples: Vec<InconsistentRecord> = Vec::new();

        for row in rows {
            let url: String = row.get("url");
            let stored_page_id: Option<i32> = row.get::<Option<i32>, _>("page_id");
            let stored_index_in_page: Option<i32> = row.get::<Option<i32>, _>("index_in_page");
            let Some(stored_page_id) = stored_page_id else { skipped_null += 1; continue; };
            let Some(stored_index_in_page) = stored_index_in_page else { skipped_null += 1; continue; };
            // ì—­ë°©í–¥ ê³„ì‚°: (page_id, index_in_page) -> (physical_page, physical_index)
            match calculator.reverse_calculate(stored_page_id, stored_index_in_page) {
                Some((phys_page, phys_index)) => {
                    // ì •ë°©í–¥ ì¬ê³„ì‚°
                    let recalc = calculator.calculate(phys_page, phys_index);
                    if recalc.page_id == stored_page_id && recalc.index_in_page == stored_index_in_page {
                        valid += 1;
                    } else {
                        invalid += 1;
                        if samples.len() < self.max_samples {
                            samples.push(InconsistentRecord {
                                url: url.clone(),
                                stored_page_id,
                                stored_index_in_page,
                                recomputed_page_id: recalc.page_id,
                                recomputed_index_in_page: recalc.index_in_page,
                                physical_page: phys_page,
                                physical_index: phys_index,
                                reason: "Recalculation mismatch".into(),
                            });
                        }
                    }
                }
                None => {
                    invalid += 1;
                    if samples.len() < self.max_samples {
                        samples.push(InconsistentRecord {
                            url,
                            stored_page_id,
                            stored_index_in_page,
                            recomputed_page_id: -1,
                            recomputed_index_in_page: -1,
                            physical_page: 0,
                            physical_index: 0,
                            reason: "Reverse calculation failed (out of range)".into(),
                        });
                    }
                }
            }
        }

        let report = DataConsistencyReport {
            total_checked: valid + invalid + skipped_null,
            valid,
            invalid,
            skipped_null_page_id: skipped_null,
            total_pages_site: total_pages,
            products_on_last_page_site: products_on_last_page,
            sample_inconsistencies: samples,
            max_samples: self.max_samples,
        };
        info!("ğŸ§ª DataConsistencyChecker report: total={} valid={} invalid={} skipped_null={}", report.total_checked, report.valid, report.invalid, report.skipped_null_page_id);
        Ok(report)
    }
}
