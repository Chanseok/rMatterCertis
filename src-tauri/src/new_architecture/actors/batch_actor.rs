//! BatchActor: ë°°ì¹˜ ë‹¨ìœ„ í¬ë¡¤ë§ ì²˜ë¦¬ Actor
//! 
//! Phase 3: Actor êµ¬í˜„ - ë°°ì¹˜ ë ˆë²¨ ì‘ì—… ê´€ë¦¬ ë° ì‹¤í–‰
//! Modern Rust 2024 ì¤€ìˆ˜: í•¨ìˆ˜í˜• ì›ì¹™, ëª…ì‹œì  ì˜ì¡´ì„±, ìƒíƒœ ìµœì†Œí™”

#![warn(clippy::all, clippy::pedantic, clippy::nursery)]
#![deny(clippy::unwrap_used, clippy::expect_used, clippy::panic)]

use std::sync::Arc;
use std::time::Instant;
use tokio::sync::{mpsc, Semaphore};
use tracing::{info, warn, error, debug};
use chrono::Utc;

use super::traits::{Actor, ActorHealth, ActorStatus, ActorType};
use super::types::{ActorCommand, BatchConfig, StageType, StageResult, ActorError};
use crate::new_architecture::channels::types::{AppEvent, StageItem, ProductUrls};  // enum ë²„ì „ì˜ StageItemê³¼ ProductUrls ì‚¬ìš©
use crate::new_architecture::context::AppContext;
use crate::new_architecture::actors::StageActor;

// ì‹¤ì œ ì„œë¹„ìŠ¤ imports ì¶”ê°€
use crate::infrastructure::{HttpClient, MatterDataExtractor, IntegratedProductRepository};
use crate::infrastructure::config::AppConfig;

/// BatchActor: ë°°ì¹˜ ë‹¨ìœ„ì˜ í¬ë¡¤ë§ ì‘ì—… ê´€ë¦¬
/// 
/// ì±…ì„:
/// - ë°°ì¹˜ ë‚´ í˜ì´ì§€ë“¤ì˜ ë³‘ë ¬ ì²˜ë¦¬ ê´€ë¦¬
/// - StageActorë“¤ì˜ ì¡°ì • ë° ìŠ¤ì¼€ì¤„ë§
/// - ë°°ì¹˜ ë ˆë²¨ ì´ë²¤íŠ¸ ë°œí–‰
/// - ë™ì‹œì„± ì œì–´ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
pub struct BatchActor {
    /// Actor ê³ ìœ  ì‹ë³„ì
    actor_id: String,
    /// í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜ ID (OneShot í˜¸í™˜ì„±)
    pub batch_id: Option<String>,
    /// ë°°ì¹˜ ìƒíƒœ
    state: BatchState,
    /// ë°°ì¹˜ ì‹œì‘ ì‹œê°„
    start_time: Option<Instant>,
    /// ì´ í˜ì´ì§€ ìˆ˜
    total_pages: u32,
    /// ì²˜ë¦¬ ì™„ë£Œëœ í˜ì´ì§€ ìˆ˜
    completed_pages: u32,
    /// ì„±ê³µí•œ ì•„ì´í…œ ìˆ˜
    success_count: u32,
    /// ì‹¤íŒ¨í•œ ì•„ì´í…œ ìˆ˜
    failure_count: u32,
    /// ë™ì‹œì„± ì œì–´ìš© ì„¸ë§ˆí¬ì–´
    concurrency_limiter: Option<Arc<Semaphore>>,
    /// ì„¤ì • (OneShot í˜¸í™˜ì„±)
    pub config: Option<Arc<crate::new_architecture::config::SystemConfig>>,
    
    // ğŸ”¥ Phase 1: ì‹¤ì œ ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì¶”ê°€
    /// HTTP í´ë¼ì´ì–¸íŠ¸
    http_client: Option<Arc<HttpClient>>,
    /// ë°ì´í„° ì¶”ì¶œê¸°
    data_extractor: Option<Arc<MatterDataExtractor>>,
    /// ì œí’ˆ ë ˆí¬ì§€í† ë¦¬
    product_repo: Option<Arc<IntegratedProductRepository>>,
    /// ì•± ì„¤ì •
    app_config: Option<AppConfig>,
}

// Debug ìˆ˜ë™ êµ¬í˜„ (ì˜ì¡´ì„±ë“¤ì´ Debugë¥¼ êµ¬í˜„í•˜ì§€ ì•Šì•„ì„œ)
impl std::fmt::Debug for BatchActor {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("BatchActor")
            .field("actor_id", &self.actor_id)
            .field("batch_id", &self.batch_id)
            .field("state", &self.state)
            .field("start_time", &self.start_time)
            .field("total_pages", &self.total_pages)
            .field("completed_pages", &self.completed_pages)
            .field("success_count", &self.success_count)
            .field("failure_count", &self.failure_count)
            .field("has_http_client", &self.http_client.is_some())
            .field("has_data_extractor", &self.data_extractor.is_some())
            .field("has_product_repo", &self.product_repo.is_some())
            .field("has_app_config", &self.app_config.is_some())
            .finish()
    }
}

/// ë°°ì¹˜ ìƒíƒœ ì—´ê±°í˜•
#[derive(Debug, Clone, PartialEq)]
pub enum BatchState {
    Idle,
    Starting,
    Processing,
    Paused,
    Completing,
    Completed,
    Failed { error: String },
}

/// ë°°ì¹˜ ê´€ë ¨ ì—ëŸ¬ íƒ€ì…
#[derive(Debug, thiserror::Error)]
pub enum BatchError {
    #[error("Batch initialization failed: {0}")]
    InitializationFailed(String),
    
    #[error("Batch already processing: {0}")]
    AlreadyProcessing(String),
    
    #[error("Batch not found: {0}")]
    BatchNotFound(String),
    
    #[error("Invalid batch configuration: {0}")]
    InvalidConfiguration(String),
    
    #[error("Concurrency limit exceeded: requested {requested}, max {max}")]
    ConcurrencyLimitExceeded { requested: u32, max: u32 },
    
    #[error("Context communication error: {0}")]
    ContextError(String),
    
    #[error("Stage processing error: {0}")]
    StageError(String),
    
    #[error("Stage processing failed: {stage} - {error}")]
    StageProcessingFailed { stage: String, error: String },
    
    #[error("Stage execution failed: {0}")]
    StageExecutionFailed(String),
    
    #[error("Service not available: {0}")]
    ServiceNotAvailable(String),
}

impl BatchActor {
    /// ìƒˆë¡œìš´ BatchActor ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ê¸°ë³¸)
    /// 
    /// # Arguments
    /// * `actor_id` - Actor ê³ ìœ  ì‹ë³„ì
    /// 
    /// # Returns
    /// * `Self` - ìƒˆë¡œìš´ BatchActor ì¸ìŠ¤í„´ìŠ¤
    pub fn new(actor_id: String) -> Self {
        Self {
            actor_id,
            batch_id: None,
            state: BatchState::Idle,
            start_time: None,
            total_pages: 0,
            completed_pages: 0,
            success_count: 0,
            failure_count: 0,
            concurrency_limiter: None,
            config: None,
            // ìƒˆë¡œ ì¶”ê°€ëœ í•„ë“œë“¤ ì´ˆê¸°í™”
            http_client: None,
            data_extractor: None,
            product_repo: None,
            app_config: None,
        }
    }
    
    /// ğŸ”¥ Phase 1: ì‹¤ì œ ì„œë¹„ìŠ¤ë“¤ê³¼ í•¨ê»˜ BatchActor ìƒì„±
    /// 
    /// # Arguments
    /// * `actor_id` - Actor ê³ ìœ  ì‹ë³„ì
    /// * `batch_id` - ë°°ì¹˜ ID
    /// * `http_client` - HTTP í´ë¼ì´ì–¸íŠ¸
    /// * `data_extractor` - ë°ì´í„° ì¶”ì¶œê¸°
    /// * `product_repo` - ì œí’ˆ ë ˆí¬ì§€í† ë¦¬
    /// * `app_config` - ì•± ì„¤ì •
    /// 
    /// # Returns
    /// * `Self` - ì„œë¹„ìŠ¤ê°€ ì£¼ì…ëœ BatchActor ì¸ìŠ¤í„´ìŠ¤
    pub fn new_with_services(
        actor_id: String,
        batch_id: String,
        http_client: Arc<HttpClient>,
        data_extractor: Arc<MatterDataExtractor>,
        product_repo: Arc<IntegratedProductRepository>,
        app_config: AppConfig,
    ) -> Self {
        Self {
            actor_id,
            batch_id: Some(batch_id),
            state: BatchState::Idle,
            start_time: None,
            total_pages: 0,
            completed_pages: 0,
            success_count: 0,
            failure_count: 0,
            concurrency_limiter: None,
            config: None,
            // ì‹¤ì œ ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì£¼ì…
            http_client: Some(http_client),
            data_extractor: Some(data_extractor),
            product_repo: Some(product_repo),
            app_config: Some(app_config),
        }
    }
    
    /// ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘
    /// 
    /// # Arguments
    /// * `batch_id` - ë°°ì¹˜ ID
    /// * `pages` - ì²˜ë¦¬í•  í˜ì´ì§€ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
    /// * `config` - ë°°ì¹˜ ì„¤ì •
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    async fn process_list_page_batch(
        &mut self,
        stage_type: StageType,
        pages: Vec<u32>,
        config: BatchConfig,
        _batch_size: u32,
        concurrency_limit: u32,
        _total_pages: u32,
        _products_on_last_page: u32,
        context: &AppContext,
    ) -> Result<(), BatchError> {
        // ìƒíƒœ ê²€ì¦
        if !matches!(self.state, BatchState::Idle) {
            return Err(BatchError::AlreadyProcessing(batch_id));
        }
        
        // ì„¤ì • ê²€ì¦
        self.validate_batch_config(&config, concurrency_limit)?;
        
        info!("ğŸ”„ BatchActor {} starting batch {} with {} pages", 
              self.actor_id, batch_id, pages.len());
        
        // ìƒíƒœ ì´ˆê¸°í™”
        self.batch_id = Some(batch_id.clone());
        self.state = BatchState::Starting;
        self.start_time = Some(Instant::now());
        self.total_pages = pages.len() as u32;
        self.completed_pages = 0;
        self.success_count = 0;
        self.failure_count = 0;
        
        // ë™ì‹œì„± ì œì–´ ì„¤ì •
        self.concurrency_limiter = Some(Arc::new(Semaphore::new(concurrency_limit as usize)));
        
        // ë°°ì¹˜ ì‹œì‘ ì´ë²¤íŠ¸ ë°œí–‰
        let start_event = AppEvent::BatchStarted {
            batch_id: batch_id.clone(),
            session_id: context.session_id.clone(),
            pages_count: pages.len() as u32,
            timestamp: Utc::now(),
        };
        
        context.emit_event(start_event).await
            .map_err(|e| BatchError::ContextError(e.to_string()))?;
        
        // ìƒíƒœë¥¼ Processingìœ¼ë¡œ ì „í™˜
        self.state = BatchState::Processing;
        
        // ì‹¤ì œ StageActor ê¸°ë°˜ ì²˜ë¦¬ êµ¬í˜„
        info!("ğŸ­ Using real StageActor-based processing for batch {}", batch_id);
        
        // ì´ˆê¸° Stage Items ìƒì„± - í˜ì´ì§€ ê¸°ë°˜ ì•„ì´í…œë“¤
        let initial_items: Vec<StageItem> = pages.iter().map(|&page_number| {
            StageItem::Page(page_number)
        }).collect();

        // Stage 1: StatusCheck - ì‚¬ì´íŠ¸ ìƒíƒœ í™•ì¸
        info!("ğŸ” Starting Stage 1: StatusCheck");
        // StatusCheckëŠ” ì‚¬ì´íŠ¸ ì „ì²´ ìƒíƒœë¥¼ í™•ì¸í•˜ë¯€ë¡œ íŠ¹ë³„í•œ URL ì•„ì´í…œìœ¼ë¡œ ì²˜ë¦¬
        let status_check_items = vec![StageItem::Url("https://csa-iot.org/csa-iot_products/".to_string())];
        
        let status_check_result = self.execute_stage_with_actor(
            StageType::StatusCheck, 
            status_check_items, 
            concurrency_limit, 
            context
        ).await?;
        
        info!("âœ… Stage 1 (StatusCheck) completed: {} success, {} failed", 
              status_check_result.successful_items, status_check_result.failed_items);

        // StatusCheck ìŠ¤í…Œì´ì§€ëŠ” ì‚¬ì´íŠ¸ ì ‘ê·¼ì„± í™•ì¸ì´ë¯€ë¡œ íŠ¹ë³„ ì²˜ë¦¬
        // ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆë‹¤ë©´ (ì²˜ë¦¬ëœ ì•„ì´í…œì´ ìˆë‹¤ë©´) ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
        if status_check_result.processed_items == 0 {
            error!("âŒ Stage 1 (StatusCheck) failed completely - no status check performed");
            self.state = BatchState::Failed { error: "StatusCheck stage failed - no status check performed".to_string() };
            return Err(BatchError::StageExecutionFailed("StatusCheck stage failed - no status check performed".to_string()));
        }
        
        // StatusCheckì—ì„œ ì‚¬ì´íŠ¸ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ ì¤‘ë‹¨
        if status_check_result.failed_items > 0 && status_check_result.successful_items == 0 {
            error!("âŒ Stage 1 (StatusCheck) failed completely - site is not accessible");
            self.state = BatchState::Failed { error: "StatusCheck stage failed - site is not accessible".to_string() };
            return Err(BatchError::StageExecutionFailed("StatusCheck stage failed - site is not accessible".to_string()));
        }

        // Stage 2: ListPageCrawling - ProductURL ìˆ˜ì§‘
        info!("ğŸ” Starting Stage 2: ListPageCrawling");
        let list_page_result = self.execute_stage_with_actor(
            StageType::ListPageCrawling, 
            initial_items.clone(), 
            concurrency_limit, 
            context
        ).await?;
        
        info!("âœ… Stage 2 (ListPageCrawling) completed: {} success, {} failed", 
              list_page_result.successful_items, list_page_result.failed_items);

        // Stage ì‹¤íŒ¨ ì‹œ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨ ê²€ì¦
        if list_page_result.successful_items == 0 {
            error!("âŒ Stage 2 (ListPageCrawling) failed completely - aborting pipeline");
            self.state = BatchState::Failed { error: "ListPageCrawling stage failed completely".to_string() };
            return Err(BatchError::StageExecutionFailed("ListPageCrawling stage failed completely".to_string()));
        }

        // Stage 2 ê²°ê³¼ë¥¼ Stage 3 ì…ë ¥ìœ¼ë¡œ ë³€í™˜
        let product_detail_items = self.transform_stage_output(
            StageType::ListPageCrawling,
            initial_items.clone(),
            &list_page_result
        ).await?;

        // Stage 3: ProductDetailCrawling - ìƒí’ˆ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        info!("ğŸ” Starting Stage 3: ProductDetailCrawling");
        let detail_result = self.execute_stage_with_actor(
            StageType::ProductDetailCrawling, 
            product_detail_items, 
            concurrency_limit, 
            context
        ).await?;
        
        info!("âœ… Stage 3 (ProductDetailCrawling) completed: {} success, {} failed", 
              detail_result.successful_items, detail_result.failed_items);

        // Stage 3 ê²°ê³¼ë¥¼ Stage 4 ì…ë ¥ìœ¼ë¡œ ë³€í™˜ 
        let data_validation_items = self.transform_stage_output(
            StageType::ProductDetailCrawling,
            initial_items.clone(),
            &detail_result
        ).await?;

        // Stage 4: DataValidation - ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        info!("ğŸ” Starting Stage 4: DataValidation");
        let validation_result = self.execute_stage_with_actor(
            StageType::DataValidation, 
            data_validation_items.clone(), 
            concurrency_limit, 
            context
        ).await?;
        
        info!("âœ… Stage 4 (DataValidation) completed: {} success, {} failed", 
              validation_result.successful_items, validation_result.failed_items);

        // Stage 4 ê²°ê³¼ë¥¼ Stage 5 ì…ë ¥ìœ¼ë¡œ ë³€í™˜ 
        let data_saving_items = self.transform_stage_output(
            StageType::DataValidation,
            data_validation_items,
            &validation_result
        ).await?;

        // Stage 5: DataSaving - ë°ì´í„° ì €ì¥
        info!("ğŸ” Starting Stage 5: DataSaving");
        let saving_result = self.execute_stage_with_actor(
            StageType::DataSaving, 
            data_saving_items, 
            concurrency_limit, 
            context
        ).await?;
        
        info!("âœ… Stage 5 (DataSaving) completed: {} success, {} failed", 
              saving_result.successful_items, saving_result.failed_items);

        // ë°°ì¹˜ ê²°ê³¼ ì§‘ê³„
        self.success_count = saving_result.successful_items;
        self.completed_pages = pages.len() as u32;
        self.state = BatchState::Completed;
        
        let completion_event = AppEvent::BatchCompleted {
            batch_id: batch_id.clone(),
            session_id: context.session_id.clone(),
            success_count: self.success_count,
            failed_count: saving_result.failed_items,
            duration: self.start_time.map(|s| s.elapsed().as_millis() as u64).unwrap_or(0),
            timestamp: Utc::now(),
        };
        
        context.emit_event(completion_event).await
            .map_err(|e| BatchError::ContextError(e.to_string()))?;
        
        Ok(())
    }
    
    /// ë°°ì¹˜ ì„¤ì • ê²€ì¦
    /// 
    /// # Arguments
    /// * `config` - ë°°ì¹˜ ì„¤ì •
    /// * `concurrency_limit` - ë™ì‹œì„± ì œí•œ
    fn validate_batch_config(&self, config: &BatchConfig, concurrency_limit: u32) -> Result<(), BatchError> {
        if config.batch_size == 0 {
            return Err(BatchError::InvalidConfiguration("Batch size cannot be zero".to_string()));
        }
        
        if concurrency_limit == 0 {
            return Err(BatchError::InvalidConfiguration("Concurrency limit cannot be zero".to_string()));
        }
        
        const MAX_CONCURRENCY: u32 = 100;
        if concurrency_limit > MAX_CONCURRENCY {
            return Err(BatchError::ConcurrencyLimitExceeded {
                requested: concurrency_limit,
                max: MAX_CONCURRENCY,
            });
        }
        
        Ok(())
    }
    
    /// ë°°ì¹˜ ID ê²€ì¦
    /// 
    /// # Arguments
    /// * `batch_id` - ê²€ì¦í•  ë°°ì¹˜ ID
    #[allow(dead_code)]
    fn validate_batch(&self, batch_id: &str) -> Result<(), BatchError> {
        match &self.batch_id {
            Some(current_id) if current_id == batch_id => Ok(()),
            Some(current_id) => Err(BatchError::BatchNotFound(format!(
                "Expected {}, got {}", current_id, batch_id
            ))),
            None => Err(BatchError::BatchNotFound("No active batch".to_string())),
        }
    }
    
    /// ë°°ì¹˜ ì •ë¦¬
    fn cleanup_batch(&mut self) {
        self.batch_id = None;
        self.state = BatchState::Idle;
        self.start_time = None;
        self.total_pages = 0;
        self.completed_pages = 0;
        self.success_count = 0;
        self.failure_count = 0;
        self.concurrency_limiter = None;
    }
    
    /// ì§„í–‰ ìƒí™© ê³„ì‚°
    /// 
    /// # Returns
    /// * `f64` - ì§„í–‰ë¥  (0.0 ~ 1.0)
    fn calculate_progress(&self) -> f64 {
        if self.total_pages == 0 {
            0.0
        } else {
            f64::from(self.completed_pages) / f64::from(self.total_pages)
        }
    }
    
    /// ì²˜ë¦¬ ì†ë„ ê³„ì‚° (í˜ì´ì§€/ì´ˆ)
    /// 
    /// # Returns
    /// * `f64` - ì²˜ë¦¬ ì†ë„
    fn calculate_processing_rate(&self) -> f64 {
        if let Some(start_time) = self.start_time {
            let elapsed = start_time.elapsed();
            if elapsed.as_secs() > 0 {
                f64::from(self.completed_pages) / elapsed.as_secs_f64()
            } else {
                0.0
            }
        } else {
            0.0
        }
    }
}

#[async_trait::async_trait]
impl Actor for BatchActor {
    type Command = ActorCommand;
    type Error = ActorError;

    fn actor_id(&self) -> &str {
        &self.actor_id
    }

    fn actor_type(&self) -> ActorType {
        ActorType::Batch
    }    async fn run(
        &mut self,
        mut context: AppContext,
        mut command_rx: mpsc::Receiver<Self::Command>,
    ) -> Result<(), Self::Error> {
        info!("ğŸ”„ BatchActor {} starting execution loop", self.actor_id);
        
        loop {
            tokio::select! {
                // ëª…ë ¹ ì²˜ë¦¬
                command = command_rx.recv() => {
                    match command {
                        Some(cmd) => {
                            debug!("ğŸ“¨ BatchActor {} received command: {:?}", self.actor_id, cmd);
                            
                            match cmd {
                                ActorCommand::ProcessBatch { 
                                    batch_id, 
                                    pages, 
                                    config, 
                                    batch_size, 
                                    concurrency_limit, 
                                    total_pages, 
                                    products_on_last_page 
                                } => {
                                    if let Err(e) = self.handle_process_batch(
                                        batch_id, 
                                        pages, 
                                        config, 
                                        batch_size, 
                                        concurrency_limit, 
                                        total_pages, 
                                        products_on_last_page, 
                                        &context
                                    ).await {
                                        error!("Failed to process batch: {}", e);
                                    }
                                }
                                
                                ActorCommand::Shutdown => {
                                    info!("ğŸ›‘ BatchActor {} received shutdown command", self.actor_id);
                                    break;
                                }
                                
                                _ => {
                                    debug!("BatchActor {} ignoring non-batch command", self.actor_id);
                                }
                            }
                        }
                        None => {
                            warn!("ğŸ“ª BatchActor {} command channel closed", self.actor_id);
                            break;
                        }
                    }
                }
                
                // ì·¨ì†Œ ì‹ í˜¸ í™•ì¸
                _ = context.cancellation_token.changed() => {
                    // Cancellation ê°ì§€
                    if *context.cancellation_token.borrow() {
                        warn!("ğŸš« BatchActor {} received cancellation signal", self.actor_id);
                        break;
                    }
                }
            }
        }
        
        info!("ğŸ BatchActor {} execution loop ended", self.actor_id);
        Ok(())
    }
    
    async fn health_check(&self) -> Result<ActorHealth, Self::Error> {
        let status = match &self.state {
            BatchState::Idle => ActorStatus::Healthy,
            BatchState::Processing => ActorStatus::Healthy,
            BatchState::Completed => ActorStatus::Healthy,
            BatchState::Paused => ActorStatus::Degraded { 
                reason: "Batch paused".to_string(),
                since: Utc::now(),
            },
            BatchState::Failed { error } => ActorStatus::Unhealthy { 
                error: error.clone(),
                since: Utc::now(),
            },
            _ => ActorStatus::Degraded { 
                reason: format!("In transition state: {:?}", self.state),
                since: Utc::now(),
            },
        };
        
        Ok(ActorHealth {
            actor_id: self.actor_id.clone(),
            actor_type: ActorType::Batch,
            status,
            last_activity: Utc::now(),
            memory_usage_mb: 0, // TODO: ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
            active_tasks: if matches!(self.state, BatchState::Processing) { 
                self.total_pages - self.completed_pages 
            } else { 
                0 
            },
            commands_processed: 0, // TODO: ì‹¤ì œ ì²˜ë¦¬ëœ ëª…ë ¹ ìˆ˜ ê³„ì‚°
            errors_count: 0, // TODO: ì‹¤ì œ ì—ëŸ¬ ìˆ˜ ê³„ì‚°
            avg_command_processing_time_ms: 0.0, // TODO: ì‹¤ì œ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            metadata: serde_json::json!({
                "batch_id": self.batch_id,
                "state": format!("{:?}", self.state),
                "total_pages": self.total_pages,
                "completed_pages": self.completed_pages,
                "success_count": self.success_count,
                "failure_count": self.failure_count,
                "progress": self.calculate_progress(),
                "processing_rate": self.calculate_processing_rate()
            }).to_string(),
        })
    }
    
    async fn shutdown(&mut self) -> Result<(), Self::Error> {
        info!("ğŸ”Œ BatchActor {} shutting down", self.actor_id);
        
        // í™œì„± ë°°ì¹˜ê°€ ìˆë‹¤ë©´ ì •ë¦¬
        if self.batch_id.is_some() {
            warn!("Cleaning up active batch during shutdown");
            self.cleanup_batch();
        }
        
        Ok(())
    }
}

impl BatchActor {
    /// ê°œë³„ Stageë¥¼ StageActorë¡œ ì‹¤í–‰
    /// 
    /// # Arguments
    /// * `stage_type` - ì‹¤í–‰í•  ìŠ¤í…Œì´ì§€ íƒ€ì…
    /// * `items` - ì²˜ë¦¬í•  ì•„ì´í…œë“¤
    /// * `concurrency_limit` - ë™ì‹œ ì‹¤í–‰ ì œí•œ
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    async fn execute_stage_with_actor(
        &self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        context: &AppContext,
    ) -> Result<StageResult, BatchError> {
        // ì„œë¹„ìŠ¤ ì˜ì¡´ì„±ì´ ìˆëŠ”ì§€ í™•ì¸
        let http_client = self.http_client.as_ref()
            .ok_or_else(|| BatchError::ServiceNotAvailable("HttpClient not initialized".to_string()))?;
        let data_extractor = self.data_extractor.as_ref()
            .ok_or_else(|| BatchError::ServiceNotAvailable("MatterDataExtractor not initialized".to_string()))?;
        let product_repo = self.product_repo.as_ref()
            .ok_or_else(|| BatchError::ServiceNotAvailable("IntegratedProductRepository not initialized".to_string()))?;
        let app_config = self.app_config.as_ref()
            .ok_or_else(|| BatchError::ServiceNotAvailable("AppConfig not initialized".to_string()))?;

        // StageActor ìƒì„± (ì‹¤ì œ ì„œë¹„ìŠ¤ë“¤ê³¼ í•¨ê»˜)
        let mut stage_actor = StageActor::new_with_services(
            format!("stage_{}_{}", stage_type.as_str(), self.actor_id),
            self.batch_id.clone().unwrap_or_default(),
            Arc::clone(http_client),
            Arc::clone(data_extractor),
            Arc::clone(product_repo),
            app_config.clone(),
        );

        // StageActorë¡œ Stage ì‹¤í–‰ (ì‹¤ì œ items ì „ë‹¬)
        let stage_result = stage_actor.execute_stage(
            stage_type,
            items,
            concurrency_limit,
            30, // timeout_secs - 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            context,
        ).await
        .map_err(|e| BatchError::StageExecutionFailed(format!("Stage execution failed: {}", e)))?;

        Ok(stage_result)
    }

    /// Stage íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ - Stage ê°„ ë°ì´í„° ì „ë‹¬ êµ¬í˜„
    /// 
    /// # Arguments
    /// * `stage_type` - ì‹¤í–‰í•  ìŠ¤í…Œì´ì§€ íƒ€ì… (í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - ìˆœì°¨ ì‹¤í–‰)
    /// * `pages` - ì²˜ë¦¬í•  í˜ì´ì§€ë“¤
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    #[allow(dead_code)]
    async fn execute_stage(
        &mut self,
        _stage_type: StageType, // íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” ëª¨ë“  Stage ìˆœì°¨ ì‹¤í–‰
        pages: Vec<u32>,
        context: &AppContext,
    ) -> Result<StageResult, BatchError> {
        use crate::new_architecture::actors::StageActor;
        use crate::new_architecture::channels::types::StageItem;
        
        info!("ï¿½ Starting Stage pipeline processing for {} pages", pages.len());
        
        // Stage ì‹¤í–‰ ìˆœì„œ ì •ì˜
        let stages = vec![
            StageType::StatusCheck,
            StageType::ListPageCrawling, 
            StageType::ProductDetailCrawling,
            StageType::DataSaving,
        ];
        
        // ì´ˆê¸° ì…ë ¥: í˜ì´ì§€ë“¤ì„ StageItemìœ¼ë¡œ ë³€í™˜
        let mut current_items: Vec<StageItem> = pages.into_iter().map(|page| {
            StageItem::Page(page)
        }).collect();
        
        let mut final_result = StageResult {
            processed_items: 0,
            successful_items: 0, 
            failed_items: 0,
            duration_ms: 0,
            details: vec![],
        };
        
        // Stage íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        for (stage_idx, stage_type) in stages.iter().enumerate() {
            info!("ğŸ¯ Executing stage {} for {} items", stage_type.as_str(), current_items.len());
            
            // ğŸ”¥ Phase 1: ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ í•¨ê»˜ StageActor ìƒì„±
            let mut stage_actor = if let (Some(http_client), Some(data_extractor), Some(product_repo), Some(app_config)) = 
                (&self.http_client, &self.data_extractor, &self.product_repo, &self.app_config) {
                
                info!("âœ… Creating StageActor with real services");
                StageActor::new_with_services(
                    format!("stage_{}_{}", stage_type.as_str().to_lowercase(), self.actor_id),
                    self.batch_id.clone().unwrap_or_default(),
                    Arc::clone(http_client),
                    Arc::clone(data_extractor),
                    Arc::clone(product_repo),
                    app_config.clone(),
                )
            } else {
                warn!("âš ï¸  Creating StageActor without services - falling back to basic initialization");
                let mut stage_actor = StageActor::new(
                    format!("stage_{}_{}", stage_type.as_str().to_lowercase(), self.actor_id),
                );
                
                // ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œë„
                stage_actor.initialize_real_services(context).await
                    .map_err(|e| BatchError::StageProcessingFailed { 
                        stage: stage_type.as_str().to_string(), 
                        error: format!("Failed to initialize real services: {}", e) 
                    })?;
                    
                stage_actor
            };
            
            // Stage ì‹¤í–‰ (ì‹¤ì œ current_items ì „ë‹¬)
            let concurrency_limit = 5; // TODO: ì„¤ì • íŒŒì¼ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
            let timeout_secs = 300;
            
            let stage_result = stage_actor.execute_stage(
                stage_type.clone(),
                current_items.clone(),
                concurrency_limit,
                timeout_secs,
                context,
            ).await.map_err(|e| BatchError::StageProcessingFailed { 
                stage: stage_type.as_str().to_string(),
                error: format!("Stage execution failed: {:?}", e)
            })?;
            
            info!("âœ… Stage {} ({}) completed: {} success, {} failed", 
                  stage_idx + 1, stage_type.as_str(), stage_result.successful_items, stage_result.failed_items);
            
            // ìµœì¢… ê²°ê³¼ ëˆ„ì 
            final_result.processed_items += stage_result.processed_items;
            final_result.successful_items += stage_result.successful_items;
            final_result.failed_items += stage_result.failed_items;
            final_result.duration_ms += stage_result.duration_ms;
            
            // ë‹¤ìŒ Stageë¥¼ ìœ„í•œ ì…ë ¥ ë°ì´í„° ë³€í™˜
            current_items = self.transform_stage_output(stage_type.clone(), current_items, &stage_result).await?;
        }
        
        info!("âœ… All stages completed in pipeline");
        Ok(final_result)
    }
    
    /// Stage ì¶œë ¥ì„ ë‹¤ìŒ Stage ì…ë ¥ìœ¼ë¡œ ë³€í™˜
    async fn transform_stage_output(
        &self, 
        completed_stage: StageType, 
        input_items: Vec<StageItem>,
        stage_result: &StageResult
    ) -> Result<Vec<StageItem>, BatchError> {
        match completed_stage {
            StageType::StatusCheck => {
                // StatusCheck â†’ ListPageCrawling: Page ì•„ì´í…œ ê·¸ëŒ€ë¡œ ì „ë‹¬
                info!("ğŸ”„ StatusCheck â†’ ListPageCrawling: passing {} Page items", input_items.len());
                Ok(input_items)
            }
            StageType::ListPageCrawling => {
                // ListPageCrawling â†’ ProductDetailCrawling: ì‹¤ì œ ìˆ˜ì§‘ëœ ProductUrls ì‚¬ìš©
                info!("ğŸ”„ ListPageCrawling â†’ ProductDetailCrawling: extracting ProductUrls from collected data");
                
                let mut transformed_items = Vec::new();
                let mut total_urls_collected = 0;
                
                for (item_index, item) in input_items.iter().enumerate() {
                    if let StageItem::Page(page_number) = item {
                        // stage_resultì—ì„œ í•´ë‹¹ í˜ì´ì§€ì˜ ì‹¤í–‰ ê²°ê³¼ í™•ì¸
                        if let Some(stage_item_result) = stage_result.details.get(item_index) {
                            if stage_item_result.success {
                                // ì‹¤ì œ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                                if let Some(collected_data_json) = &stage_item_result.collected_data {
                                    // JSONì—ì„œ ProductURLë“¤ì„ íŒŒì‹±
                                    match serde_json::from_str::<Vec<crate::domain::product_url::ProductUrl>>(collected_data_json) {
                                        Ok(product_urls) => {
                                            // ProductURLë“¤ì„ Stringìœ¼ë¡œ ë³€í™˜
                                            let url_strings: Vec<String> = product_urls.iter()
                                                .map(|product_url| product_url.url.clone())
                                                .collect();
                                            
                                            if !url_strings.is_empty() {
                                                total_urls_collected += url_strings.len();
                                                
                                                let product_urls = ProductUrls {
                                                    urls: url_strings.clone(),
                                                    batch_id: Some(self.actor_id.clone()),
                                                };
                                                
                                                transformed_items.push(StageItem::ProductUrls(product_urls));
                                                
                                                info!("âœ… Extracted {} ProductURLs from page {}", url_strings.len(), page_number);
                                            } else {
                                                warn!("âš ï¸  Page {} crawling succeeded but no ProductURLs were collected", page_number);
                                            }
                                        }
                                        Err(e) => {
                                            warn!("âš ï¸  Failed to parse collected data for page {}: {}", page_number, e);
                                            warn!("âš ï¸  Raw collected data: {}", collected_data_json);
                                        }
                                    }
                                } else {
                                    warn!("âš ï¸  Page {} succeeded but no collected data available", page_number);
                                }
                            } else {
                                warn!("âš ï¸  Page {} failed in ListPageCrawling stage, skipping URL extraction", page_number);
                            }
                        } else {
                            warn!("âš ï¸  No stage result found for page {} (item index {})", page_number, item_index);
                        }
                    }
                }
                
                info!("âœ… Transformed {} Page items to {} ProductUrls items ({} total URLs)", 
                      input_items.len(), transformed_items.len(), total_urls_collected);
                
                if transformed_items.is_empty() {
                    warn!("âš ï¸  No ProductURLs were extracted - all pages may have failed or returned no data");
                }
                
                Ok(transformed_items)
            }
            StageType::ProductDetailCrawling => {
                // ProductDetailCrawling â†’ DataSaving: ProductUrls ì•„ì´í…œ ê·¸ëŒ€ë¡œ ì „ë‹¬
                // (ì‹¤ì œë¡œëŠ” ProductDetail ë°ì´í„°ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•˜ì§€ë§Œ, í˜„ì¬ëŠ” ê°„ì†Œí™”)
                let item_count = input_items.len();
                info!("ğŸ”„ ProductDetailCrawling â†’ DataSaving: passing {} ProductUrls items", item_count);
                Ok(input_items)
            }
            StageType::DataSaving => {
                // DataSavingì€ ë§ˆì§€ë§‰ ë‹¨ê³„ì´ë¯€ë¡œ ë³€í™˜ ë¶ˆí•„ìš”
                info!("ğŸ”„ DataSaving completed - pipeline finished");
                Ok(input_items)
            }
            _ => Ok(input_items)
        }
    }
}
