//! BatchActor: ë°°ì¹˜ ë‹¨ìœ„ í¬ë¡¤ë§ ì²˜ë¦¬ Actor
//!
//! Phase 3: Actor êµ¬í˜„ - ë°°ì¹˜ ë ˆë²¨ ì‘ì—… ê´€ë¦¬ ë° ì‹¤í–‰
//! Modern Rust 2024 ì¤€ìˆ˜: í•¨ìˆ˜í˜• ì›ì¹™, ëª…ì‹œì  ì˜ì¡´ì„±, ìƒíƒœ ìµœì†Œí™”

#![warn(clippy::all, clippy::pedantic, clippy::nursery)]
#![deny(clippy::unwrap_used, clippy::expect_used, clippy::panic)]

use chrono::Utc;
use std::collections::{HashSet, VecDeque};
use std::sync::Arc;
use std::sync::Mutex;
use std::time::Instant;
use tokio::sync::{Semaphore, mpsc};
use tracing::{debug, error, info, warn};

use super::traits::{Actor, ActorHealth, ActorStatus, ActorType};
use super::types::{ActorCommand, ActorError, BatchConfig, StageResult, StageType};
use crate::new_architecture::actors::StageActor;
use crate::new_architecture::actors::types::AppEvent;
use crate::new_architecture::channels::types::{ProductUrls, StageItem};
use crate::new_architecture::context::AppContext;

// ì‹¤ì œ ì„œë¹„ìŠ¤ imports ì¶”ê°€
use crate::domain::services::SiteStatus;
use crate::infrastructure::config::AppConfig;
use crate::infrastructure::{HttpClient, IntegratedProductRepository, MatterDataExtractor};

/// BatchActor: ë°°ì¹˜ ë‹¨ìœ„ì˜ í¬ë¡¤ë§ ì‘ì—… ê´€ë¦¬
///
/// ì±…ì„:
/// - ë°°ì¹˜ ë‚´ í˜ì´ì§€ë“¤ì˜ ë³‘ë ¬ ì²˜ë¦¬ ê´€ë¦¬
/// - StageActorë“¤ì˜ ì¡°ì • ë° ìŠ¤ì¼€ì¤„ë§
/// - ë°°ì¹˜ ë ˆë²¨ ì´ë²¤íŠ¸ ë°œí–‰
/// - ë™ì‹œì„± ì œì–´ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
pub struct BatchActor {
    /// Actor ê³ ìœ  ì‹ë³„ì
    actor_id: String,
    /// í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜ ID (OneShot í˜¸í™˜ì„±)
    pub batch_id: Option<String>,
    /// ë°°ì¹˜ ìƒíƒœ
    state: BatchState,
    /// ë°°ì¹˜ ì‹œì‘ ì‹œê°„
    start_time: Option<Instant>,
    /// ì´ í˜ì´ì§€ ìˆ˜
    total_pages: u32,
    /// ì²˜ë¦¬ ì™„ë£Œëœ í˜ì´ì§€ ìˆ˜
    completed_pages: u32,
    /// ì„±ê³µí•œ ì•„ì´í…œ ìˆ˜
    success_count: u32,
    /// ì‹¤íŒ¨í•œ ì•„ì´í…œ ìˆ˜
    failure_count: u32,
    /// ë™ì‹œì„± ì œì–´ìš© ì„¸ë§ˆí¬ì–´
    concurrency_limiter: Option<Arc<Semaphore>>,
    /// ì„¤ì • (OneShot í˜¸í™˜ì„±)
    pub config: Option<Arc<crate::new_architecture::config::SystemConfig>>,

    // ğŸ”¥ Phase 1: ì‹¤ì œ ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì¶”ê°€
    /// HTTP í´ë¼ì´ì–¸íŠ¸
    http_client: Option<Arc<HttpClient>>,
    /// ë°ì´í„° ì¶”ì¶œê¸°
    data_extractor: Option<Arc<MatterDataExtractor>>,
    /// ì œí’ˆ ë ˆí¬ì§€í† ë¦¬
    product_repo: Option<Arc<IntegratedProductRepository>>,
    /// ì•± ì„¤ì •
    app_config: Option<AppConfig>,

    /// Stage 2(ListPageCrawling)ì—ì„œ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨í•œ í˜ì´ì§€ ë²ˆí˜¸ ëª©ë¡
    failed_list_pages: Vec<u32>,
    // ìµœê·¼ ì²˜ë¦¬í•œ Product URL LRU ìºì‹œ (ê²½ëŸ‰ dedupe 1ë‹¨ê³„)
    recent_product_urls: VecDeque<String>,
    recent_product_set: HashSet<String>,
    recent_capacity: usize,
    /// URL ì¤‘ë³µ ì œê±° ì‚¬ìš© ì—¬ë¶€ (ExecutionPlanì—ì„œ ì „ë‹¬)
    skip_duplicate_urls: bool,
    /// ëˆ„ì  ì¤‘ë³µ ìŠ¤í‚µ ìˆ˜ (ë°°ì¹˜ ë‹¨ìœ„)
    duplicates_skipped: u32,
    products_inserted: u32,
    products_updated: u32,
    /// ì™¸ë¶€ì—ì„œ ì½ì„ ìˆ˜ ìˆëŠ” ë©”íŠ¸ë¦­ ê³µìœ  ìƒíƒœ (ì˜µì…˜)
    pub shared_metrics: Option<Arc<Mutex<(u32, u32)>>>, // (inserted, updated)
    // Unified detail crawling accumulation
    collected_product_urls: Vec<crate::domain::product_url::ProductUrl>,
    defer_detail_crawling: bool,
}

// Debug ìˆ˜ë™ êµ¬í˜„ (ì˜ì¡´ì„±ë“¤ì´ Debugë¥¼ êµ¬í˜„í•˜ì§€ ì•Šì•„ì„œ)
impl std::fmt::Debug for BatchActor {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("BatchActor")
            .field("actor_id", &self.actor_id)
            .field("batch_id", &self.batch_id)
            .field("state", &self.state)
            .field("start_time", &self.start_time)
            .field("total_pages", &self.total_pages)
            .field("completed_pages", &self.completed_pages)
            .field("success_count", &self.success_count)
            .field("failure_count", &self.failure_count)
            .field("has_http_client", &self.http_client.is_some())
            .field("has_data_extractor", &self.data_extractor.is_some())
            .field("has_product_repo", &self.product_repo.is_some())
            .field("has_app_config", &self.app_config.is_some())
            .field("failed_list_pages", &self.failed_list_pages)
            .finish()
    }
}

/// ë°°ì¹˜ ìƒíƒœ ì—´ê±°í˜•
#[derive(Debug, Clone, PartialEq)]
pub enum BatchState {
    Idle,
    Starting,
    Processing,
    Paused,
    Completing,
    Completed,
    Failed { error: String },
}

/// ë°°ì¹˜ ê´€ë ¨ ì—ëŸ¬ íƒ€ì…
#[derive(Debug, thiserror::Error)]
pub enum BatchError {
    #[error("Batch initialization failed: {0}")]
    InitializationFailed(String),

    #[error("Batch already processing: {0}")]
    AlreadyProcessing(String),

    #[error("Batch not found: {0}")]
    BatchNotFound(String),

    #[error("Invalid batch configuration: {0}")]
    InvalidConfiguration(String),

    #[error("Concurrency limit exceeded: requested {requested}, max {max}")]
    ConcurrencyLimitExceeded { requested: u32, max: u32 },

    #[error("Context communication error: {0}")]
    ContextError(String),

    #[error("Stage processing error: {0}")]
    StageError(String),

    #[error("Stage processing failed: {stage} - {error}")]
    StageProcessingFailed { stage: String, error: String },

    #[error("Stage execution failed: {0}")]
    StageExecutionFailed(String),

    #[error("Service not available: {0}")]
    ServiceNotAvailable(String),
}

impl BatchActor {
    /// ìƒˆë¡œìš´ BatchActor ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ê¸°ë³¸)
    ///
    /// # Arguments
    /// * `actor_id` - Actor ê³ ìœ  ì‹ë³„ì
    ///
    /// # Returns
    /// * `Self` - ìƒˆë¡œìš´ BatchActor ì¸ìŠ¤í„´ìŠ¤
    pub fn new(actor_id: String) -> Self {
        Self {
            actor_id,
            batch_id: None,
            state: BatchState::Idle,
            start_time: None,
            total_pages: 0,
            completed_pages: 0,
            success_count: 0,
            failure_count: 0,
            concurrency_limiter: None,
            config: None,
            // ìƒˆë¡œ ì¶”ê°€ëœ í•„ë“œë“¤ ì´ˆê¸°í™”
            http_client: None,
            data_extractor: None,
            product_repo: None,
            app_config: None,
            failed_list_pages: Vec::new(),
            recent_product_urls: VecDeque::new(),
            recent_product_set: HashSet::new(),
            recent_capacity: 2000,
            skip_duplicate_urls: true,
            duplicates_skipped: 0,
            products_inserted: 0,
            products_updated: 0,
            shared_metrics: None,
            collected_product_urls: Vec::new(),
            defer_detail_crawling: std::env::var("MC_UNIFIED_DETAIL")
                .map(|v| {
                    let t = v.trim();
                    !(t.eq("0") || t.eq_ignore_ascii_case("false"))
                })
                .unwrap_or(false),
        }
    }

    /// ğŸ”¥ Phase 1: ì‹¤ì œ ì„œë¹„ìŠ¤ë“¤ê³¼ í•¨ê»˜ BatchActor ìƒì„±
    ///
    /// # Arguments
    /// * `actor_id` - Actor ê³ ìœ  ì‹ë³„ì
    /// * `batch_id` - ë°°ì¹˜ ID
    /// * `http_client` - HTTP í´ë¼ì´ì–¸íŠ¸
    /// * `data_extractor` - ë°ì´í„° ì¶”ì¶œê¸°
    /// * `product_repo` - ì œí’ˆ ë ˆí¬ì§€í† ë¦¬
    /// * `app_config` - ì•± ì„¤ì •
    ///
    /// # Returns
    /// * `Self` - ì„œë¹„ìŠ¤ê°€ ì£¼ì…ëœ BatchActor ì¸ìŠ¤í„´ìŠ¤
    pub fn new_with_services(
        actor_id: String,
        batch_id: String,
        http_client: Arc<HttpClient>,
        data_extractor: Arc<MatterDataExtractor>,
        product_repo: Arc<IntegratedProductRepository>,
        app_config: AppConfig,
    ) -> Self {
        Self {
            actor_id,
            batch_id: Some(batch_id),
            state: BatchState::Idle,
            start_time: None,
            total_pages: 0,
            completed_pages: 0,
            success_count: 0,
            failure_count: 0,
            concurrency_limiter: None,
            config: None,
            // ì‹¤ì œ ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì£¼ì…
            http_client: Some(http_client),
            data_extractor: Some(data_extractor),
            product_repo: Some(product_repo),
            app_config: Some(app_config),
            failed_list_pages: Vec::new(),
            recent_product_urls: VecDeque::new(),
            recent_product_set: HashSet::new(),
            recent_capacity: 2000,
            skip_duplicate_urls: true,
            duplicates_skipped: 0,
            products_inserted: 0,
            products_updated: 0,
            shared_metrics: None,
            collected_product_urls: Vec::new(),
            defer_detail_crawling: std::env::var("MC_UNIFIED_DETAIL")
                .map(|v| {
                    let t = v.trim();
                    !(t.eq("0") || t.eq_ignore_ascii_case("false"))
                })
                .unwrap_or(false),
        }
    }

    /// ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘
    ///
    /// # Arguments
    /// * `batch_id` - ë°°ì¹˜ ID
    /// * `pages` - ì²˜ë¦¬í•  í˜ì´ì§€ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
    /// * `config` - ë°°ì¹˜ ì„¤ì •
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    async fn process_list_page_batch(
        &mut self,
        batch_id: String,
        _stage_type: StageType,
        pages: Vec<u32>,
        config: BatchConfig,
        _batch_size: u32,
        concurrency_limit: u32,
        _total_pages: u32,
        _products_on_last_page: u32,
        context: &AppContext,
    ) -> Result<(), BatchError> {
        // ìƒíƒœ ê²€ì¦
        if !matches!(self.state, BatchState::Idle) {
            return Err(BatchError::AlreadyProcessing(batch_id));
        }

        // ì„¤ì • ê²€ì¦
        self.validate_batch_config(&config, concurrency_limit)?;

        info!(
            "ğŸ”„ [Batch START] actor={}, batch_id={}, pages={}, range={:?}",
            self.actor_id,
            batch_id,
            pages.len(),
            if pages.is_empty() {
                None
            } else {
                Some((pages.first().copied(), pages.last().copied()))
            }
        );

        // ê³„íš ëŒ€ë¹„ ì ìš© ê°’ ê²€ì¦ ë¡œê·¸ (plan vs applied)
        let planned_range = (config.start_page, config.end_page);
        let applied_range = if pages.is_empty() {
            None
        } else {
            Some((pages.first().copied(), pages.last().copied()))
        };
        info!(
            "ğŸ§­ [Batch PLAN/APPLIED] planned={:?} applied={:?} count={}",
            planned_range,
            applied_range,
            pages.len()
        );

        // ìƒíƒœ ì´ˆê¸°í™”
        self.batch_id = Some(batch_id.clone());
        self.state = BatchState::Starting;
        self.start_time = Some(Instant::now());
        self.total_pages = pages.len() as u32;
        self.completed_pages = 0;
        self.success_count = 0;
        self.failure_count = 0;
        // ìƒˆ ë°°ì¹˜ë§ˆë‹¤ ì¤‘ë³µ ë°©ì§€ ìºì‹œ ì´ˆê¸°í™” (ì„¸ì…˜ ì „ì²´ ìœ ì§€ê°€ ì•„ë‹ˆë¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê²©ë¦¬)
        self.recent_product_urls.clear();
        self.recent_product_set.clear();
        debug!("â™»ï¸ Cleared recent product URL dedupe caches for new batch");

        // ë™ì‹œì„± ì œì–´ ì„¤ì •
        self.concurrency_limiter = Some(Arc::new(Semaphore::new(concurrency_limit as usize)));

        // ë°°ì¹˜ ì‹œì‘ ì´ë²¤íŠ¸ ë°œí–‰
        let start_event = AppEvent::BatchStarted {
            batch_id: batch_id.clone(),
            session_id: context.session_id.clone(),
            pages_count: pages.len() as u32,
            timestamp: Utc::now(),
        };

        context
            .emit_event(start_event)
            .map_err(|e| BatchError::ContextError(e.to_string()))?;

        // KPI: ë°°ì¹˜ ì‹œì‘ (êµ¬ì¡°í™” ë¡œê·¸)
        info!(target: "kpi.batch",
            "{{\"event\":\"batch_started\",\"session_id\":\"{}\",\"batch_id\":\"{}\",\"pages_count\":{},\"ts\":\"{}\"}}",
            context.session_id,
            batch_id,
            pages.len(),
            chrono::Utc::now()
        );

        // ìƒíƒœë¥¼ Processingìœ¼ë¡œ ì „í™˜
        self.state = BatchState::Processing;

        // ì‹¤ì œ StageActor ê¸°ë°˜ ì²˜ë¦¬ êµ¬í˜„
        info!(
            "ğŸ­ Using real StageActor-based processing for batch {}",
            batch_id
        );

        // ì´ˆê¸° Stage Items ìƒì„± - í˜ì´ì§€ ê¸°ë°˜ ì•„ì´í…œë“¤
        let initial_items: Vec<StageItem> = pages
            .iter()
            .map(|&page_number| StageItem::Page(page_number))
            .collect();

        // Stage 1: StatusCheck - ì‚¬ì´íŠ¸ ìƒíƒœ í™•ì¸ (ì„¸ì…˜ íŒíŠ¸ê°€ ì—†ì„ ë•Œë§Œ ì‹¤í–‰)
        let mut total_pages_hint: Option<u32> = None;
        let mut last_page_products_hint: Option<u32> = None;
        if _total_pages > 0 && _products_on_last_page > 0 {
            info!(
                "ğŸ§  Using provided SiteStatus hints from Session: total_pages={}, products_on_last_page={}",
                _total_pages, _products_on_last_page
            );
            total_pages_hint = Some(_total_pages);
            last_page_products_hint = Some(_products_on_last_page);
        } else {
            info!("ğŸ” Starting Stage 1: StatusCheck (no valid session hints)");
            // StatusCheckëŠ” ì‚¬ì´íŠ¸ ì „ì²´ ìƒíƒœë¥¼ í™•ì¸í•˜ë¯€ë¡œ íŠ¹ë³„í•œ URL ì•„ì´í…œìœ¼ë¡œ ì²˜ë¦¬
            let status_check_items = vec![StageItem::Url(
                "https://csa-iot.org/csa-iot_products/".to_string(),
            )];
            let status_check_result = self
                .execute_stage_with_actor(
                    StageType::StatusCheck,
                    status_check_items,
                    concurrency_limit,
                    context,
                )
                .await?;
            info!(
                "âœ… Stage 1 (StatusCheck) completed: {} success, {} failed",
                status_check_result.successful_items, status_check_result.failed_items
            );

            // ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆë‹¤ë©´ (ì²˜ë¦¬ëœ ì•„ì´í…œì´ ìˆë‹¤ë©´) ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
            if status_check_result.processed_items == 0 {
                error!("âŒ Stage 1 (StatusCheck) failed completely - no status check performed");
                self.state = BatchState::Failed {
                    error: "StatusCheck stage failed - no status check performed".to_string(),
                };
                // ë°°ì¹˜ ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë°œí–‰
                let fail_event = AppEvent::BatchFailed {
                    batch_id: batch_id.clone(),
                    session_id: context.session_id.clone(),
                    error: "StatusCheck stage failed - no status check performed".to_string(),
                    final_failure: true,
                    timestamp: Utc::now(),
                };
                context
                    .emit_event(fail_event)
                    .map_err(|e| BatchError::ContextError(e.to_string()))?;
                return Err(BatchError::StageExecutionFailed(
                    "StatusCheck stage failed - no status check performed".to_string(),
                ));
            }
            // StatusCheckì—ì„œ ì‚¬ì´íŠ¸ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ ì¤‘ë‹¨
            if status_check_result.failed_items > 0 && status_check_result.successful_items == 0 {
                error!("âŒ Stage 1 (StatusCheck) failed completely - site is not accessible");
                self.state = BatchState::Failed {
                    error: "StatusCheck stage failed - site is not accessible".to_string(),
                };
                // ë°°ì¹˜ ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë°œí–‰
                let fail_event = AppEvent::BatchFailed {
                    batch_id: batch_id.clone(),
                    session_id: context.session_id.clone(),
                    error: "StatusCheck stage failed - site is not accessible".to_string(),
                    final_failure: true,
                    timestamp: Utc::now(),
                };
                context
                    .emit_event(fail_event)
                    .map_err(|e| BatchError::ContextError(e.to_string()))?;
                return Err(BatchError::StageExecutionFailed(
                    "StatusCheck stage failed - site is not accessible".to_string(),
                ));
            }

            // StatusCheckì—ì„œ ìˆ˜ì§‘ëœ SiteStatus JSONì„ íŒŒì‹±í•˜ì—¬ í˜ì´ì§€ë„¤ì´ì…˜ íŒíŠ¸ë¡œ ì‚¬ìš©
            if let Some(first) = status_check_result.details.first() {
                if let Some(json) = &first.collected_data {
                    match serde_json::from_str::<SiteStatus>(json) {
                        Ok(site_status) => {
                            total_pages_hint = Some(site_status.total_pages);
                            last_page_products_hint = Some(site_status.products_on_last_page);
                            info!(
                                "ğŸ“Š SiteStatus hints from Stage 1: total_pages={}, products_on_last_page={}",
                                site_status.total_pages, site_status.products_on_last_page
                            );
                        }
                        Err(e) => {
                            warn!(
                                "âš ï¸ Failed to parse SiteStatus from Stage 1 collected_data: {}",
                                e
                            );
                        }
                    }
                }
            }
        }

        // Stage 2: ListPageCrawling - ProductURL ìˆ˜ì§‘
        info!("ğŸ” Starting Stage 2: ListPageCrawling");

        // Stage 2ëŠ” í˜ì´ì§€ë„¤ì´ì…˜ íŒíŠ¸ë¥¼ StageActorì— ì£¼ì…í•´ì•¼ í•¨ â†’ ì „ìš© ì‹¤í–‰ ê²½ë¡œ ì‚¬ìš©
        let list_page_result = self
            .execute_stage_with_actor_with_hints(
                StageType::ListPageCrawling,
                initial_items.clone(),
                concurrency_limit,
                context,
                total_pages_hint,
                last_page_products_hint,
            )
            .await?;

        info!(
            "âœ… Stage 2 (ListPageCrawling) completed: {} success, {} failed",
            list_page_result.successful_items, list_page_result.failed_items
        );

        // Stage 2ì—ì„œ ìµœì¢… ì‹¤íŒ¨í•œ í˜ì´ì§€ ìˆ˜ì§‘
        self.failed_list_pages.clear();
        for (idx, item) in initial_items.iter().enumerate() {
            if let StageItem::Page(page_no) = item {
                if let Some(detail) = list_page_result.details.get(idx) {
                    if !detail.success {
                        self.failed_list_pages.push(*page_no);
                    }
                }
            }
        }
        if !self.failed_list_pages.is_empty() {
            warn!(
                "âš ï¸ Stage 2 ended with {} failed pages after retries: {:?}",
                self.failed_list_pages.len(),
                self.failed_list_pages
            );
            // ì§„í–‰ ìƒí™© ì´ë²¤íŠ¸ë¡œ ì‹¤íŒ¨ í˜ì´ì§€ ì •ë³´ ìš”ì•½ ë°œí–‰ (ìƒ˜í”Œ ìµœëŒ€ 10)
            let sample_len = self.failed_list_pages.len().min(10);
            let sample: Vec<u32> = self
                .failed_list_pages
                .iter()
                .copied()
                .take(sample_len)
                .collect();
            let progress_event = AppEvent::Progress {
                session_id: context.session_id.clone(),
                current_step: 2,
                total_steps: 5,
                message: format!(
                    "Stage 2 retries exhausted for {} pages (sample: {:?})",
                    self.failed_list_pages.len(),
                    sample
                ),
                percentage: 40.0,
                timestamp: Utc::now(),
            };
            context
                .emit_event(progress_event)
                .map_err(|e| BatchError::ContextError(e.to_string()))?;
        }

        // Stage ì‹¤íŒ¨ ì‹œ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨ ê²€ì¦
        if list_page_result.successful_items == 0 {
            error!("âŒ Stage 2 (ListPageCrawling) failed completely - aborting pipeline");
            self.state = BatchState::Failed {
                error: "ListPageCrawling stage failed completely".to_string(),
            };
            // ë°°ì¹˜ ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë°œí–‰
            let fail_event = AppEvent::BatchFailed {
                batch_id: batch_id.clone(),
                session_id: context.session_id.clone(),
                error: "ListPageCrawling stage failed completely".to_string(),
                final_failure: true,
                timestamp: Utc::now(),
            };
            context
                .emit_event(fail_event)
                .map_err(|e| BatchError::ContextError(e.to_string()))?;
            return Err(BatchError::StageExecutionFailed(
                "ListPageCrawling stage failed completely".to_string(),
            ));
        }

        // Stage 2 ê²°ê³¼ë¥¼ Stage 3 ì…ë ¥ìœ¼ë¡œ ë³€í™˜ ë˜ëŠ” ëˆ„ì 
        let product_detail_items = self.transform_stage_output(
            StageType::ListPageCrawling,
            initial_items.clone(),
            &list_page_result,
        )?;

        let mut detail_result_opt: Option<StageResult> = None;
        if self.defer_detail_crawling {
            for item in &product_detail_items {
                if let StageItem::ProductUrls(wrapper) = item {
                    self.collected_product_urls.extend(wrapper.urls.clone());
                }
            }
            info!(
                "ğŸ§º Deferred product detail crawling: accumulated_urls={} (batch pages={})",
                self.collected_product_urls.len(),
                pages.len()
            );
        } else {
            // ì¦‰ì‹œ ìƒì„¸ ìˆ˜ì§‘
            info!("ğŸ” Starting Stage 3: ProductDetailCrawling");
            let detail_result = match self
                .execute_stage_with_actor(
                    StageType::ProductDetailCrawling,
                    product_detail_items.clone(),
                    concurrency_limit,
                    context,
                )
                .await
            {
                Ok(r) => r,
                Err(e) => {
                    let fail_event = AppEvent::BatchFailed {
                        batch_id: batch_id.clone(),
                        session_id: context.session_id.clone(),
                        error: format!("Stage 3 failed: {}", e),
                        final_failure: true,
                        timestamp: Utc::now(),
                    };
                    context
                        .emit_event(fail_event)
                        .map_err(|er| BatchError::ContextError(er.to_string()))?;
                    self.state = BatchState::Failed {
                        error: format!("Stage 3 failed: {}", e),
                    };
                    return Err(e);
                }
            };
            info!(
                "âœ… Stage 3 (ProductDetailCrawling) completed: {} success, {} failed",
                detail_result.successful_items, detail_result.failed_items
            );
            info!(target: "kpi.batch", "{{\"event\":\"batch_stage_summary\",\"batch_id\":\"{}\",\"stage\":\"product_detail\",\"success\":{},\"failed\":{},\"pages\":{},\"ts\":\"{}\"}}",
                batch_id, detail_result.successful_items, detail_result.failed_items, pages.len(), chrono::Utc::now());
            detail_result_opt = Some(detail_result);
        }

        // Summarize failed product detail URLs by correlating input items with Stage 3 results
        if !self.defer_detail_crawling {
            // detail_result only exists in non-deferred path; re-execute minimal failure inspection via executing stage again not desired.
            // TODO: Refactor to hold detail_result outside branch if failure summary needed.
            // Skipping failure summary in deferred mode.
            /*
                if detail_result.failed_items > 0 {
                    let mut failed_detail_urls: Vec<String> = Vec::new();
                    for (idx, item) in product_detail_items.iter().enumerate() {
                        if let Some(item_result) = detail_result.details.get(idx) {
                            if !item_result.success {
                                match item {
                                    StageItem::ProductUrls(urls_wrapper) => {
                                        // If this item was a batch of URLs, log the count rather than each URL
                                        warn!("âš ï¸ ProductDetailCrawling subtask failed for a batch of {} urls (index={})", urls_wrapper.urls.len(), idx);
                                    }
                                    StageItem::Url(_url_str) => {
                                        // No direct URL payload here
                                    }
                                    StageItem::Product(product) => {
                                        failed_detail_urls.push(product.url.clone());
                                    }
                                    _ => {}
                                }
                            }
                        }
                    }
                    if !failed_detail_urls.is_empty() {
                        let sample_len = failed_detail_urls.len().min(10);
                        let sample = &failed_detail_urls[..sample_len];
                        warn!("âš ï¸ Stage 3 ended with {} failed detail URLs (sample up to 10): {:?}",
                            failed_detail_urls.len(), sample);
                        // ì§„í–‰ ìƒí™© ì´ë²¤íŠ¸ë¡œ ì‹¤íŒ¨ URL ìš”ì•½ ë°œí–‰
                        let progress_event = AppEvent::Progress {
                            session_id: context.session_id.clone(),
                            current_step: 3,
                            total_steps: 5,
                            message: format!(
                                "Stage 3 retries exhausted for {} product details (sample: {:?})",
                                failed_detail_urls.len(), sample
                            ),
                            percentage: 60.0,
                            timestamp: Utc::now(),
                        };
                        context.emit_event(progress_event)
                            .map_err(|e| BatchError::ContextError(e.to_string()))?;
                    }
            }
            */
        }

        // Stage 3 ê²°ê³¼ë¥¼ Stage 4 ì…ë ¥ìœ¼ë¡œ ë³€í™˜
        let data_validation_items = if self.defer_detail_crawling {
            // Deferred mode: skip (no items)
            Vec::new()
        } else {
            // ê¸°ì¡´ ë³€í™˜ ê²°ê³¼ (ê° ProductDetail ë‹¨ìœ„) â†’ í•˜ë‚˜ì˜ ProductDetails StageItem ìœ¼ë¡œ í•©ì³ 1íšŒ ì‹¤í–‰
            let per_item = self.transform_stage_output(
                StageType::ProductDetailCrawling,
                product_detail_items,
                detail_result_opt
                    .as_ref()
                    .expect("detail_result present when not deferred"),
            )?;
            if per_item.is_empty() {
                Vec::new()
            } else {
                // ëª¨ë“  Product ë˜ëŠ” ProductDetails ì•„ì´í…œì—ì„œ ìƒì„¸ ì œí’ˆë“¤ì„ ì¶”ì¶œí•´ í•˜ë‚˜ë¡œ ë³‘í•©
                use crate::new_architecture::channels::types::{
                    ProductDetails, StageItem as SItem,
                };
                let mut all_products: Vec<crate::domain::product::ProductDetail> = Vec::new();
                let mut all_source_urls: Vec<crate::domain::product_url::ProductUrl> = Vec::new();
                for it in per_item.into_iter() {
                    match it {
                        SItem::ProductDetails(pd) => {
                            all_source_urls.extend(pd.source_urls.into_iter());
                            all_products.extend(pd.products.into_iter());
                        }
                        SItem::Product(_p) => {
                            // ë‹¨ì¼ ProductInfo ë¡œ í‘œí˜„ëœ ê²½ìš° ProductDetail ë³€í™˜ ë¶ˆê°€ â†’ ë¬´ì‹œ ë˜ëŠ” í–¥í›„ ë³€í™˜ ë¡œì§ ì¶”ê°€
                            debug!("Skipping non-detailed product item in aggregation");
                        }
                        _ => {}
                    }
                }
                if all_products.is_empty() {
                    Vec::new()
                } else {
                    let stats = crate::new_architecture::channels::types::ExtractionStats {
                        attempted: all_products.len() as u32,
                        successful: all_products.len() as u32,
                        failed: 0,
                        empty_responses: 0,
                    };
                    let merged = ProductDetails {
                        products: all_products,
                        source_urls: all_source_urls,
                        extraction_stats: stats,
                    };
                    vec![SItem::ProductDetails(merged)]
                }
            }
        };

        // Stage 4: DataValidation - ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        info!("ğŸ” Starting Stage 4: DataValidation");
        let validation_result = match self
            .execute_stage_with_actor(
                StageType::DataValidation,
                data_validation_items.clone(),
                concurrency_limit,
                context,
            )
            .await
        {
            Ok(r) => r,
            Err(e) => {
                let fail_event = AppEvent::BatchFailed {
                    batch_id: batch_id.clone(),
                    session_id: context.session_id.clone(),
                    error: format!("Stage 4 failed: {}", e),
                    final_failure: true,
                    timestamp: Utc::now(),
                };
                context
                    .emit_event(fail_event)
                    .map_err(|er| BatchError::ContextError(er.to_string()))?;
                self.state = BatchState::Failed {
                    error: format!("Stage 4 failed: {}", e),
                };
                return Err(e);
            }
        };

        info!(
            "âœ… Stage 4 (DataValidation) completed: {} success, {} failed",
            validation_result.successful_items, validation_result.failed_items
        );
        info!(target: "kpi.batch", "{{\"event\":\"batch_stage_summary\",\"batch_id\":\"{}\",\"stage\":\"data_validation\",\"success\":{},\"failed\":{},\"pages\":{},\"ts\":\"{}\"}}",
          batch_id, validation_result.successful_items, validation_result.failed_items, pages.len(), chrono::Utc::now());

        // Stage 4 ê²°ê³¼ë¥¼ Stage 5 ì…ë ¥ìœ¼ë¡œ ë³€í™˜
        let data_saving_items = if self.defer_detail_crawling {
            Vec::new()
        } else {
            self.transform_stage_output(
                StageType::DataValidation,
                data_validation_items,
                &validation_result,
            )?
        };

        // Stage 5: DataSaving - ë°ì´í„° ì €ì¥
        info!("ğŸ” Starting Stage 5: DataSaving");
        let saving_result = match self
            .execute_stage_with_actor(
                StageType::DataSaving,
                data_saving_items,
                concurrency_limit,
                context,
            )
            .await
        {
            Ok(r) => r,
            Err(e) => {
                let fail_event = AppEvent::BatchFailed {
                    batch_id: batch_id.clone(),
                    session_id: context.session_id.clone(),
                    error: format!("Stage 5 failed: {}", e),
                    final_failure: true,
                    timestamp: Utc::now(),
                };
                context
                    .emit_event(fail_event)
                    .map_err(|er| BatchError::ContextError(er.to_string()))?;
                self.state = BatchState::Failed {
                    error: format!("Stage 5 failed: {}", e),
                };
                return Err(e);
            }
        };

        info!(
            "âœ… Stage 5 (DataSaving) completed: {} success, {} failed",
            saving_result.successful_items, saving_result.failed_items
        );
        info!(target: "kpi.batch", "{{\"event\":\"batch_stage_summary\",\"batch_id\":\"{}\",\"stage\":\"data_saving\",\"success\":{},\"failed\":{},\"pages\":{},\"ts\":\"{}\"}}",
          batch_id, saving_result.successful_items, saving_result.failed_items, pages.len(), chrono::Utc::now());

        // DataSaving ë‹¨ê³„ì—ì„œ product insert/update ë©”íŠ¸ë¦­ ì¶”ì¶œ
        // StageItemResult.collected_data ì— JSON { products_inserted, products_updated, total_affected }
        let mut inserted_sum = 0u32;
        let mut updated_sum = 0u32;
        for item in &saving_result.details {
            if let Some(data) = &item.collected_data {
                if data.starts_with('{') {
                    if let Ok(v) = serde_json::from_str::<serde_json::Value>(data) {
                        if let Some(pi) = v.get("products_inserted").and_then(|x| x.as_u64()) {
                            inserted_sum = inserted_sum.saturating_add(pi as u32);
                        }
                        if let Some(pu) = v.get("products_updated").and_then(|x| x.as_u64()) {
                            updated_sum = updated_sum.saturating_add(pu as u32);
                        }
                    }
                }
            }
        }
        self.products_inserted = inserted_sum;
        self.products_updated = updated_sum;
        if let Some(shared) = &self.shared_metrics {
            if let Ok(mut g) = shared.lock() {
                *g = (self.products_inserted, self.products_updated);
            }
        }

        // ë°°ì¹˜ ê²°ê³¼ ì§‘ê³„ (ì„±ê³µ ì¹´ìš´íŠ¸ëŠ” saving ë‹¨ê³„ ì„±ê³µ ê¸°ì¤€)
        self.success_count = saving_result.successful_items;
        self.completed_pages = pages.len() as u32;
        self.state = BatchState::Completed;
        info!(
            "ğŸ [Batch COMPLETE] actor={}, batch_id={}, pages_processed={}",
            self.actor_id,
            batch_id,
            pages.len()
        );

        // ì¶”ê°€: ë°°ì¹˜ ìš”ì•½ í•œ ì¤„ ë¡œê·¸ë¡œ í•µì‹¬ ì§€í‘œ ì§‘ê³„ ì¶œë ¥
        let duration_ms = self
            .start_time
            .map(|s| s.elapsed().as_millis() as u64)
            .unwrap_or(0);
        info!(
            "ğŸ“¦ [Batch SUMMARY] actor={}, batch_id={}, pages_total={}, success_items={}, failed_items={}, retries_usedâ‰ˆ{}, duration_ms={}, products_inserted={}, products_updated={}, deferred_detail={}",
            self.actor_id,
            batch_id,
            self.total_pages,
            saving_result.successful_items,
            saving_result.failed_items,
            {
                let stage2_retries: u32 =
                    list_page_result.details.iter().map(|d| d.retry_count).sum();
                if self.defer_detail_crawling {
                    stage2_retries
                } else {
                    let stage3_retries: u32 = detail_result_opt
                        .as_ref()
                        .map(|r| r.details.iter().map(|d| d.retry_count).sum())
                        .unwrap_or(0);
                    stage2_retries.saturating_add(stage3_retries)
                }
            },
            duration_ms,
            self.products_inserted,
            self.products_updated,
            self.defer_detail_crawling
        );

        let completion_event = AppEvent::BatchCompleted {
            batch_id: batch_id.clone(),
            session_id: context.session_id.clone(),
            success_count: self.success_count,
            failed_count: saving_result.failed_items,
            duration: self
                .start_time
                .map(|s| s.elapsed().as_millis() as u64)
                .unwrap_or(0),
            timestamp: Utc::now(),
        };

        context
            .emit_event(completion_event)
            .map_err(|e| BatchError::ContextError(e.to_string()))?;

        // KPI: ë°°ì¹˜ ì™„ë£Œ (êµ¬ì¡°í™” ë¡œê·¸)
        info!(target: "kpi.batch",
            "{{\"event\":\"batch_completed\",\"session_id\":\"{}\",\"batch_id\":\"{}\",\"pages_total\":{},\"pages_success\":{},\"pages_failed\":{},\"duration_ms\":{},\"products_inserted\":{},\"products_updated\":{},\"ts\":\"{}\"}}",
            context.session_id,
            batch_id,
            self.total_pages,
            self.success_count.max(list_page_result.successful_items),
            list_page_result.failed_items,
            self.start_time.map(|s| s.elapsed().as_millis() as u64).unwrap_or(0),
            self.products_inserted,
            self.products_updated,
            chrono::Utc::now()
        );

        // TODO: Integrate real DataSaving inserted/updated metrics: requires StageActor -> BatchActor callback.
        // Current workaround: StageActor logs metrics; future enhancement: channel message carrying counts.

        // === ì¶”ê°€: ë°°ì¹˜ ë¦¬í¬íŠ¸ ì´ë²¤íŠ¸ ë°œí–‰ ===
        let duration_ms = self
            .start_time
            .map(|s| s.elapsed().as_millis() as u64)
            .unwrap_or(0);
        // Stage 2/3 ê²°ê³¼ëŠ” ìƒë‹¨ ìŠ¤ì½”í”„ì˜ ë³€ìˆ˜ë“¤ì—ì„œ ê°€ì ¸ì˜´. ì‚¬ìš© ê°€ëŠ¥ ì‹œ ì§‘ê³„, ì—†ìœ¼ë©´ ë³´ìˆ˜ì  ê¸°ë³¸ê°’.
        let pages_total = self.total_pages;
        let pages_success = self.success_count.max(list_page_result.successful_items);
        let pages_failed = list_page_result.failed_items;
        let (details_success, details_failed) = if self.defer_detail_crawling {
            (0, 0)
        } else {
            (
                validation_result.successful_items,
                validation_result.failed_items,
            )
        };
        let stage2_retries: u32 = list_page_result.details.iter().map(|d| d.retry_count).sum();
        let retries_used = if self.defer_detail_crawling {
            stage2_retries
        } else {
            let stage3_retries: u32 = detail_result_opt
                .as_ref()
                .map(|r| r.details.iter().map(|d| d.retry_count).sum())
                .unwrap_or(0);
            stage2_retries.saturating_add(stage3_retries)
        };
        let report_event = AppEvent::BatchReport {
            session_id: context.session_id.clone(),
            batch_id: batch_id.clone(),
            pages_total,
            pages_success,
            pages_failed,
            list_pages_failed: self.failed_list_pages.clone(),
            details_success,
            details_failed,
            retries_used,
            duration_ms,
            duplicates_skipped: self.duplicates_skipped,
            products_inserted: self.products_inserted,
            products_updated: self.products_updated,
            timestamp: Utc::now(),
        };
        context
            .emit_event(report_event)
            .map_err(|e| BatchError::ContextError(e.to_string()))?;

        Ok(())
    }

    /// ë°°ì¹˜ ì„¤ì • ê²€ì¦
    ///
    /// # Arguments
    /// * `config` - ë°°ì¹˜ ì„¤ì •
    /// * `concurrency_limit` - ë™ì‹œì„± ì œí•œ
    fn validate_batch_config(
        &self,
        config: &BatchConfig,
        concurrency_limit: u32,
    ) -> Result<(), BatchError> {
        if config.batch_size == 0 {
            return Err(BatchError::InvalidConfiguration(
                "Batch size cannot be zero".to_string(),
            ));
        }

        if concurrency_limit == 0 {
            return Err(BatchError::InvalidConfiguration(
                "Concurrency limit cannot be zero".to_string(),
            ));
        }

        const MAX_CONCURRENCY: u32 = 100;
        if concurrency_limit > MAX_CONCURRENCY {
            return Err(BatchError::ConcurrencyLimitExceeded {
                requested: concurrency_limit,
                max: MAX_CONCURRENCY,
            });
        }

        Ok(())
    }

    /// ë°°ì¹˜ ID ê²€ì¦
    ///
    /// # Arguments
    /// * `batch_id` - ê²€ì¦í•  ë°°ì¹˜ ID
    #[allow(dead_code)]
    fn validate_batch(&self, batch_id: &str) -> Result<(), BatchError> {
        match &self.batch_id {
            Some(current_id) if current_id == batch_id => Ok(()),
            Some(current_id) => Err(BatchError::BatchNotFound(format!(
                "Expected {}, got {}",
                current_id, batch_id
            ))),
            None => Err(BatchError::BatchNotFound("No active batch".to_string())),
        }
    }

    /// ë°°ì¹˜ ì •ë¦¬
    fn cleanup_batch(&mut self) {
        self.batch_id = None;
        self.state = BatchState::Idle;
        self.start_time = None;
        self.total_pages = 0;
        self.completed_pages = 0;
        self.success_count = 0;
        self.failure_count = 0;
        self.concurrency_limiter = None;
    }

    /// ì§„í–‰ ìƒí™© ê³„ì‚°
    ///
    /// # Returns
    /// * `f64` - ì§„í–‰ë¥  (0.0 ~ 1.0)
    fn calculate_progress(&self) -> f64 {
        if self.total_pages == 0 {
            0.0
        } else {
            f64::from(self.completed_pages) / f64::from(self.total_pages)
        }
    }

    /// ì²˜ë¦¬ ì†ë„ ê³„ì‚° (í˜ì´ì§€/ì´ˆ)
    ///
    /// # Returns
    /// * `f64` - ì²˜ë¦¬ ì†ë„
    fn calculate_processing_rate(&self) -> f64 {
        if let Some(start_time) = self.start_time {
            let elapsed = start_time.elapsed();
            if elapsed.as_secs() > 0 {
                f64::from(self.completed_pages) / elapsed.as_secs_f64()
            } else {
                0.0
            }
        } else {
            0.0
        }
    }
}

#[async_trait::async_trait]
impl Actor for BatchActor {
    type Command = ActorCommand;
    type Error = ActorError;

    fn actor_id(&self) -> &str {
        &self.actor_id
    }

    fn actor_type(&self) -> ActorType {
        ActorType::Batch
    }
    async fn run(
        &mut self,
        mut context: AppContext,
        mut command_rx: mpsc::Receiver<Self::Command>,
    ) -> Result<(), Self::Error> {
        info!("ğŸ”„ BatchActor {} starting execution loop", self.actor_id);

        loop {
            tokio::select! {
                // ëª…ë ¹ ì²˜ë¦¬
                command = command_rx.recv() => {
                    match command {
                        Some(cmd) => {
                            debug!("ğŸ“¨ BatchActor {} received command: {:?}", self.actor_id, cmd);

                            match cmd {
                                ActorCommand::ProcessBatch {
                                    batch_id,
                                    pages,
                                    config,
                                    batch_size,
                                    concurrency_limit,
                                    total_pages,
                                    products_on_last_page
                                } => {
                                    if let Err(e) = self.process_list_page_batch(
                                        batch_id,
                                        StageType::ListPageCrawling, // stage_type ì¶”ê°€
                                        pages,
                                        config,
                                        batch_size,
                                        concurrency_limit,
                                        total_pages,
                                        products_on_last_page,
                                        &context
                                    ).await {
                                        error!("Failed to process batch: {}", e);
                                        info!("[BatchActorRun] exiting early after failed batch");
                                        info!("ğŸ BatchActor {} execution loop ended (failure)", self.actor_id);
                                        return Err(ActorError::CommandProcessingFailed(format!("batch failed: {}", e)));
                                    } else {
                                        // ë‹¨ì¼ ë°°ì¹˜ ëª¨ë“œ: ì¶”ê°€ ëª…ë ¹ì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ì¢…ë£Œí•˜ì—¬ ìƒìœ„ awaitê°€ í’€ë¦¬ë„ë¡ í•œë‹¤.
                                        info!("[BatchActorRun] single batch processed successfully â€” returning to caller");
                                        info!("ğŸ BatchActor {} execution loop ended (single batch success)", self.actor_id);
                                        return Ok(());
                                    }
                                }

                                ActorCommand::Shutdown => {
                                    info!("ğŸ›‘ BatchActor {} received shutdown command", self.actor_id);
                                    break;
                                }

                                _ => {
                                    debug!("BatchActor {} ignoring non-batch command", self.actor_id);
                                }
                            }
                        }
                        None => {
                            warn!("ğŸ“ª BatchActor {} command channel closed", self.actor_id);
                            break;
                        }
                    }
                }

                // ì·¨ì†Œ ì‹ í˜¸ í™•ì¸
                _ = context.cancellation_token.changed() => {
                    // Cancellation ê°ì§€
                    if *context.cancellation_token.borrow() {
                        warn!("ğŸš« BatchActor {} received cancellation signal", self.actor_id);
                        break;
                    }
                }
            }
        }

        info!("ğŸ BatchActor {} execution loop ended", self.actor_id);
        Ok(())
    }

    async fn health_check(&self) -> Result<ActorHealth, Self::Error> {
        let status = match &self.state {
            BatchState::Idle => ActorStatus::Healthy,
            BatchState::Processing => ActorStatus::Healthy,
            BatchState::Completed => ActorStatus::Healthy,
            BatchState::Paused => ActorStatus::Degraded {
                reason: "Batch paused".to_string(),
                since: Utc::now(),
            },
            BatchState::Failed { error } => ActorStatus::Unhealthy {
                error: error.clone(),
                since: Utc::now(),
            },
            _ => ActorStatus::Degraded {
                reason: format!("In transition state: {:?}", self.state),
                since: Utc::now(),
            },
        };

        Ok(ActorHealth {
            actor_id: self.actor_id.clone(),
            actor_type: ActorType::Batch,
            status,
            last_activity: Utc::now(),
            memory_usage_mb: 0, // TODO: ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
            active_tasks: if matches!(self.state, BatchState::Processing) {
                self.total_pages - self.completed_pages
            } else {
                0
            },
            commands_processed: 0, // TODO: ì‹¤ì œ ì²˜ë¦¬ëœ ëª…ë ¹ ìˆ˜ ê³„ì‚°
            errors_count: 0,       // TODO: ì‹¤ì œ ì—ëŸ¬ ìˆ˜ ê³„ì‚°
            avg_command_processing_time_ms: 0.0, // TODO: ì‹¤ì œ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            metadata: serde_json::json!({
                "batch_id": self.batch_id,
                "state": format!("{:?}", self.state),
                "total_pages": self.total_pages,
                "completed_pages": self.completed_pages,
                "success_count": self.success_count,
                "failure_count": self.failure_count,
                "progress": self.calculate_progress(),
                "processing_rate": self.calculate_processing_rate()
            })
            .to_string(),
        })
    }

    async fn shutdown(&mut self) -> Result<(), Self::Error> {
        info!("ğŸ”Œ BatchActor {} shutting down", self.actor_id);

        // í™œì„± ë°°ì¹˜ê°€ ìˆë‹¤ë©´ ì •ë¦¬
        if self.batch_id.is_some() {
            warn!("Cleaning up active batch during shutdown");
            self.cleanup_batch();
        }

        Ok(())
    }
}

impl BatchActor {
    /// ê°œë³„ Stageë¥¼ StageActorë¡œ ì‹¤í–‰
    /// TODO: StageItemCompleted ì´ë²¤íŠ¸ ìˆ˜ì‹  ì±„ë„ ë„ì…í•˜ì—¬ products_inserted/products_updated ì‹¤ì‹œê°„ ë°˜ì˜
    /// # Arguments
    /// * `stage_type` - ì‹¤í–‰í•  ìŠ¤í…Œì´ì§€ íƒ€ì…
    /// * `items` - ì²˜ë¦¬í•  ì•„ì´í…œë“¤
    /// * `concurrency_limit` - ë™ì‹œ ì‹¤í–‰ ì œí•œ
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    async fn execute_stage_with_actor(
        &self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        context: &AppContext,
    ) -> Result<StageResult, BatchError> {
        // ì„œë¹„ìŠ¤ ì˜ì¡´ì„±ì´ ìˆëŠ”ì§€ í™•ì¸
        let http_client = self.http_client.as_ref().ok_or_else(|| {
            BatchError::ServiceNotAvailable("HttpClient not initialized".to_string())
        })?;
        let data_extractor = self.data_extractor.as_ref().ok_or_else(|| {
            BatchError::ServiceNotAvailable("MatterDataExtractor not initialized".to_string())
        })?;
        let product_repo = self.product_repo.as_ref().ok_or_else(|| {
            BatchError::ServiceNotAvailable(
                "IntegratedProductRepository not initialized".to_string(),
            )
        })?;
        let app_config = self.app_config.as_ref().ok_or_else(|| {
            BatchError::ServiceNotAvailable("AppConfig not initialized".to_string())
        })?;

        // StageActor ìƒì„± (ì‹¤ì œ ì„œë¹„ìŠ¤ë“¤ê³¼ í•¨ê»˜)
        let mut stage_actor = StageActor::new_with_services(
            format!("stage_{}_{}", stage_type.as_str(), self.actor_id),
            self.batch_id.clone().unwrap_or_default(),
            Arc::clone(http_client),
            Arc::clone(data_extractor),
            Arc::clone(product_repo),
            app_config.clone(),
        );

        // StageActorë¡œ Stage ì‹¤í–‰ (ì‹¤ì œ items ì „ë‹¬)
        let stage_result = stage_actor
            .execute_stage(
                stage_type,
                items,
                concurrency_limit,
                30, // timeout_secs - 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                context,
            )
            .await
            .map_err(|e| {
                BatchError::StageExecutionFailed(format!("Stage execution failed: {}", e))
            })?;

        Ok(stage_result)
    }

    /// íŒíŠ¸ë¥¼ ì£¼ì…í•  ìˆ˜ ìˆëŠ” Stage ì‹¤í–‰ ë„ìš°ë¯¸ (ListPage ë“±)
    async fn execute_stage_with_actor_with_hints(
        &self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        context: &AppContext,
        total_pages_hint: Option<u32>,
        products_on_last_page_hint: Option<u32>,
    ) -> Result<StageResult, BatchError> {
        // ê¸°ë³¸ ì‹¤í–‰ ì¤€ë¹„ëŠ” ë™ì¼
        let http_client = self.http_client.as_ref().ok_or_else(|| {
            BatchError::ServiceNotAvailable("HttpClient not initialized".to_string())
        })?;
        let data_extractor = self.data_extractor.as_ref().ok_or_else(|| {
            BatchError::ServiceNotAvailable("MatterDataExtractor not initialized".to_string())
        })?;
        let product_repo = self.product_repo.as_ref().ok_or_else(|| {
            BatchError::ServiceNotAvailable(
                "IntegratedProductRepository not initialized".to_string(),
            )
        })?;
        let app_config = self.app_config.as_ref().ok_or_else(|| {
            BatchError::ServiceNotAvailable("AppConfig not initialized".to_string())
        })?;

        let mut stage_actor = StageActor::new_with_services(
            format!("stage_{}_{}", stage_type.as_str(), self.actor_id),
            self.batch_id.clone().unwrap_or_default(),
            Arc::clone(http_client),
            Arc::clone(data_extractor),
            Arc::clone(product_repo),
            app_config.clone(),
        );

        if let (Some(tp), Some(plp)) = (total_pages_hint, products_on_last_page_hint) {
            stage_actor.set_site_pagination_hints(tp, plp);
        }

        let stage_result = stage_actor
            .execute_stage(stage_type, items, concurrency_limit, 30, context)
            .await
            .map_err(|e| {
                BatchError::StageExecutionFailed(format!("Stage execution failed: {}", e))
            })?;

        Ok(stage_result)
    }

    /// Stage íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ - Stage ê°„ ë°ì´í„° ì „ë‹¬ êµ¬í˜„
    ///
    /// # Arguments
    /// * `stage_type` - ì‹¤í–‰í•  ìŠ¤í…Œì´ì§€ íƒ€ì… (í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - ìˆœì°¨ ì‹¤í–‰)
    /// * `pages` - ì²˜ë¦¬í•  í˜ì´ì§€ë“¤
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    #[allow(dead_code)]
    async fn execute_stage(
        &mut self,
        _stage_type: StageType, // íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” ëª¨ë“  Stage ìˆœì°¨ ì‹¤í–‰
        pages: Vec<u32>,
        context: &AppContext,
    ) -> Result<StageResult, BatchError> {
        use crate::new_architecture::actors::StageActor;
        use crate::new_architecture::channels::types::StageItem;

        info!(
            "ï¿½ Starting Stage pipeline processing for {} pages",
            pages.len()
        );

        // Stage ì‹¤í–‰ ìˆœì„œ ì •ì˜
        let stages = [
            StageType::StatusCheck,
            StageType::ListPageCrawling,
            StageType::ProductDetailCrawling,
            StageType::DataSaving,
        ];

        // ì´ˆê¸° ì…ë ¥: í˜ì´ì§€ë“¤ì„ StageItemìœ¼ë¡œ ë³€í™˜
        let mut current_items: Vec<StageItem> = pages
            .into_iter()
            .map(|page| StageItem::Page(page))
            .collect();

        let mut final_result = StageResult {
            processed_items: 0,
            successful_items: 0,
            failed_items: 0,
            duration_ms: 0,
            details: vec![],
        };

        // Stage íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        for (stage_idx, stage_type) in stages.iter().enumerate() {
            info!(
                "ğŸ¯ Executing stage {} for {} items",
                stage_type.as_str(),
                current_items.len()
            );

            // ğŸ”¥ Phase 1: ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ í•¨ê»˜ StageActor ìƒì„±
            let mut stage_actor = if let (
                Some(http_client),
                Some(data_extractor),
                Some(product_repo),
                Some(app_config),
            ) = (
                &self.http_client,
                &self.data_extractor,
                &self.product_repo,
                &self.app_config,
            ) {
                info!("âœ… Creating StageActor with real services");
                StageActor::new_with_services(
                    format!(
                        "stage_{}_{}",
                        stage_type.as_str().to_lowercase(),
                        self.actor_id
                    ),
                    self.batch_id.clone().unwrap_or_default(),
                    Arc::clone(http_client),
                    Arc::clone(data_extractor),
                    Arc::clone(product_repo),
                    app_config.clone(),
                )
            } else {
                warn!(
                    "âš ï¸  Creating StageActor without services - falling back to basic initialization"
                );
                let mut stage_actor = StageActor::new(format!(
                    "stage_{}_{}",
                    stage_type.as_str().to_lowercase(),
                    self.actor_id
                ));

                // ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œë„
                stage_actor
                    .initialize_real_services(context)
                    .await
                    .map_err(|e| BatchError::StageProcessingFailed {
                        stage: stage_type.as_str().to_string(),
                        error: format!("Failed to initialize real services: {}", e),
                    })?;

                stage_actor
            };

            // Stage ì‹¤í–‰ (ì‹¤ì œ current_items ì „ë‹¬)
            // Use config when available, fall back to sensible defaults
            let (concurrency_limit, timeout_secs) = if let Some(app_config) = &self.app_config {
                let stage_concurrency = match stage_type {
                    StageType::ListPageCrawling => {
                        app_config.user.crawling.workers.list_page_max_concurrent as u32
                    }
                    StageType::ProductDetailCrawling => {
                        app_config
                            .user
                            .crawling
                            .workers
                            .product_detail_max_concurrent as u32
                    }
                    _ => app_config.user.max_concurrent_requests,
                };
                (
                    stage_concurrency,
                    app_config.user.crawling.timing.operation_timeout_seconds,
                )
            } else {
                (5, 300)
            };

            let stage_result = stage_actor
                .execute_stage(
                    stage_type.clone(),
                    current_items.clone(),
                    concurrency_limit,
                    timeout_secs,
                    context,
                )
                .await
                .map_err(|e| BatchError::StageProcessingFailed {
                    stage: stage_type.as_str().to_string(),
                    error: format!("Stage execution failed: {:?}", e),
                })?;

            info!(
                "âœ… Stage {} ({}) completed: {} success, {} failed",
                stage_idx + 1,
                stage_type.as_str(),
                stage_result.successful_items,
                stage_result.failed_items
            );

            // ìµœì¢… ê²°ê³¼ ëˆ„ì 
            final_result.processed_items += stage_result.processed_items;
            final_result.successful_items += stage_result.successful_items;
            final_result.failed_items += stage_result.failed_items;
            final_result.duration_ms += stage_result.duration_ms;

            // ë‹¤ìŒ Stageë¥¼ ìœ„í•œ ì…ë ¥ ë°ì´í„° ë³€í™˜
            current_items =
                self.transform_stage_output(stage_type.clone(), current_items, &stage_result)?;
        }

        info!("âœ… All stages completed in pipeline");
        Ok(final_result)
    }

    /// Stage ì¶œë ¥ì„ ë‹¤ìŒ Stage ì…ë ¥ìœ¼ë¡œ ë³€í™˜
    fn transform_stage_output(
        &mut self,
        completed_stage: StageType,
        input_items: Vec<StageItem>,
        stage_result: &StageResult,
    ) -> Result<Vec<StageItem>, BatchError> {
        match completed_stage {
            StageType::StatusCheck => {
                // StatusCheck â†’ ListPageCrawling: Page ì•„ì´í…œ ê·¸ëŒ€ë¡œ ì „ë‹¬
                info!(
                    "ğŸ”„ StatusCheck â†’ ListPageCrawling: passing {} Page items",
                    input_items.len()
                );
                Ok(input_items)
            }
            StageType::ListPageCrawling => {
                // ListPageCrawling â†’ ProductDetailCrawling: ì‹¤ì œ ìˆ˜ì§‘ëœ ProductUrls ì‚¬ìš©
                info!(
                    "ğŸ”„ ListPageCrawling â†’ ProductDetailCrawling: extracting ProductUrls from collected data"
                );

                let mut transformed_items = Vec::new();
                let mut total_urls_collected = 0;
                let mut total_urls_after_dedupe = 0;
                let enable_dedupe = self.skip_duplicate_urls;
                let mut total_duplicates_skipped = 0u32;

                for (item_index, item) in input_items.iter().enumerate() {
                    if let StageItem::Page(page_number) = item {
                        // stage_resultì—ì„œ í•´ë‹¹ í˜ì´ì§€ì˜ ì‹¤í–‰ ê²°ê³¼ í™•ì¸
                        if let Some(stage_item_result) = stage_result.details.get(item_index) {
                            if stage_item_result.success {
                                // ì‹¤ì œ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                                if let Some(collected_data_json) = &stage_item_result.collected_data
                                {
                                    // JSONì—ì„œ ProductURLë“¤ì„ íŒŒì‹±
                                    match serde_json::from_str::<
                                        Vec<crate::domain::product_url::ProductUrl>,
                                    >(collected_data_json)
                                    {
                                        Ok(product_urls_vec) => {
                                            if !product_urls_vec.is_empty() {
                                                let original_count = product_urls_vec.len();
                                                total_urls_collected += original_count;
                                                let filtered_vec = if enable_dedupe {
                                                    let mut filtered =
                                                        Vec::with_capacity(original_count);
                                                    for pu in product_urls_vec.into_iter() {
                                                        let key = pu.url.clone();
                                                        if !self.recent_product_set.contains(&key) {
                                                            // LRU eviction if needed
                                                            if self.recent_product_urls.len()
                                                                >= self.recent_capacity
                                                            {
                                                                if let Some(old) = self
                                                                    .recent_product_urls
                                                                    .pop_front()
                                                                {
                                                                    self.recent_product_set
                                                                        .remove(&old);
                                                                }
                                                            }
                                                            self.recent_product_set
                                                                .insert(key.clone());
                                                            self.recent_product_urls.push_back(key);
                                                            filtered.push(pu);
                                                        } else {
                                                            total_duplicates_skipped += 1;
                                                        }
                                                    }
                                                    filtered
                                                } else {
                                                    product_urls_vec
                                                };

                                                let after_count = filtered_vec.len();
                                                total_urls_after_dedupe += after_count;

                                                if after_count > 0 {
                                                    let product_urls = ProductUrls {
                                                        urls: filtered_vec,
                                                        batch_id: Some(self.actor_id.clone()),
                                                    };
                                                    transformed_items
                                                        .push(StageItem::ProductUrls(product_urls));
                                                }

                                                if enable_dedupe {
                                                    info!(
                                                        "âœ… Extracted page {} URLs: original={} after_dedupe={} skipped={} recent_cache_size={} recent_set_size={}",
                                                        page_number,
                                                        original_count,
                                                        after_count,
                                                        original_count.saturating_sub(after_count),
                                                        self.recent_product_urls.len(),
                                                        self.recent_product_set.len()
                                                    );
                                                } else {
                                                    info!(
                                                        "âœ… Extracted {} ProductURLs from page {} (dedupe disabled)",
                                                        original_count, page_number
                                                    );
                                                }
                                            } else {
                                                warn!(
                                                    "âš ï¸  Page {} crawling succeeded but no ProductURLs were collected",
                                                    page_number
                                                );
                                            }
                                        }
                                        Err(e) => {
                                            warn!(
                                                "âš ï¸  Failed to parse collected data for page {}: {}",
                                                page_number, e
                                            );
                                            warn!(
                                                "âš ï¸  Raw collected data: {}",
                                                collected_data_json
                                            );
                                        }
                                    }
                                } else {
                                    warn!(
                                        "âš ï¸  Page {} succeeded but no collected data available",
                                        page_number
                                    );
                                }
                            } else {
                                warn!(
                                    "âš ï¸  Page {} failed in ListPageCrawling stage, skipping URL extraction",
                                    page_number
                                );
                            }
                        } else {
                            warn!(
                                "âš ï¸  No stage result found for page {} (item index {})",
                                page_number, item_index
                            );
                        }
                    }
                }

                if enable_dedupe {
                    info!(
                        "âœ… Transformed {} Page items â†’ {} ProductUrls items (total_urls_collected={} after_dedupe={} duplicates_skipped={} recent_cache_size={})",
                        input_items.len(),
                        transformed_items.len(),
                        total_urls_collected,
                        total_urls_after_dedupe,
                        total_duplicates_skipped,
                        self.recent_product_urls.len()
                    );
                } else {
                    info!(
                        "âœ… Transformed {} Page items to {} ProductUrls items ({} total URLs)",
                        input_items.len(),
                        transformed_items.len(),
                        total_urls_collected
                    );
                }

                if transformed_items.is_empty() {
                    warn!(
                        "âš ï¸  No ProductURLs were extracted - all pages may have failed or returned no data"
                    );
                }
                // ëˆ„ì  í•©ì‚° í›„ ì €ì¥
                self.duplicates_skipped = self
                    .duplicates_skipped
                    .saturating_add(total_duplicates_skipped);

                Ok(transformed_items)
            }
            StageType::ProductDetailCrawling => {
                // ProductDetailCrawling â†’ DataValidation: collected_dataì—ì„œ ProductDetails ì¶”ì¶œ
                info!(
                    "ğŸ”„ ProductDetailCrawling â†’ DataValidation: extracting ProductDetails from collected data"
                );

                let mut transformed_items = Vec::new();
                let mut total_products_collected = 0;

                for (item_index, item) in input_items.iter().enumerate() {
                    let item_type_name = match item {
                        StageItem::Page(page) => format!("Page({})", page),
                        StageItem::Url(url) => format!("Url({})", url),
                        StageItem::Product(_) => "Product".to_string(),
                        StageItem::ValidationTarget(_) => "ValidationTarget".to_string(),
                        StageItem::ProductList(_) => "ProductList".to_string(),
                        StageItem::ProductUrls(urls) => {
                            format!("ProductUrls({} URLs)", urls.urls.len())
                        }
                        StageItem::ProductDetails(details) => {
                            format!("ProductDetails({} products)", details.products.len())
                        }
                        StageItem::ValidatedProducts(_) => "ValidatedProducts".to_string(),
                    };
                    info!(
                        "ğŸ” Checking item {} of type: {}",
                        item_index, item_type_name
                    );

                    if let StageItem::ProductUrls(_product_urls) = item {
                        // stage_resultì—ì„œ í•´ë‹¹ ì•„ì´í…œì˜ ì‹¤í–‰ ê²°ê³¼ í™•ì¸
                        info!("ğŸ” Looking for stage result at index {}", item_index);
                        if let Some(stage_item_result) = stage_result.details.get(item_index) {
                            info!(
                                "ğŸ” Found stage result: success={}, collected_data_present={}",
                                stage_item_result.success,
                                stage_item_result.collected_data.is_some()
                            );
                            if stage_item_result.success {
                                // ì‹¤ì œ ìˆ˜ì§‘ëœ ProductDetails ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                                if let Some(collected_data_json) = &stage_item_result.collected_data
                                {
                                    info!(
                                        "ğŸ”„ Attempting to parse ProductDetails JSON: {} chars",
                                        collected_data_json.len()
                                    );
                                    // JSONì—ì„œ ProductDetailsë¥¼ íŒŒì‹±
                                    match serde_json::from_str::<
                                        crate::new_architecture::channels::types::ProductDetails,
                                    >(collected_data_json)
                                    {
                                        Ok(product_details_wrapper) => {
                                            if !product_details_wrapper.products.is_empty() {
                                                let product_count =
                                                    product_details_wrapper.products.len();
                                                total_products_collected += product_count;
                                                transformed_items.push(StageItem::ProductDetails(
                                                    product_details_wrapper,
                                                ));
                                                info!(
                                                    "âœ… Extracted {} ProductDetails from ProductUrls",
                                                    product_count
                                                );
                                            } else {
                                                warn!(
                                                    "âš ï¸  ProductDetailCrawling succeeded but no ProductDetails were collected"
                                                );
                                            }
                                        }
                                        Err(e) => {
                                            error!(
                                                "âŒ Failed to parse ProductDetails from collected data: {}",
                                                e
                                            );
                                            error!(
                                                "ğŸ“„ Raw collected data preview: {}",
                                                &collected_data_json
                                                    [..collected_data_json.len().min(200)]
                                            );
                                        }
                                    }
                                } else {
                                    warn!(
                                        "âš ï¸  ProductDetailCrawling succeeded but no collected data available for item {} -> synthesizing minimal ProductDetails (dev mode)",
                                        item_index
                                    );
                                    // Synthesize minimal ProductDetails wrapper using the original ProductUrls if accessible
                                    if let StageItem::ProductUrls(urls_wrapper) = item {
                                        if !urls_wrapper.urls.is_empty() {
                                            // Use current domain::product::ProductDetail definition
                                            let synth_count = 3.min(urls_wrapper.urls.len());
                                            let now = chrono::Utc::now();
                                            let synth_products: Vec<
                                                crate::domain::product::ProductDetail,
                                            > = urls_wrapper
                                                .urls
                                                .iter()
                                                .take(synth_count)
                                                .enumerate()
                                                .map(|(i, u)| {
                                                    crate::domain::product::ProductDetail {
                                                        url: u.url.clone(),
                                                        page_id: Some(u.page_id),
                                                        index_in_page: Some(u.index_in_page),
                                                        id: None,
                                                        manufacturer: Some(
                                                            "SynthManufacturer".into(),
                                                        ),
                                                        model: Some(format!("Model{}", i)),
                                                        device_type: None,
                                                        certificate_id: None,
                                                        certification_date: None,
                                                        software_version: None,
                                                        hardware_version: None,
                                                        vid: None,
                                                        pid: None,
                                                        family_sku: None,
                                                        family_variant_sku: None,
                                                        firmware_version: None,
                                                        family_id: None,
                                                        tis_trp_tested: None,
                                                        specification_version: None,
                                                        transport_interface: None,
                                                        primary_device_type_id: None,
                                                        application_categories: None,
                                                        description: Some(
                                                            "Synthetic placeholder detail".into(),
                                                        ),
                                                        compliance_document_url: None,
                                                        program_type: Some("Synthetic".into()),
                                                        created_at: now,
                                                        updated_at: now,
                                                    }
                                                })
                                                .collect();
                                            let wrapper = crate::new_architecture::channels::types::ProductDetails {
                                                products: synth_products,
                                                source_urls: urls_wrapper.urls.clone(),
                                                extraction_stats: crate::new_architecture::channels::types::ExtractionStats {
                                                    attempted: urls_wrapper.urls.len() as u32,
                                                    successful: synth_count as u32,
                                                    failed: 0,
                                                    empty_responses: 0,
                                                },
                                            };
                                            total_products_collected += wrapper.products.len();
                                            transformed_items
                                                .push(StageItem::ProductDetails(wrapper));
                                            info!(
                                                "ğŸ§ª Synthesized {} ProductDetails (dev fallback)",
                                                synth_count
                                            );
                                        }
                                    }
                                }
                            } else {
                                warn!(
                                    "âš ï¸  ProductUrls failed in ProductDetailCrawling stage, skipping item {}",
                                    item_index
                                );
                            }
                        } else {
                            warn!(
                                "âš ï¸  No stage result found for ProductUrls item (item index {})",
                                item_index
                            );
                        }
                    } else {
                        info!("ğŸ” Skipping non-ProductUrls item at index {}", item_index);
                    }
                }

                info!(
                    "âœ… Transformed {} ProductUrls items to {} ProductDetails items ({} total products)",
                    input_items.len(),
                    transformed_items.len(),
                    total_products_collected
                );

                if transformed_items.is_empty() {
                    warn!("âš ï¸  No ProductDetails were extracted - all ProductUrls may have failed");
                }

                Ok(transformed_items)
            }
            StageType::DataValidation => {
                // DataValidation â†’ DataSaving: ProductDetails ì•„ì´í…œ ê·¸ëŒ€ë¡œ ì „ë‹¬
                let item_count = input_items.len();
                info!(
                    "ğŸ”„ DataValidation â†’ DataSaving: passing {} ProductDetails items",
                    item_count
                );
                Ok(input_items)
            }
            StageType::DataSaving => {
                // DataSavingì€ ë§ˆì§€ë§‰ ë‹¨ê³„ì´ë¯€ë¡œ ë³€í™˜ ë¶ˆí•„ìš”
                info!("ğŸ”„ DataSaving completed - pipeline finished");
                Ok(input_items)
            }
        }
    }
}
