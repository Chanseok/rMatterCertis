//! StageActor: ê°œë³„ ìŠ¤í…Œì´ì§€ ì‘ì—… ì²˜ë¦¬ Actor
//! 
//! Phase 3: Actor êµ¬í˜„ - ìŠ¤í…Œì´ì§€ ë ˆë²¨ ì‘ì—… ì‹¤í–‰ ë° ê´€ë¦¬
//! Modern Rust 2024 ì¤€ìˆ˜: í•¨ìˆ˜í˜• ì›ì¹™, ëª…ì‹œì  ì˜ì¡´ì„±, ìƒíƒœ ìµœì†Œí™”

use std::sync::Arc;
use std::time::{Duration, Instant};
use chrono::Utc;
use tokio::{sync::mpsc, time::timeout};
use tracing::{info, warn, error, debug};
use uuid::Uuid;
use once_cell::sync::Lazy;
use std::sync::Mutex as StdMutex;
use std::collections::HashSet;

use crate::infrastructure::{HttpClient, MatterDataExtractor, IntegratedProductRepository};
use crate::infrastructure::config::AppConfig;
use crate::new_architecture::actors::types::{AppEvent, StageResult, StageItemResult, StageItemType, ActorCommand, SimpleMetrics};
use crate::new_architecture::channels::types::{StageItem};
use crate::new_architecture::context::AppContext;
use crate::new_architecture::actors::traits::{Actor, ActorHealth, ActorStatus, ActorType};
use crate::new_architecture::actors::types::ActorError;
use crate::domain::services::SiteStatus;
use crate::infrastructure::crawling_service_impls::{StatusCheckerImpl, ProductListCollectorImpl, ProductDetailCollectorImpl, CollectorConfig};
use crate::domain::services::{StatusChecker, ProductListCollector, ProductDetailCollector};
use crate::new_architecture::actors::types::{StageType};
use crate::domain::pagination::PaginationCalculator;
use thiserror::Error;

// NOTE: ì›ë˜ íŒŒì¼ ìƒë‹¨ì´ ì†ìƒë˜ì–´ ì¬ì‘ì„±. ì•„ë˜ ê¸°ì¡´ êµ¬í˜„ë“¤ê³¼ ì—°ê²°ë˜ë„ë¡ ë™ì¼í•œ íƒ€ì…/impl ìœ ì§€.

// ë‚´ë¶€ ìƒíƒœ enum (ê°„ë‹¨ ì¬êµ¬ì„± - ì›ë˜ ì†ìƒëœ ì •ì˜ ë³µì›)
#[derive(Clone, PartialEq, Debug)]
enum StageState {
    Idle,
    Starting,
    Processing,
    Completed,
    Timeout,
    Failed { error: String },
}

#[derive(Debug, Error, Clone)]
pub enum StageError {
    #[error("Stage already processing: {0}")]
    AlreadyProcessing(String),
    #[error("Stage not found: {0}")]
    StageNotFound(String),
    #[error("Invalid configuration: {0}")]
    InvalidConfiguration(String),
    #[error("Service initialization failed: {0}")]
    ServiceInitialization(String),
    #[error("Initialization failed: {0}")]
    InitializationFailed(String),
    #[error("Context communication error: {0}")]
    ContextError(String),
    #[error("Processing timeout: {timeout_secs}s")]
    ProcessingTimeout { timeout_secs: u64 },
    #[error("Unsupported stage type: {0:?}")]
    UnsupportedStageType(StageType),
    #[error("Item processing failed: {item_id} - {error}")]
    ItemProcessingFailed { item_id: String, error: String },
}

// StageActor êµ¬ì¡°ì²´ (í•„ìš” í•„ë“œë§Œ ë³µì›; ë‚˜ë¨¸ì§€ ë¡œì§ê³¼ ë§¤ì¹­)
// Removed automatic Debug derive due to non-Debug trait object fields; manual impl below
pub struct StageActor {
    pub actor_id: String,
    pub batch_id: String,
    pub stage_id: Option<String>,
    pub stage_type: Option<StageType>,
    state: StageState,
    start_time: Option<Instant>,
    total_items: u32,
    completed_items: u32,
    success_count: u32,
    failure_count: u32,
    skipped_count: u32,
    item_results: Vec<StageItemResult>,
    // ì„œë¹„ìŠ¤ ì˜ì¡´ì„±
    status_checker: Option<Arc<dyn StatusChecker>>,
    product_list_collector: Option<Arc<dyn ProductListCollector>>,
    product_detail_collector: Option<Arc<dyn ProductDetailCollector>>,
    _product_repo: Option<Arc<IntegratedProductRepository>>,
    http_client: Option<Arc<HttpClient>>,
    data_extractor: Option<Arc<MatterDataExtractor>>,
    app_config: Option<AppConfig>,
    // íŒíŠ¸
    site_total_pages_hint: Option<u32>,
    products_on_last_page_hint: Option<u32>,
}

// Prevent duplicate DataSaving executions per (session_id,batch_id)
static DATA_SAVING_RUN_GUARD: Lazy<StdMutex<HashSet<String>>> = Lazy::new(|| StdMutex::new(HashSet::new()));

// Manual Debug implementation to avoid requiring Debug on all service trait object dependencies
impl std::fmt::Debug for StageActor {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("StageActor")
            .field("actor_id", &self.actor_id)
            .field("batch_id", &self.batch_id)
            .field("stage_id", &self.stage_id)
            .field("stage_type", &self.stage_type)
            .field("state", &self.state)
            .field("total_items", &self.total_items)
            .field("completed_items", &self.completed_items)
            .field("success_count", &self.success_count)
            .field("failure_count", &self.failure_count)
            .field("skipped_count", &self.skipped_count)
            .finish()
    }
}

// Extension trait to restore helper methods expected by per-item task logic
trait StageItemExt {
    fn id_string(&self) -> String;
    fn item_type_enum(&self) -> StageItemType;
}

impl StageItemExt for StageItem {
    fn id_string(&self) -> String {
        match self {
            StageItem::Page(p) => format!("page_{}", p),
            StageItem::Url(u) => u.clone(),
            StageItem::Product(p) => p.url.clone(),
            StageItem::ProductList(l) => format!("list_page_{}", l.page_number),
            StageItem::ProductUrls(urls) => format!("product_urls_{}", urls.urls.len()),
            StageItem::ProductDetails(d) => format!("product_details_{}", d.products.len()),
            StageItem::ValidatedProducts(v) => format!("validated_products_{}", v.products.len()),
            StageItem::ValidationTarget(v) => format!("validation_target_{}", v.len()),
        }
    }
    fn item_type_enum(&self) -> StageItemType {
        match self {
            StageItem::Page(page) => StageItemType::Page { page_number: *page },
            StageItem::Url(_u) => StageItemType::Url { url_type: "generic".into() },
            StageItem::Product(_p) => StageItemType::Url { url_type: "product".into() },
            StageItem::ProductList(_l) => StageItemType::ProductUrls { urls: vec![] },
            StageItem::ProductUrls(list) => StageItemType::ProductUrls { urls: list.urls.iter().map(|u| u.url.clone()).collect() },
            StageItem::ProductDetails(_d) => StageItemType::Url { url_type: "product_details".into() },
            StageItem::ValidatedProducts(_v) => StageItemType::Url { url_type: "validated_products".into() },
            StageItem::ValidationTarget(_t) => StageItemType::Url { url_type: "validation_target".into() },
        }
    }
}

impl StageActor {
    /// ìƒˆë¡œìš´ StageActor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    /// 
    /// # Arguments
    /// * `actor_id` - Actor ê³ ìœ  ì‹ë³„ì
    /// 
    /// # Returns
    /// * `Self` - ìƒˆë¡œìš´ StageActor ì¸ìŠ¤í„´ìŠ¤
    pub fn new(actor_id: String) -> Self {
        let batch_id = Uuid::new_v4().to_string();
        Self {
            actor_id,
            batch_id,
            stage_id: None,
            stage_type: None,
            state: StageState::Idle,
            start_time: None,
            total_items: 0,
            completed_items: 0,
            success_count: 0,
            failure_count: 0,
            skipped_count: 0,
            item_results: Vec::new(),
            status_checker: None,
            product_list_collector: None,
            product_detail_collector: None,
            _product_repo: None,
            http_client: None,
            data_extractor: None,
            app_config: None,
            site_total_pages_hint: None,
            products_on_last_page_hint: None,
        }
    }

    // (Early duplicate progress helpers removed; canonical versions near file end)
    
    /// ğŸ”¥ Phase 1: ì‹¤ì œ ì„œë¹„ìŠ¤ë“¤ê³¼ í•¨ê»˜ StageActor ìƒì„±
    /// 
    /// # Arguments
    /// * `actor_id` - Actor ê³ ìœ  ì‹ë³„ì
    /// * `batch_id` - ë°°ì¹˜ ì‹ë³„ì
    /// * `http_client` - HTTP í´ë¼ì´ì–¸íŠ¸
    /// * `data_extractor` - ë°ì´í„° ì¶”ì¶œê¸°
    /// * `product_repo` - ì œí’ˆ ë ˆí¬ì§€í† ë¦¬
    /// * `app_config` - ì•± ì„¤ì •
    /// 
    /// # Returns
    /// * `Self` - ì„œë¹„ìŠ¤ê°€ ì£¼ì…ëœ StageActor ì¸ìŠ¤í„´ìŠ¤
    pub fn new_with_services(
        actor_id: String,
        batch_id: String,
        http_client: Arc<HttpClient>,
        data_extractor: Arc<MatterDataExtractor>,
        product_repo: Arc<IntegratedProductRepository>,
        app_config: AppConfig,
    ) -> Self {
        // Arcì—ì„œ í´ë¡ ì„ í†µí•´ ì‹¤ì œ ê°’ ì¶”ì¶œ
        let http_client_inner = (*http_client).clone();
        let data_extractor_inner = (*data_extractor).clone();
        
        // ì‹¤ì œ ì„œë¹„ìŠ¤ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì»¬ë ‰í„° ìƒì„± (ServiceBasedBatchCrawlingEngine íŒ¨í„´ ì°¸ì¡°)
        let status_checker: Option<Arc<dyn StatusChecker>> = Some(Arc::new(StatusCheckerImpl::with_product_repo(
            http_client_inner.clone(),
            data_extractor_inner.clone(),
            app_config.clone(),
            Arc::clone(&product_repo),
        )));
        
        // ProductListCollector ìƒì„±
        let list_collector_config = CollectorConfig {
            max_concurrent: app_config.user.crawling.workers.list_page_max_concurrent as u32,
            concurrency: app_config.user.crawling.workers.list_page_max_concurrent as u32,
            delay_between_requests: Duration::from_millis(app_config.user.request_delay_ms),
            delay_ms: app_config.user.request_delay_ms,
            batch_size: app_config.user.batch.batch_size,
            retry_attempts: app_config.user.crawling.workers.max_retries,
            retry_max: app_config.user.crawling.workers.max_retries,
        };
        
        // StatusCheckerImplì„ ë‹¤ì‹œ ìƒì„± (ProductListCollectorê°€ StatusCheckerImplì„ ìš”êµ¬)
        let status_checker_for_list = Arc::new(StatusCheckerImpl::with_product_repo(
            http_client_inner.clone(),
            data_extractor_inner.clone(),
            app_config.clone(),
            Arc::clone(&product_repo),
        ));
        
        let product_list_collector: Option<Arc<dyn ProductListCollector>> = Some(Arc::new(ProductListCollectorImpl::new(
            Arc::new(http_client_inner.clone()),
            Arc::new(data_extractor_inner.clone()),
            list_collector_config.clone(),
            status_checker_for_list,
        )));
        
        // ProductDetailCollector ìƒì„±
        let detail_collector_config = CollectorConfig {
            max_concurrent: app_config.user.crawling.workers.product_detail_max_concurrent as u32,
            concurrency: app_config.user.crawling.workers.product_detail_max_concurrent as u32,
            delay_between_requests: Duration::from_millis(app_config.user.request_delay_ms),
            delay_ms: app_config.user.request_delay_ms,
            batch_size: app_config.user.batch.batch_size,
            retry_attempts: app_config.user.crawling.workers.max_retries,
            retry_max: app_config.user.crawling.workers.max_retries,
        };
        
        let product_detail_collector: Option<Arc<dyn ProductDetailCollector>> = Some(Arc::new(ProductDetailCollectorImpl::new(
            Arc::new(http_client_inner.clone()),
            Arc::new(data_extractor_inner.clone()),
            detail_collector_config,
        )));
        
        Self {
            actor_id,
            batch_id,
            stage_id: None,
            stage_type: None,
            state: StageState::Idle,
            start_time: None,
            total_items: 0,
            completed_items: 0,
            success_count: 0,
            failure_count: 0,
            skipped_count: 0,
            item_results: Vec::new(),
            // ì‹¤ì œ ì„œë¹„ìŠ¤ë“¤ ì£¼ì…
            status_checker,
            product_list_collector,
            product_detail_collector,
            _product_repo: Some(product_repo),
            http_client: Some(http_client),
            data_extractor: Some(data_extractor),
            app_config: Some(app_config),
            site_total_pages_hint: None,
            products_on_last_page_hint: None,
        }
    }
    
    /// OneShot Actor ì‹œìŠ¤í…œ í˜¸í™˜ì„±ì„ ìœ„í•œ ìƒì„±ì
    /// 
    /// # Arguments
    /// * `batch_id` - ë°°ì¹˜ ì‹ë³„ì
    /// * `config` - ì‹œìŠ¤í…œ ì„¤ì •
    /// * `total_pages` - ì´ í˜ì´ì§€ ìˆ˜ (ì„ íƒì )
    /// * `products_on_last_page` - ë§ˆì§€ë§‰ í˜ì´ì§€ ì œí’ˆ ìˆ˜ (ì„ íƒì )
    /// 
    /// # Returns
    /// * `Self` - ìƒˆë¡œìš´ StageActor ì¸ìŠ¤í„´ìŠ¤
    pub fn new_with_oneshot(
        batch_id: String, 
        _config: Arc<crate::new_architecture::config::SystemConfig>,
        _total_pages: u32,
        _products_on_last_page: u32
    ) -> Self {
        let actor_id = Uuid::new_v4().to_string();
        Self {
            actor_id,
            batch_id,
            stage_id: None,
            stage_type: None,
            state: StageState::Idle,
            start_time: None,
            total_items: 0,
            completed_items: 0,
            success_count: 0,
            failure_count: 0,
            skipped_count: 0,
            item_results: Vec::new(),
            status_checker: None,
            product_list_collector: None,
            product_detail_collector: None,
            _product_repo: None,
            http_client: None,
            data_extractor: None,
            app_config: None,
            site_total_pages_hint: None,
            products_on_last_page_hint: None,
        }
    }

    /// ì‚¬ì´íŠ¸ í˜ì´ì§€ë„¤ì´ì…˜ íŒíŠ¸ ì„¤ì • (StatusCheck ê²°ê³¼ë¥¼ ìƒìœ„ì—ì„œ ì£¼ì…)
    pub fn set_site_pagination_hints(&mut self, total_pages: u32, products_on_last_page: u32) {
        self.site_total_pages_hint = Some(total_pages);
        self.products_on_last_page_hint = Some(products_on_last_page);
        info!("ğŸ”§ Applied site pagination hints: total_pages={}, products_on_last_page={}", total_pages, products_on_last_page);
    }
    
    /// ì‹¤ì œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” - guide/re-arch-plan-final2.md ì„¤ê³„ ê¸°ë°˜
    /// ServiceBasedBatchCrawlingEngine íŒ¨í„´ ì°¸ì¡°í•˜ë˜ Actor ëª¨ë¸ì— ë§ê²Œ êµ¬í˜„
    pub async fn initialize_real_services(&mut self, _context: &AppContext) -> Result<(), StageError> {
        info!("ğŸ¯ [ACTOR] Initializing real services for StageActor: {}", self.actor_id);
        
        // AppConfig ë¡œë“œ (ì„¤ì • íŒŒì¼ì—ì„œ)
        let app_config = crate::infrastructure::config::AppConfig::default();
        
        // HTTP Client ìƒì„± (ServiceBasedBatchCrawlingEngineê³¼ ë™ì¼í•œ ë°©ì‹)
        let http_client = app_config.create_http_client()
            .map_err(|e| StageError::ServiceInitialization(format!("Failed to create HTTP client: {}", e)))?;
        
        // ë°ì´í„° ì¶”ì¶œê¸° ìƒì„±
        let data_extractor = MatterDataExtractor::new()
            .map_err(|e| StageError::ServiceInitialization(format!("Failed to create data extractor: {}", e)))?;
        
        // ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒì„± (ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
        let database_url = crate::infrastructure::database_paths::get_main_database_url();
        let pool = sqlx::SqlitePool::connect(&database_url).await
            .map_err(|e| StageError::ServiceInitialization(format!("Failed to connect to database: {}", e)))?;
        let product_repo = Arc::new(IntegratedProductRepository::new(pool));
        
        // StatusChecker ìƒì„± (ServiceBasedBatchCrawlingEngineê³¼ ë™ì¼í•œ ë°©ì‹)
        let status_checker = Arc::new(StatusCheckerImpl::with_product_repo(
            http_client.clone(),
            data_extractor.clone(),
            app_config.clone(),
            Arc::clone(&product_repo),
        ));
        
        // List Collector Config (ServiceBasedBatchCrawlingEngine íŒ¨í„´ ì°¸ì¡°)
        let list_collector_config = CollectorConfig {
            max_concurrent: app_config.user.crawling.workers.list_page_max_concurrent as u32,
            concurrency: app_config.user.crawling.workers.list_page_max_concurrent as u32,
            delay_between_requests: Duration::from_millis(app_config.user.request_delay_ms),
            delay_ms: app_config.user.request_delay_ms,
            batch_size: app_config.user.batch.batch_size,
            retry_attempts: app_config.user.crawling.workers.max_retries,
            retry_max: app_config.user.crawling.workers.max_retries,
        };
        
        let detail_collector_config = CollectorConfig {
            max_concurrent: app_config.user.crawling.workers.product_detail_max_concurrent as u32,
            concurrency: app_config.user.crawling.workers.product_detail_max_concurrent as u32,
            delay_between_requests: Duration::from_millis(app_config.user.request_delay_ms),
            delay_ms: app_config.user.request_delay_ms,
            batch_size: app_config.user.batch.batch_size,
            retry_attempts: app_config.user.crawling.workers.max_retries,
            retry_max: app_config.user.crawling.workers.max_retries,
        };
        
        // Status checkerë¥¼ concrete typeìœ¼ë¡œ ìƒì„± (ProductListCollectorì— í•„ìš”)
        let status_checker_impl = Arc::new(StatusCheckerImpl::with_product_repo(
            http_client.clone(),
            data_extractor.clone(),
            app_config.clone(),
            Arc::clone(&product_repo),
        ));
        
        // ProductListCollector ìƒì„± (ServiceBasedBatchCrawlingEngineê³¼ ë™ì¼í•œ ë°©ì‹)
        let product_list_collector = Arc::new(ProductListCollectorImpl::new(
            Arc::new(http_client.clone()),
            Arc::new(data_extractor.clone()),
            list_collector_config,
            status_checker_impl,
        ));
        
        // ProductDetailCollector ìƒì„± (ServiceBasedBatchCrawlingEngineê³¼ ë™ì¼í•œ ë°©ì‹)
        let product_detail_collector = Arc::new(ProductDetailCollectorImpl::new(
            Arc::new(http_client.clone()),
            Arc::new(data_extractor.clone()),
            detail_collector_config,
        ));
        
        // ì„œë¹„ìŠ¤ë“¤ì„ StageActorì— í• ë‹¹
        self.status_checker = Some(status_checker);
        self.product_list_collector = Some(product_list_collector);
        self.product_detail_collector = Some(product_detail_collector);
    self._product_repo = Some(product_repo);
        self.http_client = Some(Arc::new(http_client));
        self.data_extractor = Some(Arc::new(data_extractor));
        self.app_config = Some(app_config);
        
        info!("âœ… [ACTOR] Real services initialized successfully for StageActor: {}", self.actor_id);
        Ok(())
    }
    
    /// í¬ë¡¤ë§ ì—”ì§„ ì´ˆê¸°í™” (ì„ì‹œ êµ¬í˜„)
    /// í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì´ë¯€ë¡œ ì‹¤ì œ ì—”ì§„ ì´ˆê¸°í™”ëŠ” ê±´ë„ˆë›°ê¸°
    pub async fn initialize_default_engines(&mut self) -> Result<(), StageError> {
        // Phase 3ì—ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘
        // ì‹¤ì œ í¬ë¡¤ë§ ì—”ì§„ ì´ˆê¸°í™”ëŠ” í–¥í›„ êµ¬í˜„
        info!("ğŸ”§ StageActor {} initialized with simulation engines", self.actor_id);
        Ok(())
    }
    
    /// ê³µê°œ ìŠ¤í…Œì´ì§€ ì‹¤í–‰ ë©”ì„œë“œ (BatchActorì—ì„œ ì‚¬ìš©)
    /// 
    /// # Arguments
    /// * `stage_type` - ì‹¤í–‰í•  ìŠ¤í…Œì´ì§€ íƒ€ì…
    /// * `items` - ì²˜ë¦¬í•  ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
    /// * `concurrency_limit` - ë™ì‹œì„± ì œí•œ
    /// * `timeout_secs` - íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    pub async fn execute_stage(
        &mut self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        timeout_secs: u64,
        context: &AppContext,
    ) -> Result<StageResult, StageError> {
        self.handle_execute_stage(
            stage_type,
            items,
            concurrency_limit,
            timeout_secs,
            context,
        ).await?;
        
        Ok(StageResult {
            processed_items: self.completed_items,
            successful_items: self.success_count,
            failed_items: self.failure_count,
            duration_ms: self.start_time.map(|start| start.elapsed().as_millis() as u64).unwrap_or(0),
            details: self.item_results.clone(),
        })
    }
    
    /// ìŠ¤í…Œì´ì§€ ì‹¤í–‰ ì²˜ë¦¬
    /// 
    /// # Arguments
    /// * `stage_type` - ì‹¤í–‰í•  ìŠ¤í…Œì´ì§€ íƒ€ì…
    /// * `items` - ì²˜ë¦¬í•  ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
    /// * `concurrency_limit` - ë™ì‹œì„± ì œí•œ
    /// * `timeout_secs` - íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    async fn handle_execute_stage(
        &mut self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        timeout_secs: u64,
        context: &AppContext,
    ) -> Result<(), StageError> {
        // ìƒíƒœ ê²€ì¦
        if !matches!(self.state, StageState::Idle) {
            return Err(StageError::AlreadyProcessing(
                self.stage_id.clone().unwrap_or_else(|| "unknown".to_string())
            ));
        }
        
        let stage_id = Uuid::new_v4().to_string();
        
        info!("ğŸ¯ StageActor {} executing stage {:?} with {} items", 
              self.actor_id, stage_type, items.len());
        
        // ìƒíƒœ ì´ˆê¸°í™”
        self.stage_id = Some(stage_id.clone());
        self.stage_type = Some(stage_type.clone());
        self.state = StageState::Starting;
        self.start_time = Some(Instant::now());
        self.total_items = items.len() as u32;
        self.completed_items = 0;
        self.success_count = 0;
        self.failure_count = 0;
        self.skipped_count = 0;
        self.item_results.clear();
        
        // ìŠ¤í…Œì´ì§€ ì‹œì‘ ì´ë²¤íŠ¸ ë°œí–‰
        let start_event = AppEvent::StageStarted {
            stage_type: stage_type.clone(),
            session_id: context.session_id.clone(),
            batch_id: Some(self.batch_id.clone()),
            items_count: items.len() as u32,
            timestamp: Utc::now(),
        };
        
        context.emit_event(start_event).await
            .map_err(|e| StageError::ContextError(e.to_string()))?;
        
        // ìƒíƒœë¥¼ Processingìœ¼ë¡œ ì „í™˜
        self.state = StageState::Processing;
        
        // íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ìŠ¤í…Œì´ì§€ ì²˜ë¦¬
        let processing_result = timeout(
            Duration::from_secs(timeout_secs),
            self.process_stage_items(stage_type.clone(), items, concurrency_limit, context)
        ).await;
        
        match processing_result {
            Ok(result) => {
                match result {
                    Ok(stage_result) => {
                        self.state = StageState::Completed;
                        
                        // ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
                        let completion_event = AppEvent::StageCompleted {
                            stage_type: stage_type.clone(),
                            session_id: context.session_id.clone(),
                            batch_id: Some(self.batch_id.clone()),
                            result: stage_result,
                            timestamp: Utc::now(),
                        };
                        
                        context.emit_event(completion_event).await
                            .map_err(|e| StageError::ContextError(e.to_string()))?;
                        
                        info!("âœ… Stage {:?} completed successfully: {}/{} items processed", 
                              stage_type, self.success_count, self.total_items);
                    }
                    Err(e) => {
                        let error_msg = e.to_string();
                        self.state = StageState::Failed { error: error_msg.clone() };
                        
                        // ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë°œí–‰
                        let failure_event = AppEvent::StageFailed {
                            stage_type: stage_type.clone(),
                            session_id: context.session_id.clone(),
                            batch_id: Some(self.batch_id.clone()),
                            error: error_msg,
                            timestamp: Utc::now(),
                        };
                        
                        context.emit_event(failure_event).await
                            .map_err(|e| StageError::ContextError(e.to_string()))?;
                        
                        return Err(e);
                    }
                }
            }
            Err(_) => {
                // íƒ€ì„ì•„ì›ƒ ë°œìƒ
                self.state = StageState::Timeout;
                
                let error = StageError::ProcessingTimeout { timeout_secs };
                
                // íƒ€ì„ì•„ì›ƒ ì´ë²¤íŠ¸ ë°œí–‰
                let timeout_event = AppEvent::StageFailed {
                    stage_type: stage_type.clone(),
                    session_id: context.session_id.clone(),
                    batch_id: Some(self.batch_id.clone()),
                    error: error.to_string(),
                    timestamp: Utc::now(),
                };
                
                context.emit_event(timeout_event).await
                    .map_err(|e| StageError::ContextError(e.to_string()))?;
                
                return Err(error);
            }
        }
        
        Ok(())
    }
    
    /// ìŠ¤í…Œì´ì§€ ì•„ì´í…œë“¤ ì²˜ë¦¬
    /// 
    /// # Arguments
    /// * `stage_type` - ìŠ¤í…Œì´ì§€ íƒ€ì…
    /// * `items` - ì²˜ë¦¬í•  ì•„ì´í…œë“¤
    /// * `concurrency_limit` - ë™ì‹œì„± ì œí•œ
    /// * `context` - Actor ì»¨í…ìŠ¤íŠ¸
    async fn process_stage_items(
        &mut self,
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        _context: &AppContext,
    ) -> Result<StageResult, StageError> {
        debug!("Processing {} items for stage {:?}", items.len(), stage_type);
        
        // ë™ì‹œì„± ìƒí•œì„ Collectorì—ë„ ë°˜ì˜í•˜ë„ë¡ CollectorConfigë¥¼ ì¬êµ¬ì„±(í•„ìš” ì‹œ)
        if let (Some(http_client), Some(data_extractor), Some(app_config)) = (&self.http_client, &self.data_extractor, &self.app_config) {
            // ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ê¸°
            if let Some(repo) = &self._product_repo {
                let list_cfg = crate::infrastructure::crawling_service_impls::CollectorConfig {
                    max_concurrent: concurrency_limit,
                    concurrency: concurrency_limit,
                    delay_between_requests: std::time::Duration::from_millis(app_config.user.request_delay_ms),
                    delay_ms: app_config.user.request_delay_ms,
                    batch_size: app_config.user.batch.batch_size,
                    retry_attempts: app_config.user.crawling.workers.max_retries,
                    retry_max: app_config.user.crawling.workers.max_retries,
                };
                let status_checker_for_list = Arc::new(crate::infrastructure::crawling_service_impls::StatusCheckerImpl::with_product_repo(
                    (**http_client).clone(),
                    (**data_extractor).clone(),
                    app_config.clone(),
                    Arc::clone(repo),
                ));
                self.product_list_collector = Some(Arc::new(crate::infrastructure::crawling_service_impls::ProductListCollectorImpl::new(
                    Arc::clone(http_client),
                    Arc::clone(data_extractor),
                    list_cfg,
                    status_checker_for_list,
                )));
            }

            // ìƒì„¸ ìˆ˜ì§‘ê¸°
            let detail_cfg = crate::infrastructure::crawling_service_impls::CollectorConfig {
                max_concurrent: concurrency_limit,
                concurrency: concurrency_limit,
                delay_between_requests: std::time::Duration::from_millis(app_config.user.request_delay_ms),
                delay_ms: app_config.user.request_delay_ms,
                batch_size: app_config.user.batch.batch_size,
                retry_attempts: app_config.user.crawling.workers.max_retries,
                retry_max: app_config.user.crawling.workers.max_retries,
            };
            self.product_detail_collector = Some(Arc::new(crate::infrastructure::crawling_service_impls::ProductDetailCollectorImpl::new(
                Arc::clone(http_client),
                Arc::clone(data_extractor),
                detail_cfg,
            )));
        }

        // ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´
        let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit as usize));
        let mut tasks = Vec::new();
        
        // ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ë³µì‚¬
        let status_checker = self.status_checker.clone();
        let product_list_collector = self.product_list_collector.clone();
        let product_detail_collector = self.product_detail_collector.clone();
    let product_repo = self._product_repo.clone();
        let http_client = self.http_client.clone();
        let data_extractor = self.data_extractor.clone();
    // í˜ì´ì§€ë„¤ì´ì…˜ íŒíŠ¸ ë³µì‚¬
    let site_total_pages_hint = self.site_total_pages_hint;
    let products_on_last_page_hint = self.products_on_last_page_hint;
        
        // ê° ì•„ì´í…œì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
        for item in items {
            let sem = semaphore.clone();
            let base_item = item.clone(); // used for lifecycle pre-emits
            let stage_type_clone = stage_type.clone();
            let status_checker_clone = status_checker.clone();
            let product_list_collector_clone = product_list_collector.clone();
            let product_detail_collector_clone = product_detail_collector.clone();
            let product_repo_clone = product_repo.clone();
            let http_client_clone = http_client.clone();
            let data_extractor_clone = data_extractor.clone();
            let session_id_clone = _context.session_id.clone();
            let batch_id_opt = Some(self.batch_id.clone());
            let ctx_clone = _context.clone();
            // Pre-emit lifecycle coarse events (page/product) before spawning heavy work
            match (&stage_type, &base_item) {
                (StageType::ListPageCrawling, StageItem::Page(pn)) => {
                    if let Err(e) = ctx_clone.emit_event(AppEvent::PageLifecycle { session_id: session_id_clone.clone(), batch_id: batch_id_opt.clone(), page_number: *pn, status: "fetch_started".into(), metrics: None, timestamp: Utc::now() }).await {
                        error!("PageLifecycle fetch_started emit failed page={} err={}", pn, e);
                    } else {
                        debug!("Emitted PageLifecycle fetch_started page={}", pn);
                    }
                }
                (StageType::ProductDetailCrawling, StageItem::ProductUrls(urls)) => {
                    let count = urls.urls.len() as u32;
                    let metrics = crate::new_architecture::actors::types::SimpleMetrics::Page { url_count: None, scheduled_details: Some(count), error: None };
                    let page_hint = urls.urls.first().map(|u| u.page_id as u32).unwrap_or(0u32);
                    if let Err(e) = ctx_clone.emit_event(AppEvent::PageLifecycle { session_id: session_id_clone.clone(), batch_id: batch_id_opt.clone(), page_number: page_hint, status: "detail_scheduled".into(), metrics: Some(metrics), timestamp: Utc::now() }).await {
                        error!("PageLifecycle detail_scheduled emit failed page={} err={}", page_hint, e);
                    } else {
                        debug!("Emitted PageLifecycle detail_scheduled page={} scheduled_details={}", page_hint, count);
                    }
                    for pu in &urls.urls { // per-product fetch_started
                        if let Err(e) = ctx_clone.emit_event(AppEvent::ProductLifecycle {
                            session_id: session_id_clone.clone(),
                            batch_id: batch_id_opt.clone(),
                            page_number: Some(pu.page_id as u32),
                            product_ref: pu.url.clone(),
                            status: "fetch_started".into(),
                            retry: None,
                            duration_ms: None,
                            metrics: None,
                            timestamp: Utc::now(),
                        }).await {
                            error!("ProductLifecycle fetch_started emit failed product={} err={}", pu.url, e);
                        }
                    }
                }
                _ => {}
            }
            let task = tokio::spawn(async move {
                let _permit = sem.acquire().await.map_err(|e|
                    StageError::InitializationFailed(format!("Semaphore error: {}", e))
                )?;
                if let Err(e) = ctx_clone.emit_event(AppEvent::StageItemStarted {
                    session_id: session_id_clone.clone(),
                    batch_id: batch_id_opt.clone(),
                    stage_type: stage_type_clone.clone(),
                    item_id: base_item.id_string(),
                    item_type: base_item.item_type_enum(),
                    timestamp: Utc::now(),
                }).await { tracing::error!("StageItemStarted emit failed: {}", e); }
                let item_start = Instant::now();
                let temp_actor = StageActor {
                    actor_id: "temp".to_string(),
                    batch_id: "temp".to_string(),
                    stage_id: None,
                    stage_type: None,
                    state: StageState::Idle,
                    start_time: None,
                    total_items: 0,
                    completed_items: 0,
                    success_count: 0,
                    failure_count: 0,
                    skipped_count: 0,
                    item_results: Vec::new(),
                    status_checker: status_checker_clone.clone(),
                    product_list_collector: product_list_collector_clone.clone(),
                    product_detail_collector: product_detail_collector_clone.clone(),
                    _product_repo: product_repo_clone.clone(),
                    http_client: http_client_clone,
                    data_extractor: data_extractor_clone,
                    app_config: None,
                    site_total_pages_hint,
                    products_on_last_page_hint,
                };
                let lifecycle_item = base_item.clone();
                let processing_item = base_item.clone();
                let result = temp_actor.process_single_item(
                    stage_type_clone.clone(),
                    processing_item,
                    status_checker_clone,
                    product_list_collector_clone,
                    product_detail_collector_clone,
                    product_repo_clone,
                ).await;
                match &result {
                    Ok(r) => {
                        // If this is DataSaving stage, perform persistence now (previous arm returned Ok(()))
                        // NOTE: Previous pattern used value patterns against references &StageType/&StageItem and never matched.
                        // We now explicitly match references to ensure the block executes.
                        if matches!(stage_type_clone, StageType::DataSaving) {
                            // DataSaving ë‹¨ê³„ì—ì„œëŠ” ProductDetails ë˜ëŠ” ValidatedProducts ë‘˜ ë‹¤ ì €ì¥ ëŒ€ìƒì´ ë  ìˆ˜ ìˆìŒ
                            let is_persist_target = matches!(lifecycle_item, StageItem::ProductDetails(_)) || matches!(lifecycle_item, StageItem::ValidatedProducts(_));
                            if is_persist_target {
                                info!("[Persist] Enter DataSaving block batch_id={:?} variant={}", batch_id_opt, match &lifecycle_item { StageItem::ProductDetails(_) => "ProductDetails", StageItem::ValidatedProducts(_) => "ValidatedProducts", _ => "Other" });
                                // Duplicate guard
                                let guard_key = format!("{}:{}:data_saving", session_id_clone, batch_id_opt.clone().unwrap_or_else(|| "none".into()));
                                if let Ok(mut guard) = DATA_SAVING_RUN_GUARD.lock() {
                                    if guard.contains(&guard_key) {
                                        info!("[PersistGuard] duplicate DataSaving suppression key={}", guard_key);
                                        return Ok(StageItemResult { item_id: "data_saving_guard".into(), item_type: StageItemType::Url { url_type: "data_saving".into() }, success: true, error: None, duration_ms: item_start.elapsed().as_millis() as u64, retry_count: 0, collected_data: None });
                                    } else {
                                        guard.insert(guard_key);
                                        info!("[PersistGuard] first DataSaving execution proceeding");
                                    }
                                }
                                // decide skip via env inside task scope
                                let skip_save = std::env::var("MC_SKIP_DB_SAVE")
                                    .ok()
                                    .map(|v| v == "1" || v.eq_ignore_ascii_case("true"))
                                    .unwrap_or(false);
                                if skip_save {
                                    info!("[Persist] Skipped by env MC_SKIP_DB_SAVE");
                                    if let Err(e) = ctx_clone.emit_event(AppEvent::ProductLifecycle {
                                        session_id: session_id_clone.clone(),
                                        batch_id: batch_id_opt.clone(),
                                        page_number: None,
                                        product_ref: "_batch_persist".into(),
                                        status: "persist_skipped".into(),
                                        retry: None,
                                        duration_ms: None,
                                        metrics: Some(SimpleMetrics::Generic { key: "reason".into(), value: "MC_SKIP_DB_SAVE".into() }),
                                        timestamp: Utc::now(),
                                    }).await { error!("ProductLifecycle persist_skipped emit failed err={}", e); }
                                } else {
                                    let attempted_count = match &lifecycle_item { StageItem::ValidatedProducts(v) => v.products.len() as u32, StageItem::ProductDetails(d) => d.products.len() as u32, _ => 0 };
                                    if let Err(e) = ctx_clone.emit_event(AppEvent::ProductLifecycle {
                                        session_id: session_id_clone.clone(),
                                        batch_id: batch_id_opt.clone(),
                                        page_number: None,
                                        product_ref: "_batch_persist".into(),
                                        status: "persist_started".into(),
                                        retry: None,
                                        duration_ms: None,
                                        metrics: Some(SimpleMetrics::Generic { key: "attempted_count".into(), value: attempted_count.to_string() }),
                                        timestamp: Utc::now(),
                                    }).await { error!("ProductLifecycle persist_started emit failed err={}", e); }
                                    let persist_start = Instant::now();
                                    if attempted_count == 0 {
                                        info!("[Persist] Empty batch (attempted_count=0) -> emit persist_empty and skip storage call");
                                        let _ = ctx_clone.emit_event(AppEvent::ProductLifecycle {
                                            session_id: session_id_clone.clone(),
                                            batch_id: batch_id_opt.clone(),
                                            page_number: None,
                                            product_ref: "_batch_persist".into(),
                                            status: "persist_empty".into(),
                                            retry: None,
                                            duration_ms: Some(0),
                                            metrics: Some(SimpleMetrics::Generic { key: "persist_result".into(), value: "attempted=0".into() }),
                                            timestamp: Utc::now(),
                                        }).await;
                                        return Ok(StageItemResult { item_id: "data_saving_empty".into(), item_type: StageItemType::Url { url_type: "data_saving".into() }, success: true, error: None, duration_ms: item_start.elapsed().as_millis() as u64, retry_count: 0, collected_data: None });
                                    }
                                    if let Some(repo) = &temp_actor._product_repo {
                                        info!("[PersistExec] starting storage call variant={}", match &lifecycle_item { StageItem::ProductDetails(_) => "ProductDetails", StageItem::ValidatedProducts(_) => "ValidatedProducts", _ => "Other" });
                                        match StageActor::execute_real_database_storage(&lifecycle_item, repo.clone()).await {
                                            Ok((inserted, updated, duplicates_ct)) => {
                                                let total = inserted + updated;
                                                let attempted = attempted_count; // from outer scope
                                                let unchanged = if attempted > total { attempted - total } else { 0 };
                                                let status = if inserted > 0 && updated == 0 { "persist_inserted" } else if updated > 0 && inserted == 0 { "persist_updated" } else if inserted == 0 && updated == 0 { if duplicates_ct == attempted { "persist_noop_all_duplicate" } else { "persist_noop" } } else { "persist_mixed" };
                                                info!("[Persist] Result status={} inserted={} updated={} duplicates={} total={} unchanged={} attempted={} duration_ms={}", status, inserted, updated, duplicates_ct, total, unchanged, attempted, persist_start.elapsed().as_millis());
                                                let metrics = SimpleMetrics::Generic { key: "persist_result".into(), value: format!("attempted={},inserted={},updated={},duplicates={},total={},unchanged={}", attempted, inserted, updated, duplicates_ct, total, unchanged) };
                                                let emit_res = ctx_clone.emit_event(AppEvent::ProductLifecycle {
                                                    session_id: session_id_clone.clone(),
                                                    batch_id: batch_id_opt.clone(),
                                                    page_number: None,
                                                    product_ref: "_batch_persist".into(),
                                                    status: status.into(),
                                                    retry: None,
                                                    duration_ms: Some(persist_start.elapsed().as_millis() as u64),
                                                    metrics: Some(metrics),
                                                    timestamp: Utc::now(),
                                                }).await;
                                                match emit_res {
                                                    Ok(_) => info!("[PersistEmit] lifecycle emitted status={}", status),
                                                    Err(e) => error!("ProductLifecycle {} emit failed err={}", status, e)
                                                }
                                                if status == "persist_noop" {
                                                    // emit anomaly diagnostic + (future) logical drift probe
                                                    if let Some(repo) = &temp_actor._product_repo {
                                                        if let Ok((cnt, minp, maxp, _)) = repo.get_product_detail_stats().await {
                                                            let attempted = match &lifecycle_item { StageItem::ValidatedProducts(v) => v.products.len() as u32, StageItem::ProductDetails(d) => d.products.len() as u32, _ => total };
                                                            let _ = ctx_clone.emit_event(AppEvent::PersistenceAnomaly {
                                                                session_id: session_id_clone.clone(),
                                                                batch_id: batch_id_opt.clone(),
                                                                kind: "all_noop".into(),
                                                                detail: format!("All attempted saves were noop: attempted={} inserted={} updated={} db_total={} db_page_range={:?}-{:?}", attempted, inserted, updated, cnt, minp, maxp),
                                                                attempted,
                                                                inserted,
                                                                updated,
                                                                timestamp: Utc::now(),
                                                            }).await;
                                                            // LogicalMappingDrift (placeholder): detect unexpected min/max inversion or large gap
                                                            if let (Some(min_p), Some(max_p)) = (minp, maxp) {
                                                                if min_p > max_p { // impossible condition -> drift
                                                                    let _ = ctx_clone.emit_event(AppEvent::PersistenceAnomaly {
                                                                        session_id: session_id_clone.clone(),
                                                                        batch_id: batch_id_opt.clone(),
                                                                        kind: "logical_mapping_drift".into(),
                                                                        detail: format!("Inverted page range detected min_page={} > max_page={} during noop persistence", min_p, max_p),
                                                                        attempted,
                                                                        inserted,
                                                                        updated,
                                                                        timestamp: Utc::now(),
                                                                    }).await;
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                            Err(e) => {
                                                error!("[Persist] Failed error={} duration_ms={}", e, persist_start.elapsed().as_millis());
                                                let emit_res = ctx_clone.emit_event(AppEvent::ProductLifecycle {
                                                    session_id: session_id_clone.clone(),
                                                    batch_id: batch_id_opt.clone(),
                                                    page_number: None,
                                                    product_ref: "_batch_persist".into(),
                                                    status: "persist_failed".into(),
                                                    retry: None,
                                                    duration_ms: Some(persist_start.elapsed().as_millis() as u64),
                                                    metrics: Some(SimpleMetrics::Generic { key: "error".into(), value: e.clone() }),
                                                    timestamp: Utc::now(),
                                                }).await;
                                                if let Err(e2) = emit_res { error!("ProductLifecycle persist_failed emit failed err={}", e2); } else { info!("[PersistEmit] lifecycle emitted status=persist_failed"); }
                                            }
                                        }
                                    } else {
                                        error!("Product repository not available during DataSaving persistence stage");
                                    }
                                }
                            }
                        }
                        if let Err(e) = ctx_clone.emit_event(AppEvent::StageItemCompleted {
                            session_id: session_id_clone.clone(),
                            batch_id: batch_id_opt.clone(),
                            stage_type: stage_type_clone.clone(),
                            item_id: r.item_id.clone(),
                            item_type: r.item_type.clone(),
                            success: true,
                            error: None,
                            duration_ms: item_start.elapsed().as_millis() as u64,
                            retry_count: r.retry_count,
                            collected_count: r.collected_data.as_ref().map(|d| {
                                // JSON ë°°ì—´ì¼ ê°€ëŠ¥ì„± ë†’ìŒ â†’ ëŒ€ëµ ê¸¸ì´ ì¶”ì • (ê°„ë‹¨ ì²˜ë¦¬)
                                if d.starts_with('[') { d.matches("\"").count() as u32 / 2 } else { 1 }
                            }),
                            timestamp: Utc::now(),
                        }).await { tracing::error!("StageItemCompleted emit failed: {}", e); }
                        // Emit lifecycle completion for page or product aggregated result
                        if let (StageType::ListPageCrawling, StageItem::Page(pn)) = (&stage_type_clone, &lifecycle_item) {
                            let metrics = crate::new_architecture::actors::types::SimpleMetrics::Page { url_count: Some(r.collected_data.as_ref().map(|d| d.len() as u32).unwrap_or(0)), scheduled_details: None, error: None };
                            if let Err(e) = ctx_clone.emit_event(AppEvent::PageLifecycle { session_id: session_id_clone.clone(), batch_id: batch_id_opt.clone(), page_number: *pn, status: "fetch_completed".into(), metrics: Some(metrics), timestamp: Utc::now() }).await { error!("PageLifecycle fetch_completed emit failed page={} err={}", pn, e); } else { debug!("Emitted PageLifecycle fetch_completed page={}", pn); }
                        }
                        // Product detail lifecycle completion (group success)
                        if let (StageType::ProductDetailCrawling, StageItem::ProductUrls(urls)) = (&stage_type_clone, &lifecycle_item) {
                            for pu in &urls.urls {
                                if let Err(e) = ctx_clone.emit_event(AppEvent::ProductLifecycle {
                                    session_id: session_id_clone.clone(),
                                    batch_id: batch_id_opt.clone(),
                                    page_number: Some(pu.page_id as u32),
                                    product_ref: pu.url.clone(),
                                    status: "fetch_completed".into(),
                                    retry: None,
                                    duration_ms: Some(item_start.elapsed().as_millis() as u64),
                                    metrics: None,
                                    timestamp: Utc::now(),
                                }).await { error!("ProductLifecycle fetch_completed emit failed product={} err={}", pu.url, e); }
                            }
                        }
                    }
                    Err(err) => {
                        if let Err(e) = ctx_clone.emit_event(AppEvent::StageItemCompleted {
                            session_id: session_id_clone.clone(),
                            batch_id: batch_id_opt.clone(),
                            stage_type: stage_type_clone.clone(),
                            item_id: "unknown".into(),
                            item_type: StageItemType::Url { url_type: "unknown".into() },
                            success: false,
                            error: Some(err.to_string()),
                            duration_ms: item_start.elapsed().as_millis() as u64,
                            retry_count: 0,
                            collected_count: None,
                            timestamp: Utc::now(),
                        }).await { tracing::error!("StageItemCompleted emit failed: {}", e); }
                        if let (StageType::ListPageCrawling, StageItem::Page(pn)) = (&stage_type_clone, &lifecycle_item) {
                            let metrics = crate::new_architecture::actors::types::SimpleMetrics::Page { url_count: None, scheduled_details: None, error: Some(err.to_string()) };
                            if let Err(e2) = ctx_clone.emit_event(AppEvent::PageLifecycle { session_id: session_id_clone.clone(), batch_id: batch_id_opt.clone(), page_number: *pn, status: "failed".into(), metrics: Some(metrics), timestamp: Utc::now() }).await { error!("PageLifecycle failed emit failed page={} err={}", pn, e2); } else { debug!("Emitted PageLifecycle failed page={}", pn); }
                        }
                        // Product detail lifecycle failure
                        if let (StageType::ProductDetailCrawling, StageItem::ProductUrls(urls)) = (&stage_type_clone, &lifecycle_item) {
                            for pu in &urls.urls {
                                let metrics = crate::new_architecture::actors::types::SimpleMetrics::Product { fields: None, size_bytes: None, error: Some(err.to_string()) };
                                if let Err(e2) = ctx_clone.emit_event(AppEvent::ProductLifecycle {
                                    session_id: session_id_clone.clone(),
                                    batch_id: batch_id_opt.clone(),
                                    page_number: Some(pu.page_id as u32),
                                    product_ref: pu.url.clone(),
                                    status: "failed".into(),
                                    retry: None,
                                    duration_ms: Some(item_start.elapsed().as_millis() as u64),
                                    metrics: Some(metrics),
                                    timestamp: Utc::now(),
                                }).await { error!("ProductLifecycle failed emit failed product={} err={}", pu.url, e2); }
                            }
                        }
                    }
                }
                result
            });
            tasks.push(task);
        }
        
        // ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
        let mut results = Vec::new();
        for task in tasks {
            match task.await {
                Ok(Ok(result)) => {
                    results.push(result);
                }
                Ok(Err(e)) => {
                    error!("Item processing failed: {}", e);
                    results.push(StageItemResult {
                        item_id: "unknown".to_string(),
                        item_type: StageItemType::Url { url_type: "unknown".to_string() },
                        success: false,
                        error: Some(e.to_string()),
                        duration_ms: 0,
                        retry_count: 0,
                        collected_data: None,
                    });
                }
                Err(e) => {
                    error!("Task join error: {}", e);
                    results.push(StageItemResult {
                        item_id: "unknown".to_string(),
                        item_type: StageItemType::Url { url_type: "unknown".to_string() },
                        success: false,
                        error: Some(format!("Task join error: {}", e)),
                        duration_ms: 0,
                        retry_count: 0,
                        collected_data: None,
                    });
                }
            }
        }
        
        // ê²°ê³¼ ì§‘ê³„
        self.item_results = results;
        self.completed_items = self.item_results.len() as u32;
        self.success_count = self.item_results.iter().filter(|r| r.success).count() as u32;
        self.failure_count = self.item_results.iter().filter(|r| !r.success).count() as u32;
        
        let duration = self.start_time
            .map(|start| start.elapsed())
            .unwrap_or(Duration::ZERO);
        
        Ok(StageResult {
            processed_items: self.completed_items,
            successful_items: self.success_count,
            failed_items: self.failure_count,
            duration_ms: duration.as_millis() as u64,
            details: self.item_results.clone(),
        })
    }
    
    /// ê°œë³„ ì•„ì´í…œ ì²˜ë¦¬ (ì‹¤ì œ ì„œë¹„ìŠ¤ ì‚¬ìš©)
    /// 
    /// # Arguments
    /// * `stage_type` - ìŠ¤í…Œì´ì§€ íƒ€ì…
    /// * `item` - ì²˜ë¦¬í•  ì•„ì´í…œ
    async fn process_single_item(
        &self,
        stage_type: StageType,
        item: StageItem,
        status_checker: Option<Arc<dyn StatusChecker>>,
        product_list_collector: Option<Arc<dyn ProductListCollector>>,
    _product_detail_collector: Option<Arc<dyn ProductDetailCollector>>,
    _product_repo: Option<Arc<IntegratedProductRepository>>,
    ) -> Result<StageItemResult, StageError> {
        let start_time = Instant::now();
        
        let item_id = match &item {
            StageItem::Page(page_num) => format!("page_{}", page_num),
            StageItem::Url(url) => url.clone(),
            StageItem::Product(product) => product.url.clone(),
            StageItem::ProductList(list) => format!("page_{}", list.page_number),
            StageItem::ProductUrls(urls) => format!("urls_{}", urls.urls.len()),
            StageItem::ProductDetails(details) => format!("details_{}", details.products.len()),
            StageItem::ValidatedProducts(products) => format!("validated_{}", products.products.len()),
            _ => "unknown".to_string(),
        };
        
        debug!("Processing item {} for stage {:?}", item_id, stage_type);
        
        // ìŠ¤í…Œì´ì§€ íƒ€ì…ë³„ ì²˜ë¦¬ ë¡œì§ - ìˆ˜ì§‘ëœ ë°ì´í„°ì™€ ì„±ê³µ ì—¬ë¶€ë¥¼ í•¨ê»˜ ë°˜í™˜
        let (success, collected_data, retries_used) = match stage_type {
            StageType::StatusCheck => {
                if let Some(checker) = status_checker {
                    match Self::execute_real_status_check(&item, checker).await {
                        Ok(site_status) => {
                            match serde_json::to_string(&site_status) {
                                Ok(json) => (Ok(()), Some(json), 0),
                                Err(e) => (Err(format!("JSON serialization failed: {}", e)), None, 0),
                            }
                        }
                        Err(e) => (Err(e), None, 0),
                    }
                } else {
                    // StatusCheckerê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
                    (Err("StatusChecker not available".to_string()), None, 0)
                }
            }
            StageType::ListPageCrawling => {
                if let Some(collector) = product_list_collector {
                    // ì¬ì‹œë„ ì„¤ì • ë¡œë“œ
                    // ê¶Œì¥ ê¸°ë³¸ ì¬ì‹œë„ ê°’ (ì„¤ëª…ëœ ìŠ¤í™ ê¸°ë°˜): ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ 4íšŒ
                    const RECOMMENDED_MAX_RETRIES_LIST: u32 = 4;
                    let (cfg_retries, base_delay_ms) = if let Some(cfg) = &self.app_config {
                        (cfg.user.crawling.workers.max_retries, cfg.user.crawling.timing.retry_delay_ms)
                    } else {
                        (3u32, 1000u64)
                    };
                    // ì„¤ì •ê°’ê³¼ ê¶Œì¥ê°’ ì¤‘ í° ê°’ ì ìš©
                    let max_retries = std::cmp::max(cfg_retries, RECOMMENDED_MAX_RETRIES_LIST);
                    // ì§€ìˆ˜ ë°±ì˜¤í”„ + ì§€í„°ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„°
                    let base_delay_ms = base_delay_ms.max(200); // ì•ˆì „í•œ ìµœì†Œê°’
                    let max_delay_ms: u64 = 30_000; // 30ì´ˆ ìƒí•œ

                    let mut attempt: u32 = 0;
                    loop {
                        match self.execute_real_list_page_processing(&item, Arc::clone(&collector)).await {
                            Ok(urls) => {
                                // ProductURLë“¤ì„ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ ì €ì¥
                                match serde_json::to_string(&urls) {
                                    Ok(json_data) => break (Ok(()), Some(json_data), attempt),
                                    Err(e) => break (Err(format!("JSON serialization failed: {}", e)), None, attempt),
                                }
                            }
                            Err(e) => {
                                if attempt < max_retries {
                                    attempt += 1;
                                    // ì§€ìˆ˜ ë°±ì˜¤í”„: base * 2^(attempt-1)
                                    // Note: use checked_shl to avoid panics for large shifts
                                    let factor = 1u64
                                        .checked_shl(attempt - 1)
                                        .unwrap_or(u64::MAX);
                                    let exp = base_delay_ms.saturating_mul(factor);
                                    let capped = std::cmp::min(exp, max_delay_ms);
                                    // ì§€í„°: ìµœëŒ€ 20% ëœë¤ ê°€ì‚°
                                    let jitter = if capped >= 10 {
                                        let range = capped / 5; // 20%
                                        fastrand::u64(0..=range)
                                    } else { 0 };
                                    let delay = capped.saturating_add(jitter);
                                    warn!(
                                        "ğŸ” ListPageCrawling attempt {}/{} after {}ms (reason: {})",
                                        attempt,
                                        max_retries,
                                        delay,
                                        e
                                    );
                                    tokio::time::sleep(std::time::Duration::from_millis(delay)).await;
                                    continue;
                                } else {
                                    error!("âŒ ListPageCrawling final failure: {}", e);
                                    break (Err(e), None, attempt);
                                }
                            }
                        }
                    }
                } else {
                    // ProductListCollectorê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
                    (Err("ProductListCollector not available".to_string()), None, 0)
                }
            }
            StageType::ProductDetailCrawling => {
                // Stage 2ì˜ ê²°ê³¼ë¡œ ë°›ì€ ProductUrlsì—ì„œ ì‹¤ì œ ì œí’ˆ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        info!("ğŸ” ProductDetailCrawling: processing ProductUrls from item {}", item_id);

                match &item {
                    StageItem::ProductUrls(product_urls) => {
            // Compact: log once at start of detail crawling for this item
            info!("ğŸ“‹ Detail crawling for {} product URLs", product_urls.urls.len());
                        
                        if let Some(collector) = &self.product_detail_collector {
                            // ì‹¤ì œ ProductDetailCollectorë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                            match Self::execute_real_product_detail_processing(product_urls, Arc::clone(collector)).await {
                                Ok(product_details) => {
                                    info!("âœ… Successfully collected {} product details", product_details.len());
                                    
                                    // ProductDetails ë˜í¼ ìƒì„±
                                    use crate::new_architecture::channels::types::{ProductDetails, ExtractionStats};
                                    let product_details_wrapper = ProductDetails {
                                        products: product_details.clone(),
                                        source_urls: product_urls.urls.clone(),
                                        extraction_stats: ExtractionStats {
                                            attempted: product_urls.urls.len() as u32,
                                            successful: product_details.len() as u32,
                                            failed: (product_urls.urls.len() - product_details.len()) as u32,
                                            empty_responses: 0, // í˜„ì¬ëŠ” 0ìœ¼ë¡œ ì„¤ì •
                                        },
                                    };
                                    
                                    // ProductDetails ë˜í¼ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ ì €ì¥
                    debug!("Serializing ProductDetails wrapper with {} products", product_details_wrapper.products.len());
                                    match serde_json::to_string(&product_details_wrapper) {
                                        Ok(json_data) => {
                        debug!("ProductDetails JSON serialization successful: {} chars", json_data.len());
                                            (Ok(()), Some(json_data), 0)
                                        },
                                        Err(e) => {
                                            error!("âŒ ProductDetails JSON serialization failed: {}", e);
                                            (Err(format!("JSON serialization failed: {}", e)), None, 0)
                                        },
                                    }
                                }
                                Err(e) => {
                                    error!("âŒ Product detail crawling failed: {}", e);
                                    (Err(e), None, 0)
                                }
                            }
                        } else {
                            error!("âŒ ProductDetailCollector not available");
                            (Err("ProductDetailCollector not available".to_string()), None, 0)
                        }
                    }
                    StageItem::ProductList(product_list) => {
                        // Legacy: ProductListì—ì„œ ProductUrl ê°ì²´ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬
                        info!("ğŸ“‹ Converting {} products from page {} to ProductUrls for detail crawling", 
                              product_list.products.len(), product_list.page_number);
                        
                        // â­ ì¤‘ìš”: Product -> ProductUrlë¡œ ë³€í™˜ ì‹œ ë©”íƒ€ë°ì´í„° ë³´ì¡´
                        // ì‹¤ì œ ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ PageIdCalculator ì´ˆê¸°í™”
                        // StatusChecker traitì— discover_total_pagesê°€ ì—†ìœ¼ë¯€ë¡œ fallback ê°’ ì‚¬ìš©
                        let (total_pages, products_on_last_page) = match (self.site_total_pages_hint, self.products_on_last_page_hint) {
                            (Some(tp), Some(plp)) => (tp, plp),
                            _ => {
                                // ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ ì•Œë ¤ì§„ ê°’ ì‚¬ìš©
                                let fallback = (498u32, 8u32);
                                info!("âœ… Using fallback site info: total_pages={}, products_on_last_page={}", fallback.0, fallback.1);
                                fallback
                            }
                        };

                        // Canonical ê³„ì‚°: í˜ì´ì§€ enumerate index ëŠ” 0-based
                        let canonical_calc = PaginationCalculator::default(); // total_pages ëŠ” í˜¸ì¶œ ì‹œ ì„¸ ë²ˆì§¸ ì¸ìë¡œ ì „ë‹¬
                        let product_urls: Vec<crate::domain::product_url::ProductUrl> = product_list.products
                            .iter()
                            .enumerate()
                            .map(|(zero_idx, product)| {
                                let c = canonical_calc.calculate(product_list.page_number, zero_idx as u32, total_pages);
                                crate::domain::product_url::ProductUrl { url: product.url.clone(), page_id: c.page_id, index_in_page: c.index_in_page }
                            })
                            .collect();

                        // ğŸ” Debug a compact summary of calculated mappings for this page
                        if !product_urls.is_empty() {
                            let min_page_id = product_urls.iter().map(|p| p.page_id).min().unwrap_or(0);
                            let max_page_id = product_urls.iter().map(|p| p.page_id).max().unwrap_or(0);
                            let min_index = product_urls.iter().map(|p| p.index_in_page).min().unwrap_or(0);
                            let max_index = product_urls.iter().map(|p| p.index_in_page).max().unwrap_or(0);
                            let sample: Vec<String> = product_urls
                                .iter()
                                .take(6)
                                .enumerate()
                                .map(|(i, p)| format!("i{}=>p{}_i{}", i, p.page_id, p.index_in_page))
                                .collect();
                            debug!(
                                "ğŸ“ Stage mapping summary (page {}): count={}, page_id=[{}..{}], index_in_page=[{}..{}], sample={:?}",
                                product_list.page_number,
                                product_urls.len(),
                                min_page_id,
                                max_page_id,
                                min_index,
                                max_index,
                                sample
                            );
                        }
                        
                        if let Some(collector) = &self.product_detail_collector {
                            use crate::new_architecture::channels::types::ProductUrls;
                            let product_urls_wrapper = ProductUrls {
                                urls: product_urls, // ProductUrl ê°ì²´ë“¤ ì§ì ‘ ì €ì¥
                                batch_id: Some(format!("batch_{}", product_list.page_number)),
                            };
                            
                            match Self::execute_real_product_detail_processing(&product_urls_wrapper, Arc::clone(collector)).await {
                                Ok(product_details) => {
                                    info!("âœ… Successfully collected {} product details", product_details.len());
                                    match serde_json::to_string(&product_details) {
                                        Ok(json_data) => (Ok(()), Some(json_data), 0),
                                        Err(e) => (Err(format!("JSON serialization failed: {}", e)), None, 0),
                                    }
                                }
                                Err(e) => {
                                    error!("âŒ Product detail crawling failed: {}", e);
                                    (Err(e), None, 0)
                                }
                            }
                        } else {
                            error!("âŒ ProductDetailCollector not available");
                            (Err("ProductDetailCollector not available".to_string()), None, 0)
                        }
                    }
                    other => {
                        warn!("âš ï¸ ProductDetailCrawling stage received unexpected item type: {:?}", other);
                        (Err("Unexpected item type for ProductDetailCrawling".to_string()), None, 0)
                    }
                }
            }
            StageType::DataValidation => {
                // Stage 3 (ProductDetailCrawling)ì—ì„œ ìˆ˜ì§‘ëœ ProductDetailë“¤ì„ ê²€ì¦
                info!("ğŸ” DataValidation: validating ProductDetails from item {}", item_id);
                
                let product_details: Vec<crate::domain::product::ProductDetail> = match &item {
                    // Stage 3ì—ì„œ ProductDetails ë°ì´í„°ë¥¼ ë°›ìŒ
                    StageItem::ProductDetails(product_details_wrapper) => {
                        info!("ğŸ“‹ Processing ProductDetails with {} products", product_details_wrapper.products.len());
                        product_details_wrapper.products.clone()
                    }
                    StageItem::ProductUrls(_product_urls) => {
                        warn!("âš ï¸ DataValidation received ProductUrls instead of ProductDetails - Stage 3 may have failed");
                        Vec::new()
                    }
                    other => {
                        warn!("âš ï¸ DataValidation stage received unexpected item type: {:?}", other);
                        Vec::new()
                    }
                };
                
                info!("âœ… Extracted {} ProductDetails for validation", product_details.len());
                
                // DataQualityAnalyzerë¡œ í’ˆì§ˆ ê²€ì¦
                use crate::new_architecture::services::data_quality_analyzer::DataQualityAnalyzer;
                let quality_analyzer = DataQualityAnalyzer::new();
                
                match quality_analyzer.validate_before_storage(&product_details).await {
                    Ok(validated_products) => {
                        // ê²€ì¦ëœ ì œí’ˆë“¤ì„ JSONìœ¼ë¡œ ì§ë ¬í™”
                        match serde_json::to_string(&validated_products) {
                            Ok(json_data) => (Ok(()), Some(json_data), 0),
                            Err(e) => (Err(format!("JSON serialization failed: {}", e)), None, 0),
                        }
                    }
                    Err(e) => {
                        error!("âŒ Data validation failed: {}", e);
                        (Err(format!("Data validation failed: {}", e)), None, 0)
                    }
                }
            }
            StageType::DataSaving => {
                // DataSaving persistence ë¡œì§ì€ ë¹„ë™ê¸° task ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ (ctx_clone ìŠ¤ì½”í”„ í™•ë³´ ìœ„í•´ ì—¬ê¸°ì„œëŠ” íŒ¨ìŠ¤ìŠ¤ë£¨)
                // ì—¬ê¸°ì„œëŠ” StageItem ì²˜ë¦¬ ê²°ê³¼ë¥¼ (Ok, None, 0) ë¡œ ë„˜ê¸°ê³  ì‹¤ì œ ì €ì¥ì€ ì•„ë˜ task match ë¶„ê¸°ì—ì„œ ìˆ˜í–‰
                (Ok(()), None, 0)
            }
        };
        
        let duration = start_time.elapsed();
        
        // StageItemì„ StageItemTypeìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
        let item_type = match &item {
            StageItem::Page(page_num) => StageItemType::Page { page_number: *page_num },
            StageItem::Url(_url) => StageItemType::Url { url_type: "site_check".to_string() },
            StageItem::Product(_product) => StageItemType::Url { url_type: "product".to_string() },
            StageItem::ProductList(_) => StageItemType::ProductUrls { urls: vec![] },
            StageItem::ProductUrls(urls) => StageItemType::ProductUrls { urls: urls.urls.iter().map(|u| u.url.clone()).collect() },
            _ => StageItemType::Url { url_type: "unknown".to_string() },
        };
        
        match success {
            Ok(()) => Ok(StageItemResult {
                item_id: item_id,
                item_type,
                success: true,
                error: None,
                duration_ms: duration.as_millis() as u64,
                retry_count: retries_used,
                collected_data,
            }),
            Err(error) => {
                let error_item_type = match &item {
                    StageItem::Page(page_num) => StageItemType::Page { page_number: *page_num },
                    StageItem::Url(_url) => StageItemType::Url { url_type: "site_check".to_string() },
                    StageItem::Product(_product) => StageItemType::Url { url_type: "product".to_string() },
                    StageItem::ProductList(_) => StageItemType::ProductUrls { urls: vec![] },
                    StageItem::ProductUrls(urls) => StageItemType::ProductUrls { urls: urls.urls.iter().map(|u| u.url.clone()).collect() },
                    _ => StageItemType::Url { url_type: "unknown".to_string() },
                };
                
                Ok(StageItemResult {
                    item_id: item_id.clone(),
                    item_type: error_item_type,
                    success: false,
                    error: Some(error.clone()),
                    duration_ms: duration.as_millis() as u64,
                    retry_count: retries_used,
                    collected_data: None,
                })
            }
        }
    }
    
    // === ì‹¤ì œ ì„œë¹„ìŠ¤ ê¸°ë°˜ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (Critical Issue #1) ===
    
    /// ì‹¤ì œ ìƒíƒœ í™•ì¸ ì²˜ë¦¬
    async fn execute_real_status_check(
        item: &StageItem,
        status_checker: Arc<dyn StatusChecker>,
    ) -> Result<SiteStatus, String> {
        // ìƒˆë¡œìš´ StageItem êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
        let item_desc = match item {
            StageItem::Page(page_num) => format!("page_{}", page_num),
            StageItem::Url(url) => url.clone(),
            _ => "unknown".to_string(),
        };
        
        // ì‹¤ì œ ì‚¬ì´íŠ¸ ìƒíƒœ í™•ì¸
        match status_checker.check_site_status().await {
            Ok(status) => {
                info!("âœ… Real status check successful for item {}", item_desc);
                Ok(status)
            }
            Err(e) => {
                warn!("âŒ Real status check failed for item {}: {}", item_desc, e);
                Err(format!("Status check failed: {}", e))
            }
        }
    }
    
    /// ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ì²˜ë¦¬
    async fn execute_real_list_page_processing(
        &self,
        item: &StageItem,
        product_list_collector: Arc<dyn ProductListCollector>,
    ) -> Result<Vec<crate::domain::product_url::ProductUrl>, String> {
        match item {
            StageItem::Page(page_number) => {
                // ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ í¬ë¡¤ë§
                // í˜ì´ì§€ë„¤ì´ì…˜ íŒíŠ¸ ì‚¬ìš©, ì—†ìœ¼ë©´ í•„ìš” ì‹œ ìƒíƒœ ì¬í™•ì¸
                let (total_pages, products_on_last_page) = match (self.site_total_pages_hint, self.products_on_last_page_hint) {
                    (Some(tp), Some(plp)) => (tp, plp),
                    _ => {
                        if let Some(checker) = &self.status_checker {
                            match checker.check_site_status().await {
                                Ok(s) => (s.total_pages, s.products_on_last_page),
                                Err(e) => {
                                    warn!("âš ï¸ Failed to get site status for list processing, using conservative defaults: {}", e);
                                    (100u32, 10u32)
                                }
                            }
                        } else {
                            warn!("âš ï¸ No StatusChecker available; using conservative defaults for pagination");
                            (100u32, 10u32)
                        }
                    }
                };

                // ë‹¨ì¼ í˜ì´ì§€ ìˆ˜ì§‘ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ë¥¼ ê·¸ëŒ€ë¡œ ì „íŒŒ
                match product_list_collector.collect_single_page(
                    *page_number, total_pages, products_on_last_page
                ).await {
                    Ok(urls) => {
                        // ë¹ˆ ê²°ê³¼ëŠ” ì‹¤íŒ¨ë¡œ ê°„ì£¼í•˜ì—¬ ì¬ì‹œë„ë¥¼ ìœ ë„
                        if urls.is_empty() {
                            warn!("âš ï¸ Page {} returned 0 URLs â€” treating as failure to trigger retry", page_number);
                            Err("Empty result from list page".to_string())
                        } else {
                            info!(
                                "âœ… Real list page processing successful for page {}: {} URLs collected",
                                page_number, urls.len()
                            );
                            for (index, url) in urls.iter().enumerate() {
                                debug!("  ğŸ“„ Collected URL {}: {}", index + 1, url.url);
                            }
                            Ok(urls)
                        }
                    }
                    Err(e) => {
                        warn!("âŒ Real list page processing failed for page {}: {}", page_number, e);
                        Err(format!("List page processing failed: {}", e))
                    }
                }
            }
            _ => Ok(vec![]), // ë‹¤ë¥¸ íƒ€ì…ì€ ë¹ˆ ë²¡í„° ë°˜í™˜
        }
    }
    
    /// ì‹¤ì œ ì œí’ˆ ìƒì„¸ ì²˜ë¦¬
    async fn execute_real_product_detail_processing(
        product_urls: &crate::new_architecture::channels::types::ProductUrls,
        product_detail_collector: Arc<dyn ProductDetailCollector>,
    ) -> Result<Vec<crate::domain::product::ProductDetail>, String> {
    debug!("Processing {} product URLs for detail crawling", product_urls.urls.len());
        
        // ProductUrls êµ¬ì¡°ì²´ì—ì„œ ProductUrl ê°ì²´ë“¤ì„ ì§ì ‘ ì‚¬ìš©
        match product_detail_collector.collect_details(&product_urls.urls).await {
            Ok(details) => {
                info!("âœ… Real product detail processing successful: {} details collected", details.len());
                
                // ìˆ˜ì§‘ëœ ProductDetailë“¤ì„ ë¡œê·¸ë¡œ í™•ì¸
                for (index, detail) in details.iter().enumerate() {
                    debug!("  ğŸ“„ Collected detail {}: {} (page_id: {:?}, index: {:?})", 
                           index + 1, detail.url, detail.page_id, detail.index_in_page);
                }
                
                Ok(details)
            }
            Err(e) => {
                warn!("âŒ Real product detail processing failed: {}", e);
                Err(format!("Product detail processing failed: {}", e))
            }
        }
    }
    
    /// ì‹¤ì œ ë°ì´í„° ê²€ì¦ ì²˜ë¦¬ (í˜„ì¬ ì™¸ë¶€ì—ì„œ ì§ì ‘ í˜¸ì¶œí•˜ì§€ ì•Šì•„ dead_code ê²½ê³  ë°œìƒ ê°€ëŠ¥)
    #[allow(dead_code)]
    async fn execute_real_data_validation(item: &StageItem) -> Result<(), String> {
        match item {
            StageItem::ProductDetails(product_details) => {
                info!("ğŸ” Starting data validation for {} ProductDetails", product_details.products.len());
                
                // DataQualityAnalyzer ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ê²€ì¦ ìˆ˜í–‰
                use crate::new_architecture::services::data_quality_analyzer::DataQualityAnalyzer;
                let analyzer = DataQualityAnalyzer::new();
                
                match analyzer.validate_before_storage(&product_details.products).await {
                    Ok(validated_products) => {
                        info!("âœ… Data quality validation completed: {} products validated", validated_products.len());
                        if validated_products.len() != product_details.products.len() {
                            warn!("âš ï¸  Data validation filtered out {} products", 
                                  product_details.products.len() - validated_products.len());
                        }
                        Ok(())
                    }
                    Err(e) => {
                        error!("âŒ Data quality validation failed: {}", e);
                        Err(format!("Data validation failed: {}", e))
                    }
                }
            }
            StageItem::ValidatedProducts(products) => {
                info!("âœ… ValidatedProducts already validated: {} products", products.products.len());
                Ok(())
            }
            _ => {
                warn!("âš ï¸  DataValidation received unexpected item type, skipping validation");
                Ok(())
            }
        }
    }
    
    /// ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì²˜ë¦¬
    async fn execute_real_database_storage(
        item: &StageItem,
        product_repo: Arc<IntegratedProductRepository>,
    ) -> Result<(u32,u32,u32), String> { // (inserted, updated, duplicates)
        match item {
            StageItem::ProductDetails(wrapper) => {
                info!("[PersistExec] handling ProductDetails count={} extraction_stats=attempted:{} success:{} failed:{}", wrapper.products.len(), wrapper.extraction_stats.attempted, wrapper.extraction_stats.successful, wrapper.extraction_stats.failed);
                let products = &wrapper.products;
                if products.is_empty() { return Ok((0,0,0)); }
                // Duplicate detection by URL
                let mut seen = std::collections::HashSet::new();
                let mut duplicates: Vec<String> = Vec::new();
                for d in products { if !seen.insert(d.url.clone()) { duplicates.push(d.url.clone()); } }
                if !duplicates.is_empty() { warn!("[PersistExec] duplicate urls detected count={} urls={:?}", duplicates.len(), duplicates); }
                let mut inserted = 0u32; let mut updated = 0u32; let mut duplicates_ct = 0u32;
                for (idx, detail) in products.iter().enumerate() {
                    let start = std::time::Instant::now();
                    debug!("[PersistExec] upsert detail idx={} url={} page_id={:?}", idx, detail.url, detail.page_id);
                    match product_repo.create_or_update_product_detail(&detail).await {
                        Ok((was_updated, was_created)) => {
                            if was_created { inserted += 1; }
                            if was_updated { updated += 1; }
                            if !was_created && !was_updated { duplicates_ct += 1; }
                            debug!("[PersistExecDetail] idx={} url={} created={} updated={} elapsed_ms={}", idx, detail.url, was_created, was_updated, start.elapsed().as_millis());
                        },
                        Err(e) => return Err(format!("Database save failed: {}", e))
                    }
                }
                Ok((inserted, updated, duplicates_ct))
            }
            StageItem::ValidatedProducts(wrapper) => {
                info!("[PersistExec] handling ValidatedProducts count={}", wrapper.products.len());
                let products = &wrapper.products;
                if products.is_empty() { return Ok((0,0,0)); }
                let mut seen = std::collections::HashSet::new();
                let mut duplicates: Vec<String> = Vec::new();
                for d in products { if !seen.insert(d.url.clone()) { duplicates.push(d.url.clone()); } }
                if !duplicates.is_empty() { warn!("[PersistExec] duplicate validated urls detected count={} urls={:?}", duplicates.len(), duplicates); }
                let mut inserted = 0u32; let mut updated = 0u32; let mut duplicates_ct = 0u32;
                for (idx, detail) in products.iter().enumerate() {
                    let start = std::time::Instant::now();
                    debug!("[PersistExec] upsert validated detail idx={} url={} page_id={:?}", idx, detail.url, detail.page_id);
                    match product_repo.create_or_update_product_detail(&detail).await {
                        Ok((was_updated, was_created)) => {
                            if was_created { inserted += 1; }
                            if was_updated { updated += 1; }
                            if !was_created && !was_updated { duplicates_ct += 1; }
                            debug!("[PersistExecDetail] validated idx={} url={} created={} updated={} elapsed_ms={}", idx, detail.url, was_created, was_updated, start.elapsed().as_millis());
                        },
                        Err(e) => return Err(format!("Database save failed: {}", e))
                    }
                }
                Ok((inserted, updated, duplicates_ct))
            }
            _ => Ok((0,0,0))
        }
    }
    
    // === ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜ë“¤ (ê¸°ì¡´) ===
    
    /// ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (Phase 3 ì„ì‹œ)
    #[allow(dead_code)]
    async fn simulate_list_page_processing(item: &StageItem) -> Result<(), String> {
        // ì„ì‹œ: ê°„ë‹¨í•œ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        tokio::time::sleep(Duration::from_millis(100)).await;
        
        // 90% ì„±ê³µë¥  ì‹œë®¬ë ˆì´ì…˜ - ê°„ë‹¨í•œ ë°©ë²• ì‚¬ìš©
        let success = match item {
            StageItem::Page(_) => true,
            StageItem::Url(_) => true,
            StageItem::Product(_) => true,
            StageItem::ValidationTarget(_) => true,
            StageItem::ProductList(_) => true, // ëŒ€ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ê°€ì •
            StageItem::ProductUrls(_) => true,
            StageItem::ProductDetails(_) => true,
            StageItem::ValidatedProducts(_) => true,
        };
        
        if success {
            Ok(())
        } else {
            Err("Simulated network error".to_string())
        }
    }
    
    /// ìŠ¤í…Œì´ì§€ ì •ë¦¬
    fn cleanup_stage(&mut self) {
        self.stage_id = None;
        self.stage_type = None;
        self.state = StageState::Idle;
        self.start_time = None;
        self.total_items = 0;
        self.completed_items = 0;
        self.success_count = 0;
        self.failure_count = 0;
        self.skipped_count = 0;
        self.item_results.clear();
    }
    
    /// ì§„í–‰ ìƒí™© ê³„ì‚°
    /// 
    /// # Returns
    /// * `f64` - ì§„í–‰ë¥  (0.0 ~ 1.0)
    fn calculate_progress(&self) -> f64 {
        if self.total_items == 0 {
            0.0
        } else {
            f64::from(self.completed_items) / f64::from(self.total_items)
        }
    }
    
    /// ì„±ê³µë¥  ê³„ì‚°
    /// 
    /// # Returns
    /// * `f64` - ì„±ê³µë¥  (0.0 ~ 1.0)
    fn calculate_success_rate(&self) -> f64 {
        if self.completed_items == 0 {
            0.0
        } else {
            f64::from(self.success_count) / f64::from(self.completed_items)
        }
    }
}

// (ê¸°ì¡´ ìƒì„¸ Actor trait êµ¬í˜„ì€ íŒŒì¼ í•˜ë‹¨ ì›ë³¸ ì˜ì—­ ìœ ì§€)

#[async_trait::async_trait]
impl Actor for StageActor {
    type Command = ActorCommand;
    type Error = ActorError;

    fn actor_id(&self) -> &str {
        self.stage_id.as_deref().unwrap_or("unknown")
    }

    fn actor_type(&self) -> ActorType {
        ActorType::Stage
    }

    async fn run(
        &mut self,
        mut context: AppContext,
        mut command_rx: mpsc::Receiver<Self::Command>,
    ) -> Result<(), Self::Error> {
        info!("ğŸ¯ StageActor {} starting execution loop", self.actor_id);
        
        loop {
            tokio::select! {
                // ëª…ë ¹ ì²˜ë¦¬
                command = command_rx.recv() => {
                    match command {
                        Some(cmd) => {
                            debug!("ğŸ“¨ StageActor {} received command: {:?}", self.actor_id, cmd);
                            
                            match cmd {
                                ActorCommand::ExecuteStage { 
                                    stage_type, 
                                    items: _, // TODO: ì ì ˆí•œ íƒ€ì… ë³€í™˜ í•„ìš”
                                    concurrency_limit, 
                                    timeout_secs 
                                } => {
                                    // ì„ì‹œ: ë¹ˆ ë²¡í„°ë¡œ ì²˜ë¦¬í•˜ì—¬ ì»´íŒŒì¼ ì—ëŸ¬ í•´ê²°
                                    let empty_items = Vec::new();
                                    if let Err(e) = self.handle_execute_stage(
                                        stage_type, 
                                        empty_items, 
                                        concurrency_limit, 
                                        timeout_secs, 
                                        &context
                                    ).await {
                                        error!("Failed to execute stage: {}", e);
                                    }
                                }
                                
                                ActorCommand::Shutdown => {
                                    info!("ğŸ›‘ StageActor {} received shutdown command", self.actor_id);
                                    break;
                                }
                                
                                _ => {
                                    debug!("StageActor {} ignoring non-stage command", self.actor_id);
                                }
                            }
                        }
                        None => {
                            warn!("ğŸ“ª StageActor {} command channel closed", self.actor_id);
                            break;
                        }
                    }
                }
                
                // ì·¨ì†Œ ì‹ í˜¸ í™•ì¸
                _ = context.cancellation_token.changed() => {
                    if *context.cancellation_token.borrow() {
                        warn!("ğŸš« StageActor {} received cancellation signal", self.actor_id);
                        break;
                    }
                }
            }
        }
        
        info!("ğŸ StageActor {} execution loop ended", self.actor_id);
        Ok(())
    }
    
    async fn health_check(&self) -> Result<ActorHealth, Self::Error> {
        let status = match &self.state {
            StageState::Idle => ActorStatus::Healthy,
            StageState::Processing => ActorStatus::Healthy,
            StageState::Completed => ActorStatus::Healthy,
            StageState::Timeout => ActorStatus::Degraded { 
                reason: "Stage timed out".to_string(),
                since: Utc::now(),
            },
            StageState::Failed { error } => ActorStatus::Unhealthy { 
                error: error.clone(),
                since: Utc::now(),
            },
            _ => ActorStatus::Degraded { 
                reason: format!("In transition state: {:?}", self.state),
                since: Utc::now(),
            },
        };
        
        Ok(ActorHealth {
            actor_id: self.stage_id.clone().unwrap_or_default(),
            actor_type: ActorType::Stage,
            status,
            last_activity: Utc::now(),
            memory_usage_mb: 0, // TODO: ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
            active_tasks: if matches!(self.state, StageState::Processing) { 
                self.total_items - self.completed_items 
            } else { 
                0 
            },
            commands_processed: 0, // TODO: ì‹¤ì œ ì²˜ë¦¬ëœ ëª…ë ¹ ìˆ˜ ê³„ì‚°
            errors_count: 0, // TODO: ì‹¤ì œ ì—ëŸ¬ ìˆ˜ ê³„ì‚°
            avg_command_processing_time_ms: 0.0, // TODO: ì‹¤ì œ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            metadata: serde_json::json!({
                "stage_id": self.stage_id,
                "stage_type": self.stage_type,
                "state": format!("{:?}", self.state),
                "total_items": self.total_items,
                "completed_items": self.completed_items,
                "success_count": self.success_count,
                "failure_count": self.failure_count,
                "skipped_count": self.skipped_count,
                "progress": self.calculate_progress(),
                "success_rate": self.calculate_success_rate()
            }).to_string(),
        })
    }

    /// ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰
    async fn shutdown(&mut self) -> Result<(), Self::Error> {
        info!("ğŸ”Œ StageActor {} shutting down", self.actor_id);
        
        // í™œì„± ìŠ¤í…Œì´ì§€ê°€ ìˆë‹¤ë©´ ì •ë¦¬
        if self.stage_id.is_some() {
            warn!("Cleaning up active stage during shutdown");
            self.cleanup_stage();
        }
        
        Ok(())
    }
}

impl StageActor {
    /// ì‹¤ì œ URLì—ì„œ ProductDetailì„ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    /// ServiceBasedBatchCrawlingEngineì˜ ë¡œì§ì„ ì°¸ì¡°í•˜ì—¬ êµ¬í˜„
    /// ì‹¤ì œ HTTP ìš”ì²­ìœ¼ë¡œ ì œí’ˆ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
    /// DataValidation ìŠ¤í…Œì´ì§€ì—ì„œ ProductUrls -> ProductDetails ë³€í™˜ì— ì‚¬ìš©
    #[allow(dead_code)]
    async fn extract_product_detail_from_url(&self, url: &str) -> Result<crate::domain::product::ProductDetail, ActorError> {
        // HTTP í´ë¼ì´ì–¸íŠ¸ í™•ì¸
        let http_client = self.http_client.as_ref()
            .ok_or_else(|| ActorError::RequestFailed("HTTP client not available".to_string()))?;
            
        // HTTP í´ë¼ì´ì–¸íŠ¸ë¡œ URLì—ì„œ HTML ê°€ì ¸ì˜¤ê¸°
        let response = http_client.fetch_response(url).await
            .map_err(|e| ActorError::RequestFailed(format!("HTTP request failed: {}", e)))?;
        
        let html_content = response.text().await
            .map_err(|e| ActorError::ParsingFailed(format!("Failed to get response text: {}", e)))?;

        if html_content.trim().is_empty() {
            return Err(ActorError::ParsingFailed(format!("Empty HTML content from {}", url)));
        }

        // ë°ì´í„° ì¶”ì¶œê¸° í™•ì¸
        let data_extractor = self.data_extractor.as_ref()
            .ok_or_else(|| ActorError::ParsingFailed("Data extractor not available".to_string()))?;
            
        // ë°ì´í„° ì¶”ì¶œê¸°ë¡œ HTML íŒŒì‹±
        let product_data_json = data_extractor.extract_product_data(&html_content)
            .map_err(|e| ActorError::ParsingFailed(format!("Failed to extract product data: {}", e)))?;

        // JSONì—ì„œ í•„ë“œë“¤ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
        let manufacturer = product_data_json.get("manufacturer")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        let model = product_data_json.get("model")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        let certificate_id = product_data_json.get("certificate_id")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        let pid = product_data_json.get("pid")
            .and_then(|v| v.as_str())
            .and_then(|s| s.parse::<i32>().ok());

        // ProductDetail êµ¬ì¡°ì²´ ìƒì„±
        use crate::domain::product::ProductDetail;
        Ok(ProductDetail {
            url: url.to_string(),
            page_id: None,
            index_in_page: None,
            id: None,
            manufacturer,
            model,
            device_type: None,
            certificate_id: certificate_id,
            certification_date: None,
            software_version: None,
            hardware_version: None,
            firmware_version: None,
            specification_version: None,
            vid: None,
            pid,
            family_sku: None,
            family_variant_sku: None,
            family_id: None,
            tis_trp_tested: None,
            transport_interface: None,
            primary_device_type_id: None,
            application_categories: None,
            description: None,
            compliance_document_url: None,
            program_type: Some("Matter".to_string()),
            created_at: chrono::Utc::now(),
            updated_at: chrono::Utc::now(),
        })
    }
}
