use serde::{Deserialize, Serialize};
use tauri::AppHandle;
use tracing::info;
// chrono is not used directly in this module

use crate::commands::actor_system_commands::{start_actor_system_crawling, ActorCrawlingRequest, CrawlingMode};

/// í†µí•© í¬ë¡¤ë§ ìš”ì²­ êµ¬ì¡°ì²´
#[derive(Debug, Deserialize)]
pub struct StartCrawlingRequest {
    pub mode: Option<String>, // "advanced" | "live" (UI ë‘ íƒ­)
    pub override_batch_size: Option<u32>,
    pub override_concurrency: Option<u32>,
    pub delay_ms: Option<u64>,
}

/// í†µí•© í¬ë¡¤ë§ ì‘ë‹µ êµ¬ì¡°ì²´
#[derive(Debug, Serialize)]
pub struct StartCrawlingResponse {
    pub success: bool,
    pub message: String,
    pub session_id: Option<String>,
}

/// í†µí•© í¬ë¡¤ë§ ëª…ë ¹ì–´ (Actor ì‹œìŠ¤í…œ ì§„ì…ì )
#[tauri::command]
pub async fn start_unified_crawling(
    app: AppHandle,
    request: StartCrawlingRequest,
) -> Result<StartCrawlingResponse, String> {
    info!("ğŸš€ í†µí•© í¬ë¡¤ë§ ìš”ì²­ ìˆ˜ì‹ : {:?}", request);
    
    // ë‹¨ì¼ ê²½ë¡œ: Actor ê¸°ë°˜
    let crawling_mode = match request.mode.as_deref() {
        Some("advanced") => Some(CrawlingMode::AdvancedEngine),
        Some("live") => Some(CrawlingMode::LiveProduction),
        _ => None,
    };
    let actor_req = ActorCrawlingRequest {
        site_url: None,
        start_page: None,
        end_page: None,
        page_count: None,
        concurrency: request.override_concurrency,
        batch_size: request.override_batch_size,
        delay_ms: request.delay_ms,
        mode: crawling_mode,
    };
    let result = start_actor_system_crawling(app.clone(), actor_req)
        .await
        .map_err(|e| format!("failed to start actor crawling: {}", e))?;
    Ok(StartCrawlingResponse { success: result.success, message: result.message, session_id: result.session_id })
}

// NOTE: engine_type ì œê±°ë¡œ í˜¸ì¶œ ë‹¨ìˆœí™”ë¨. FEëŠ” mode + override_* ë§Œ ì „ë‹¬.
