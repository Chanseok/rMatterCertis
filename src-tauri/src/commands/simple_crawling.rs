use tauri::State;
use serde::{Deserialize, Serialize};
use ts_rs::TS;
use tracing::info;

use crate::infrastructure::config::ConfigManager;
use crate::infrastructure::crawling_service_impls::CrawlingRangeCalculator;
use crate::infrastructure::integrated_product_repository::IntegratedProductRepository;
use crate::application::AppState;

/// í¬ë¡¤ë§ ì„¸ì…˜ ì •ë³´ (ê°„ì†Œí™”)
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct CrawlingSession {
    pub session_id: String,
    pub started_at: String,
    pub status: String,
}

/// Smart Crawling ì‹œì‘ - ì„¤ì • íŒŒì¼ ê¸°ë°˜ ìë™ ì‹¤í–‰
#[tauri::command]
pub async fn start_smart_crawling(
    app_handle: tauri::AppHandle,
    state: State<'_, AppState>
) -> Result<CrawlingSession, String> {
    let session_id = format!("session_{}", chrono::Utc::now().timestamp());
    let started_at = chrono::Utc::now().to_rfc3339();
    
    info!("ğŸš€ Starting smart crawling session: {} (ì„¤ì • íŒŒì¼ ê¸°ë°˜ ììœ¨ ë™ì‘)", session_id);
    
    // ğŸ¯ ì„¤ê³„ ë¬¸ì„œ ì¤€ìˆ˜: íŒŒë¼ë¯¸í„° ì—†ì´ ì„¤ì • íŒŒì¼ë§Œìœ¼ë¡œ ë™ì‘
    // 1. ì„¤ì • íŒŒì¼ ìë™ ë¡œë”© (config/*.toml)
    let config_manager = ConfigManager::new()
        .map_err(|e| format!("Failed to initialize config manager: {}", e))?;
    
    let config = config_manager.load_config().await
        .map_err(|e| format!("Failed to load config from file: {}", e))?;

    info!("âœ… Config loaded from files: max_pages={}, request_delay={}ms", 
          config.user.crawling.page_range_limit, config.user.request_delay_ms);

    // 2. Actor ì‹œìŠ¤í…œì— ì„¸ì…˜ ì‹œì‘ ëª…ë ¹ ì „ì†¡ (ì„¤ê³„ ë¬¸ì„œ ì¤€ìˆ˜)
    // TODO: SessionActor â†’ BatchActor â†’ StageActor ê³„ì¸µì  êµ¬ì¡° ì‚¬ìš©
    // use crate::new_architecture::actor_system::SessionActor;
    // let session_command = ActorCommand::StartSession { session_id: session_id.clone() };
    // session_actor.send(session_command).await?;
    
    // 3. ì„ì‹œ: ì§ì ‘ í¬ë¡¤ë§ ì‹¤í–‰ (ë‚˜ì¤‘ì— Actor ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´)
    info!("âš ï¸ ì„ì‹œ êµ¬í˜„: Actor ì‹œìŠ¤í…œ ëŒ€ì‹  ì§ì ‘ ì‹¤í–‰ (ì¶”í›„ ì„¤ê³„ ë¬¸ì„œ ì¤€ìˆ˜ë¡œ ë³€ê²½ í•„ìš”)");
    
    // ServiceBasedBatchCrawlingEngine ì‚¬ìš© (ì„ì‹œ)
    use crate::commands::crawling_v4::{CrawlingEngineState, execute_crawling_with_range, init_crawling_engine};
    use tauri::Manager;
    
    if let Some(engine_state) = app_handle.try_state::<CrawlingEngineState>() {
        // ì—”ì§„ ì´ˆê¸°í™” í™•ì¸
        {
            let engine_guard = engine_state.engine.read().await;
            if engine_guard.is_none() {
                drop(engine_guard);
                info!("ğŸ”§ Initializing crawling engine...");
                
                match init_crawling_engine(app_handle.clone(), engine_state.clone()).await {
                    Ok(response) => {
                        if !response.success {
                            return Err(format!("Engine initialization failed: {}", response.message));
                        }
                    }
                    Err(e) => return Err(format!("Engine initialization error: {}", e)),
                }
            }
        }
        
        // ì„ì‹œ: ë²”ìœ„ ê³„ì‚° (ë‚˜ì¤‘ì— CrawlingPlannerë¡œ ì´ë™ í•„ìš”)
        let pool = state.get_database_pool().await?;
        let product_repo = IntegratedProductRepository::new(pool);
        let range_calculator = CrawlingRangeCalculator::new(
            std::sync::Arc::new(product_repo),
            config.clone(),
        );
        
        let total_pages = 485u32; // TODO: ì‚¬ì´íŠ¸ ìƒíƒœ ì²´í¬ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        let products_on_last_page = 11u32; // TODO: ì‚¬ì´íŠ¸ ë¶„ì„ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        
        let range_result = range_calculator.calculate_next_crawling_range(
            total_pages,
            products_on_last_page,
        ).await
        .map_err(|e| format!("Range calculation failed: {}", e))?;
        
        if let Some((start_page, end_page)) = range_result {
            info!("ğŸ“Š Calculated range: {} â†’ {} (ì„¤ì • íŒŒì¼ ê¸°ë°˜)", start_page, end_page);
            
            // ğŸ¯ ì„¤ê³„ ì¤€ìˆ˜: ë²”ìœ„ ì¬ê³„ì‚° ì—†ì´ ì§ì ‘ ì‹¤í–‰
            match execute_crawling_with_range(
                &app_handle,
                &engine_state,
                start_page,
                end_page
            ).await {
                Ok(response) => {
                    info!("âœ… Smart crawling initiated: {}", response.message);
                }
                Err(e) => {
                    return Err(format!("Crawling execution failed: {}", e));
                }
            }
        } else {
            return Err("No pages to crawl (all up to date)".to_string());
        }
    } else {
        return Err("CrawlingEngineState not available".to_string());
    }
    
    Ok(CrawlingSession {
        session_id,
        started_at,
        status: "started".to_string(),
    })
}
