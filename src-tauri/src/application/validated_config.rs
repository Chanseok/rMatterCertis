use crate::infrastructure::config::AppConfig;
use std::time::Duration;

/// ê²€ì¦ë˜ê³  ì ìš© ê°€ëŠ¥í•œ í¬ë¡¤ë§ ì„¤ì • êµ¬ì¡°ì²´
/// 
/// ì‚¬ìš©ì ì„¤ì •ì„ ê²€ì¦í•˜ê³  í•˜ë“œì½”ë”©ëœ ê°’ë“¤ì„ ì œê±°í•˜ê¸° ìœ„í•œ êµ¬ì¡°ì²´ì…ë‹ˆë‹¤.
/// ëª¨ë“  ì„¤ì •ê°’ì€ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ë²”ìœ„ë¡œ ê²€ì¦ë˜ë©°, ì´ ê°’ë“¤ì´ ì‹¤ì œ í¬ë¡¤ë§ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
#[derive(Debug, Clone)]
pub struct ValidatedCrawlingConfig {
    /// ê²€ì¦ëœ ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜ (í•˜ë“œì½”ë”© ì œê±°)
    pub max_concurrent: u32,
    /// ê²€ì¦ëœ í˜ì´ì§€ ë²”ìœ„ ì œí•œ (í•˜ë“œì½”ë”© ì œê±°) 
    pub page_range_limit: u32,
    /// ê²€ì¦ëœ ë°°ì¹˜ í¬ê¸°
    pub batch_size: u32,
    /// ì„¸ë§ˆí¬ì–´ í—ˆìš© ìˆ˜ (max_concurrentì™€ ë™ì¼)
    pub semaphore_permits: usize,
    /// ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„
    pub request_delay_ms: u64,
    /// ì¬ì‹œë„ íšŸìˆ˜
    pub max_retries: u32,
    /// íƒ€ì„ì•„ì›ƒ ì„¤ì •
    pub request_timeout_seconds: u32,
}

impl ValidatedCrawlingConfig {
    /// ì‚¬ìš©ì ì„¤ì •ì—ì„œ ê²€ì¦ëœ í¬ë¡¤ë§ ì„¤ì • ìƒì„±
    /// 
    /// ëª¨ë“  ì„¤ì •ê°’ì„ ê²€ì¦í•˜ê³  ì•ˆì „í•œ ë²”ìœ„ë¡œ ì œí•œí•©ë‹ˆë‹¤.
    pub fn from_user_config(config: &AppConfig) -> Self {
        let user_config = &config.user;
        let crawling_config = &user_config.crawling;
        let workers_config = &crawling_config.workers;
        
        // ë™ì‹œì„± ì„¤ì • ê²€ì¦ (1-50 ë²”ìœ„)
        let max_concurrent = workers_config.list_page_max_concurrent
            .max(1)   // ìµœì†Œ 1ê°œ
            .min(50); // ìµœëŒ€ 50ê°œ
            
        // í˜ì´ì§€ ë²”ìœ„ ì œí•œ ê²€ì¦ (1-500 ë²”ìœ„)  
        let page_range_limit = crawling_config.page_range_limit
            .max(1)    // ìµœì†Œ 1í˜ì´ì§€
            .min(500); // ìµœëŒ€ 500í˜ì´ì§€
            
        // ë°°ì¹˜ í¬ê¸° ê²€ì¦ (1-200 ë²”ìœ„)
        let batch_size = workers_config.db_batch_size
            .max(1)    // ìµœì†Œ 1ê°œ
            .min(200); // ìµœëŒ€ 200ê°œ
            
        // ìš”ì²­ ì§€ì—° ì‹œê°„ ê²€ì¦ (100ms-10000ms ë²”ìœ„)
        let request_delay_ms = user_config.request_delay_ms
            .max(100)   // ìµœì†Œ 100ms
            .min(10000); // ìµœëŒ€ 10ì´ˆ
            
        // ì¬ì‹œë„ íšŸìˆ˜ ê²€ì¦ (1-10 ë²”ìœ„)
        let max_retries = workers_config.max_retries
            .max(1)   // ìµœì†Œ 1íšŒ
            .min(10); // ìµœëŒ€ 10íšŒ
            
        // íƒ€ì„ì•„ì›ƒ ê²€ì¦ (10-120ì´ˆ ë²”ìœ„)
        let request_timeout_seconds = workers_config.request_timeout_seconds
            .max(10)  // ìµœì†Œ 10ì´ˆ
            .min(120); // ìµœëŒ€ 2ë¶„
            
        Self {
            max_concurrent,
            page_range_limit,
            batch_size,
            semaphore_permits: max_concurrent as usize,
            request_delay_ms,
            max_retries,
            request_timeout_seconds,
        }
    }
    
    /// ì„¤ì •ê°’ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    pub fn log_config(&self) {
        log::info!("ğŸ”§ ValidatedCrawlingConfig applied:");
        log::info!("   max_concurrent: {} (semaphore_permits: {})", 
                   self.max_concurrent, self.semaphore_permits);
        log::info!("   page_range_limit: {}", self.page_range_limit);
        log::info!("   batch_size: {}", self.batch_size);
        log::info!("   request_delay_ms: {}", self.request_delay_ms);
        log::info!("   max_retries: {}", self.max_retries);
        log::info!("   request_timeout_seconds: {}", self.request_timeout_seconds);
    }
    
    /// ë™ì‹œì„± ì œì–´ìš© ì„¸ë§ˆí¬ì–´ í¬ê¸° ë°˜í™˜
    pub fn get_semaphore_permits(&self) -> usize {
        self.semaphore_permits
    }
    
    /// ìš”ì²­ ì§€ì—° Duration ë°˜í™˜
    pub fn get_request_delay(&self) -> Duration {
        Duration::from_millis(self.request_delay_ms)
    }
    
    /// ìš”ì²­ íƒ€ì„ì•„ì›ƒ Duration ë°˜í™˜
    pub fn get_request_timeout(&self) -> Duration {
        Duration::from_secs(self.request_timeout_seconds as u64)
    }
}

impl Default for ValidatedCrawlingConfig {
    fn default() -> Self {
        Self {
            max_concurrent: 3,
            page_range_limit: 10,
            batch_size: 50,
            semaphore_permits: 3,
            request_delay_ms: 1000,
            max_retries: 3,
            request_timeout_seconds: 30,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::infrastructure::config::defaults;

    #[test]
    fn test_config_validation_ranges() {
        let mut config = AppConfig::default();
        
        // ê·¹ë‹¨ì ì¸ ê°’ë“¤ ì„¤ì •
        config.user.crawling.workers.list_page_max_concurrent = 0; // ë„ˆë¬´ ì‘ìŒ
        config.user.crawling.page_range_limit = 1000; // ë„ˆë¬´ í¼
        config.user.request_delay_ms = 50; // ë„ˆë¬´ ì‘ìŒ
        
        let validated = ValidatedCrawlingConfig::from_user_config(&config);
        
        // ê²€ì¦ëœ ë²”ìœ„ í™•ì¸
        assert_eq!(validated.max_concurrent, 1); // ìµœì†Œê°’ìœ¼ë¡œ ë³´ì •
        assert_eq!(validated.page_range_limit, 500); // ìµœëŒ€ê°’ìœ¼ë¡œ ë³´ì •
        assert_eq!(validated.request_delay_ms, 100); // ìµœì†Œê°’ìœ¼ë¡œ ë³´ì •
        assert_eq!(validated.semaphore_permits, 1); // max_concurrentì™€ ë™ì¼
    }
    
    #[test]
    fn test_config_normal_values() {
        let mut config = AppConfig::default();
        
        // ì •ìƒì ì¸ ê°’ë“¤ ì„¤ì •
        config.user.crawling.workers.list_page_max_concurrent = 24;
        config.user.crawling.page_range_limit = 20;
        config.user.request_delay_ms = 500;
        
        let validated = ValidatedCrawlingConfig::from_user_config(&config);
        
        // ì„¤ì •ê°’ì´ ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸
        assert_eq!(validated.max_concurrent, 24);
        assert_eq!(validated.page_range_limit, 20);
        assert_eq!(validated.request_delay_ms, 500);
        assert_eq!(validated.semaphore_permits, 24);
    }
}
