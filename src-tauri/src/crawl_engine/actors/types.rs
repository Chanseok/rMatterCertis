//! Actor ì‹œìŠ¤í…œ íƒ€ì… ì •ì˜
//!
//! Actor ê°„ í†µì‹ ê³¼ ì´ë²¤íŠ¸ë¥¼ ìœ„í•œ í•µì‹¬ íƒ€ì…ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
//! ts-rsë¥¼ í†µí•´ TypeScript íƒ€ì…ì´ ìë™ ìƒì„±ë©ë‹ˆë‹¤.

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use ts_rs::TS;

// ë„ë©”ì¸ ê°ì²´ import ì¶”ê°€
use crate::domain::integrated_product::ProductDetail;
use crate::domain::product_url::ProductUrl;

/// Actor-Event ê³„ì•½ ë²„ì „ (additive-only ì •ì±…)
pub const ACTOR_CONTRACT_VERSION: &str = "v1"; // bump when UI requires new additive schema set

/// Actor ê°„ í†µì‹ ì„ ìœ„í•œ í†µí•© ëª…ë ¹ íƒ€ì…
///
/// ì‹œìŠ¤í…œì˜ ëª¨ë“  Actorê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ê³µí†µ ëª…ë ¹ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
/// ê³„ì¸µë³„ë¡œ ëª…ë ¹ì„ êµ¬ë¶„í•˜ì—¬ ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub enum ActorCommand {
    // === ì„¸ì…˜ ë ˆë²¨ ëª…ë ¹ ===
    /// í¬ë¡¤ë§ ì„¸ì…˜ ì‹œì‘
    StartCrawling {
        session_id: String,
        config: CrawlingConfig,
    },

    /// ì„¸ì…˜ ì¼ì‹œì •ì§€
    PauseSession { session_id: String, reason: String },

    /// ì„¸ì…˜ ì¬ê°œ
    ResumeSession { session_id: String },

    /// ì„¸ì…˜ ì·¨ì†Œ
    CancelSession { session_id: String, reason: String },

    /// ë¯¸ë¦¬ ìƒì„±ëœ ExecutionPlanì„ ê·¸ëŒ€ë¡œ ì‹¤í–‰ (ì¬ê³„íš ê¸ˆì§€)
    ExecutePrePlanned {
        session_id: String,
        plan: ExecutionPlan,
    },

    // === ë°°ì¹˜ ë ˆë²¨ ëª…ë ¹ ===
    /// ë°°ì¹˜ ì²˜ë¦¬
    ProcessBatch {
        batch_id: String,
        pages: Vec<u32>,
        config: BatchConfig,
        batch_size: u32,
        concurrency_limit: u32,
        total_pages: u32,
        products_on_last_page: u32,
    },

    // === ìŠ¤í…Œì´ì§€ ë ˆë²¨ ëª…ë ¹ ===
    /// ìŠ¤í…Œì´ì§€ ì‹¤í–‰
    ExecuteStage {
        stage_type: StageType,
        items: Vec<StageItem>,
        concurrency_limit: u32,
        timeout_secs: u64,
    },

    // === ì‹œìŠ¤í…œ ë ˆë²¨ ëª…ë ¹ ===
    /// ì‹œìŠ¤í…œ ì¢…ë£Œ
    Shutdown,

    /// í—¬ìŠ¤ ì²´í¬
    HealthCheck,
}

/// Actor ê°„ ì „ë‹¬ë˜ëŠ” ì´ë²¤íŠ¸
///
/// ì‹œìŠ¤í…œ ìƒíƒœ ë³€í™”ë¥¼ ì•Œë¦¬ëŠ” ì´ë²¤íŠ¸ë“¤ì…ë‹ˆë‹¤.
/// ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œì…ë‹ˆë‹¤.
/// ActorContractVersion: v1
/// Core field groups (v2 clarification - additive only):
/// - Session lifecycle: SessionStarted/Completed/Failed { session_id, timestamp }
/// - Progress: Progress { session_id, current_step, total_steps, percentage }
/// - Batch: BatchStarted/Completed/Failed { batch_id, session_id, timestamp }
/// - Stage: StageStarted/Completed/Failed { stage_type, session_id, batch_id? }
/// - Persistence diagnostics: `ProductLifecycle` { status, metrics? }, `PersistenceAnomaly` { kind, detail }
/// - Metrics snapshots: DatabaseStats { total_product_details, min_page, max_page }
/// UI ì†Œë¹„ìëŠ” ìµœì†Œ session_id + timestamp ì¡°í•©ì„ í‚¤ë¡œ ì‚¬ìš©í•˜ê³ , ì„ íƒì ìœ¼ë¡œ batch_id / stage_type ìœ¼ë¡œ ì„¸ë¶„í™” ë Œë”ë§.
///
/// ë²„ì „ ê´€ë¦¬ ì›ì¹™:
/// 1. Additive-only (ìƒˆ ì´ë²¤íŠ¸/í•„ë“œ ì¶”ê°€ëŠ” í—ˆìš©)
/// 2. í•„ë“œ ì œê±°/ì˜ë¯¸ ë³€ê²½ ê¸ˆì§€ â†’ ìƒˆ í•„ë“œ/ì´ë²¤íŠ¸ë¡œ êµì²´ í›„ ê¸°ì¡´ Deprecated ìœ ì§€
/// 3. ë²„ì „ ì¦ê°€ ì¡°ê±´: UI ë¶„ê¸° í•„ìˆ˜ ìŠ¤í‚¤ë§ˆ ë³€í™”(ì¶”ê°€ í•„ë“œê°€ breaking semantic) ë˜ëŠ” ìš”ì•½(summary) êµ¬ì¡° í™•ì¥
/// 4. TS `actorContractVersion.ts` ì™€ ê°’ ë™ê¸°í™” í•„ìš”
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AppEvent {
    // === ì„¸ì…˜ ì´ë²¤íŠ¸ ===
    SessionStarted {
        session_id: String,
        config: CrawlingConfig,
        timestamp: DateTime<Utc>,
    },

    SessionPaused {
        session_id: String,
        reason: String,
        timestamp: DateTime<Utc>,
    },

    SessionResumed {
        session_id: String,
        timestamp: DateTime<Utc>,
    },

    SessionCompleted {
        session_id: String,
        summary: SessionSummary,
        timestamp: DateTime<Utc>,
    },

    /// ì„¸ì…˜ ì¢…ë£Œ í›„, ë‹¤ìŒ í¬ë¡¤ë§ ë²”ìœ„ë¥¼ ìœ„í•œ ì‹ ê·œ ê³„íš(í”Œë˜ë„ˆ ê²°ê³¼)ì„ ì „ë‹¬
    NextPlanReady {
        session_id: String,
    plan: crate::crawl_engine::services::crawling_planner::CrawlingPlan,
        timestamp: DateTime<Utc>,
    },

    SessionFailed {
        session_id: String,
        error: String,
        final_failure: bool,
        timestamp: DateTime<Utc>,
    },

    SessionTimeout {
        session_id: String,
        elapsed: u64, // Durationì„ millisecondsë¡œ ë³€ê²½
        timestamp: DateTime<Utc>,
    },

    /// ì‚¬ì „ ì ê²€(í”„ë¦¬í”Œë¼ì´íŠ¸) ì§„ë‹¨ ì´ë²¤íŠ¸: ë¡œì»¬ DB ë° ì‚¬ì´íŠ¸ ìƒíƒœ ìš”ì•½
    PreflightDiagnostics {
        session_id: String,
        db_products: i64,
        db_min_page: Option<i32>,
        db_max_page: Option<i32>,
        site_total_pages: Option<u32>,
        site_known_last_page: Option<u32>,
        reason: Option<String>,
        timestamp: DateTime<Utc>,
    },

    /// ì €ì¥ ë‹¨ê³„ ì´ìƒ íƒì§€ (ì˜ˆ: ì˜ˆìƒ ì‹ ê·œ/ì—…ë°ì´íŠ¸ ì—†ì„ ë•Œ, page_id ì—­ìˆœ ë¶ˆì¼ì¹˜ ë“±)
    PersistenceAnomaly {
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        kind: String,   // e.g. "all_noop", "page_id_mismatch"
        detail: String, // human readable description
        attempted: u32, // attempted product details in this batch stage
        inserted: u32,
        updated: u32,
        timestamp: DateTime<Utc>,
    },

    /// DB í†µê³„ ìŠ¤ëƒ…ìƒ· (ì§„í–‰ ì¤‘ ì£¼ê¸°ì  ë³´ê³  ìš©ë„)
    DatabaseStats {
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        total_product_details: i64,
        min_page: Option<i32>,
        max_page: Option<i32>,
        note: Option<String>,
        timestamp: DateTime<Utc>,
    },

    // === ë°°ì¹˜ ì´ë²¤íŠ¸ ===
    BatchStarted {
        batch_id: String,
        session_id: String,
        pages_count: u32,
        timestamp: DateTime<Utc>,
    },

    BatchCompleted {
        batch_id: String,
        session_id: String,
        success_count: u32,
        failed_count: u32,
        duration: u64, // Durationì„ millisecondsë¡œ ë³€ê²½
        timestamp: DateTime<Utc>,
    },

    BatchFailed {
        batch_id: String,
        session_id: String,
        error: String,
        final_failure: bool,
        timestamp: DateTime<Utc>,
    },

    // === ìŠ¤í…Œì´ì§€ ì´ë²¤íŠ¸ ===
    StageStarted {
        stage_type: StageType,
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        items_count: u32,
        timestamp: DateTime<Utc>,
    },

    StageCompleted {
        stage_type: StageType,
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        result: StageResult,
        timestamp: DateTime<Utc>,
    },

    StageFailed {
        stage_type: StageType,
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        error: String,
        timestamp: DateTime<Utc>,
    },

    /// ìŠ¤í…Œì´ì§€ ì¬ì‹œë„ ì•Œë¦¼ (additive v1)
    StageRetrying {
        stage_type: StageType,
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        attempt: u32,
        max_attempts: u32,
        reason: Option<String>,
        timestamp: DateTime<Utc>,
    },

    // === ìŠ¤í…Œì´ì§€ ì•„ì´í…œ(ì„¸ë¶€ ë‹¨ìœ„) ì´ë²¤íŠ¸ ===
    /// ê°œë³„ ì•„ì´í…œ ì²˜ë¦¬ ì‹œì‘ (í˜ì´ì§€ ë˜ëŠ” ìƒí’ˆ ë‹¨ìœ„)
    StageItemStarted {
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        stage_type: StageType,
        item_id: String,
        item_type: StageItemType,
        timestamp: DateTime<Utc>,
    },
    /// ê°œë³„ ì•„ì´í…œ ì²˜ë¦¬ ì™„ë£Œ
    StageItemCompleted {
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        stage_type: StageType,
        item_id: String,
        item_type: StageItemType,
        success: bool,
        #[serde(skip_serializing_if = "Option::is_none")]
        error: Option<String>,
        duration_ms: u64,
        retry_count: u32,
        /// ìˆ˜ì§‘ëœ ì—”íŠ¸ë¦¬ ìˆ˜ (ListPage: product URL ê°œìˆ˜, ProductDetail: ìƒì„¸ í•„ë“œ ê°ì²´ ê°œìˆ˜)
        #[serde(skip_serializing_if = "Option::is_none")]
        collected_count: Option<u32>,
        timestamp: DateTime<Utc>,
    },

    // === ì§„í–‰ ìƒí™© ì´ë²¤íŠ¸ ===
    Progress {
        session_id: String,
        current_step: u32,
        total_steps: u32,
        message: String,
        percentage: f64,
        timestamp: DateTime<Utc>,
    },

    // === ì„±ëŠ¥ ì´ë²¤íŠ¸ ===
    PerformanceMetrics {
        session_id: String,
        metrics: PerformanceMetrics,
        timestamp: DateTime<Utc>,
    },

    // === ë¦¬í¬íŠ¸ ì´ë²¤íŠ¸ ===
    /// ë°°ì¹˜ ë‹¨ìœ„ ìš”ì•½ ë¦¬í¬íŠ¸
    BatchReport {
        session_id: String,
        batch_id: String,
        pages_total: u32,
        pages_success: u32,
        pages_failed: u32,
        list_pages_failed: Vec<u32>,
        details_success: u32,
        details_failed: u32,
        retries_used: u32,
        duration_ms: u64,
        /// ì¤‘ë³µ ì œê±°ë¡œ ìŠ¤í‚µëœ Product URL ìˆ˜ (ì˜µì…˜ - v1 ê¸°ë³¸ 0)
        #[serde(default)]
        duplicates_skipped: u32,
        #[serde(default)]
        products_inserted: u32,
        #[serde(default)]
        products_updated: u32,
        timestamp: DateTime<Utc>,
    },

    /// ì„¸ì…˜ ì „ì²´ ìš”ì•½ ë¦¬í¬íŠ¸
    CrawlReportSession {
        session_id: String,
        batches_processed: u32,
        total_pages: u32,
        total_success: u32,
        total_failed: u32,
        total_retries: u32,
        duration_ms: u64,
        #[serde(default)]
        products_inserted: u32,
        #[serde(default)]
        products_updated: u32,
        timestamp: DateTime<Utc>,
    },

    // === Phase lifecycle events (high-level orchestration) ===
    PhaseStarted {
        session_id: String,
        phase: CrawlPhase,
        timestamp: DateTime<Utc>,
    },
    PhaseCompleted {
        session_id: String,
        phase: CrawlPhase,
        succeeded: bool,
        duration_ms: u64,
        timestamp: DateTime<Utc>,
    },
    PhaseAborted {
        session_id: String,
        phase: CrawlPhase,
        reason: String,
        timestamp: DateTime<Utc>,
    },

    // === Graceful shutdown events ===
    ShutdownRequested {
        session_id: String,
        reason: String,
        timestamp: DateTime<Utc>,
    },
    ShutdownCompleted {
        session_id: String,
        timestamp: DateTime<Utc>,
    },

    // === (Additive v1) Granular Page / Detail Task Events ===
    /// ê°œë³„ í˜ì´ì§€ ì²˜ë¦¬ ì‹œì‘ (ListPages phase ë²”ìœ„ ë‚´)
    PageTaskStarted {
        session_id: String,
        page: u32,
        batch_id: Option<String>,
        timestamp: DateTime<Utc>,
    },
    /// ê°œë³„ í˜ì´ì§€ ì²˜ë¦¬ ì„±ê³µ
    PageTaskCompleted {
        session_id: String,
        page: u32,
        batch_id: Option<String>,
        duration_ms: u64,
        timestamp: DateTime<Utc>,
    },
    /// ê°œë³„ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (ì¬ì‹œë„ í›„ ìµœì¢… ì‹¤íŒ¨ ë˜ëŠ” ì¤‘ê°„ ì‹¤íŒ¨)
    PageTaskFailed {
        session_id: String,
        page: u32,
        batch_id: Option<String>,
        error: String,
        final_failure: bool,
        timestamp: DateTime<Utc>,
    },
    /// (ë¯¸êµ¬í˜„ ProductDetails Phase ëŒ€ë¹„) ìƒì„¸ ì‘ì—… ì‹œì‘
    DetailTaskStarted {
        session_id: String,
        detail_id: String,
        page: Option<u32>,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        #[serde(skip_serializing_if = "Option::is_none")]
        range_idx: Option<u32>,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_index: Option<u32>,
        /// ì´ë²¤íŠ¸ ìŠ¤ì½”í”„ íŒíŠ¸ (ì˜ˆ: "session" | "batch" ë“±)
        #[serde(skip_serializing_if = "Option::is_none")]
        scope: Option<String>,
        timestamp: DateTime<Utc>,
    },
    DetailTaskCompleted {
        session_id: String,
        detail_id: String,
        page: Option<u32>,
        duration_ms: u64,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        #[serde(skip_serializing_if = "Option::is_none")]
        range_idx: Option<u32>,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_index: Option<u32>,
        /// ì´ë²¤íŠ¸ ìŠ¤ì½”í”„ íŒíŠ¸ (ì˜ˆ: "session" | "batch" ë“±)
        #[serde(skip_serializing_if = "Option::is_none")]
        scope: Option<String>,
        timestamp: DateTime<Utc>,
    },
    DetailTaskFailed {
        session_id: String,
        detail_id: String,
        page: Option<u32>,
        error: String,
        final_failure: bool,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        #[serde(skip_serializing_if = "Option::is_none")]
        range_idx: Option<u32>,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_index: Option<u32>,
        /// ì´ë²¤íŠ¸ ìŠ¤ì½”í”„ íŒíŠ¸ (ì˜ˆ: "session" | "batch" ë“±)
        #[serde(skip_serializing_if = "Option::is_none")]
        scope: Option<String>,
        timestamp: DateTime<Utc>,
    },
    /// Detail phase dynamic concurrency reduction triggered
    DetailConcurrencyDownshifted {
        session_id: String,
        old_limit: u32,
        new_limit: u32,
        trigger: String,
        timestamp: DateTime<Utc>,
    },

    // === Fine-grained lifecycle events (additive v2) ===
    /// Page lifecycle state transition (queued -> fetch_started -> fetch_completed | failed -> urls_extracted)
    PageLifecycle {
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        page_number: u32,
        status: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        metrics: Option<SimpleMetrics>,
        timestamp: DateTime<Utc>,
    },
    /// Product lifecycle (optional aggregation level for group fetch) or per-product when available
    ProductLifecycle {
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        /// Origin page number if known
        #[serde(skip_serializing_if = "Option::is_none")]
        page_number: Option<u32>,
        product_ref: String, // URL or hashed key
        status: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        retry: Option<u32>,
        #[serde(skip_serializing_if = "Option::is_none")]
        duration_ms: Option<u64>,
        #[serde(skip_serializing_if = "Option::is_none")]
        metrics: Option<SimpleMetrics>,
        timestamp: DateTime<Utc>,
    },
    /// Grouped product lifecycle aggregation (reduces event volume)
    ProductLifecycleGroup {
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        #[serde(skip_serializing_if = "Option::is_none")]
        page_number: Option<u32>,
        group_size: u32,
        started: u32,
        succeeded: u32,
        failed: u32,
        duplicates: u32,
        duration_ms: u64,
        phase: String, // fetch | persist
        timestamp: DateTime<Utc>,
    },
    /// Fine grained HTTP fetch latency for list or detail product requests
    HttpRequestTiming {
        session_id: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        batch_id: Option<String>,
        request_kind: String, // list_page | detail_page
        target: String,       // URL or logical key
        page_number: Option<u32>,
        attempt: u32,
        latency_ms: u64,
        timestamp: DateTime<Utc>,
    },

    // === Validation (page_id/index_in_page integrity) events (additive v1) ===
    ValidationStarted {
        session_id: String,
        scan_pages: u32,
        total_pages_site: Option<u32>,
        timestamp: DateTime<Utc>,
    },
    ValidationPageScanned {
        session_id: String,
        physical_page: u32,
        products_found: u32,
        assigned_start_offset: u64,
        assigned_end_offset: u64,
        timestamp: DateTime<Utc>,
    },
    ValidationDivergenceFound {
        session_id: String,
        physical_page: u32,
        kind: String,   // first_missing | coord_mismatch | duplicate | gap
        detail: String, // human readable
        expected_offset: u64,
        timestamp: DateTime<Utc>,
    },
    ValidationAnomaly {
        session_id: String,
        code: String, // duplicate_index | sparse_page | out_of_range
        detail: String,
        timestamp: DateTime<Utc>,
    },
    ValidationCompleted {
        session_id: String,
        pages_scanned: u32,
        products_checked: u64,
        divergences: u32,
        anomalies: u32,
        duration_ms: u64,
        timestamp: DateTime<Utc>,
    },

    // === Sync (partial recrawl + DB upsert) events (additive v1) ===
    SyncStarted {
        session_id: String,
        ranges: Vec<(u32, u32)>, // (start_oldest, end_newest) inclusive per range
        #[serde(skip_serializing_if = "Option::is_none")]
        rate_limit: Option<u32>,
        timestamp: DateTime<Utc>,
    },
    SyncPageStarted {
        session_id: String,
        physical_page: u32,
        timestamp: DateTime<Utc>,
    },
    SyncUpsertProgress {
        session_id: String,
        physical_page: u32,
        inserted: u32,
        updated: u32,
        skipped: u32,
        failed: u32,
        timestamp: DateTime<Utc>,
    },
    SyncPageCompleted {
        session_id: String,
        physical_page: u32,
        inserted: u32,
        updated: u32,
        skipped: u32,
        failed: u32,
        ms: u64,
        timestamp: DateTime<Utc>,
    },
    SyncWarning {
        session_id: String,
        code: String,
        detail: String,
        timestamp: DateTime<Utc>,
    },
    SyncCompleted {
        session_id: String,
        pages_processed: u32,
        inserted: u32,
        updated: u32,
        skipped: u32,
        failed: u32,
        duration_ms: u64,
        #[serde(skip_serializing_if = "Option::is_none")]
        deleted: Option<u32>,
        #[serde(skip_serializing_if = "Option::is_none")]
        total_pages: Option<u32>,
        #[serde(skip_serializing_if = "Option::is_none")]
        items_on_last_page: Option<u32>,
        #[serde(skip_serializing_if = "Option::is_none")]
        anomalies: Option<Vec<SyncAnomalyEntry>>,
        timestamp: DateTime<Utc>,
    },
}

/// Compact anomaly entry for SyncCompleted summary
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SyncAnomalyEntry {
    pub page_id: i32,
    pub count: i64,
    pub current_page_number: u32,
}

// Lightweight TS-friendly metrics container (additive, extensible)
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "kind", content = "data")]
pub enum SimpleMetrics {
    Page {
        url_count: Option<u32>,
        scheduled_details: Option<u32>,
        error: Option<String>,
    },
    Product {
        fields: Option<u32>,
        size_bytes: Option<u32>,
        error: Option<String>,
    },
    Generic {
        key: String,
        value: String,
    },
}

/// High-level crawl phases (extensible)
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub enum CrawlPhase {
    ListPages,
    ProductDetails,
    DataValidation,
    Finalize,
}

/// í¬ë¡¤ë§ ì„¤ì •
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct CrawlingConfig {
    /// ì‚¬ì´íŠ¸ URL
    pub site_url: String,

    /// ì‹œì‘ í˜ì´ì§€
    pub start_page: u32,

    /// ì¢…ë£Œ í˜ì´ì§€
    pub end_page: u32,

    /// ë™ì‹œ ì‹¤í–‰ ì œí•œ
    pub concurrency_limit: u32,

    /// ë°°ì¹˜ í¬ê¸°
    pub batch_size: u32,

    /// ìš”ì²­ ì§€ì—° ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    pub request_delay_ms: u64,

    /// íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    pub timeout_secs: u64,

    /// ì¬ì‹œë„ íšŸìˆ˜
    pub max_retries: u32,

    /// í¬ë¡¤ë§ ì „ëµ (ê¸°ë³¸: ìµœì‹  í˜ì´ì§€ ê¸°ì¤€ ì—­ìˆœ)
    pub strategy: CrawlingStrategy,
}

impl Default for CrawlingConfig {
    fn default() -> Self {
        Self {
            site_url: "https://example.com".to_string(),
            start_page: 1,
            end_page: 10,
            concurrency_limit: 5,
            batch_size: 20,
            request_delay_ms: 1000,
            timeout_secs: 30,
            max_retries: 3,
            strategy: CrawlingStrategy::NewestFirst,
        }
    }
}

/// í¬ë¡¤ë§ ì „ëµ ëª¨ë“œ
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub enum CrawlingStrategy {
    /// ì‚¬ì´íŠ¸ ìµœì‹  í˜ì´ì§€ë¶€í„° Nê°œ (ê¸°ì¡´ Planner ê¸°ë³¸)
    NewestFirst,
    /// ë¡œì»¬ DB ì €ì¥ ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ì–´ì„œ ìˆ˜ì§‘ (ì¦ë¶„)
    ContinueFromDb,
}

/// ë°°ì¹˜ ì„¤ì •
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct BatchConfig {
    /// ë°°ì¹˜ í¬ê¸°
    pub batch_size: u32,

    /// ë™ì‹œ ì‹¤í–‰ ì œí•œ
    pub concurrency_limit: u32,

    /// ë°°ì¹˜ ê°„ ì§€ì—° ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    pub batch_delay_ms: u64,

    /// ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ì—¬ë¶€
    pub retry_on_failure: bool,

    /// ì‹œì‘ í˜ì´ì§€ (ì˜µì…˜)
    pub start_page: Option<u32>,

    /// ì¢…ë£Œ í˜ì´ì§€ (ì˜µì…˜)
    pub end_page: Option<u32>,
}

impl Default for BatchConfig {
    fn default() -> Self {
        Self {
            batch_size: 20,
            concurrency_limit: 3,
            batch_delay_ms: 500,
            retry_on_failure: true,
            start_page: None,
            end_page: None,
        }
    }
}

/// ìŠ¤í…Œì´ì§€ íƒ€ì…
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub enum StageType {
    /// ìƒíƒœ í™•ì¸
    StatusCheck,

    /// ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ í¬ë¡¤ë§
    ListPageCrawling,

    /// ìƒí’ˆ ìƒì„¸ í¬ë¡¤ë§
    ProductDetailCrawling,

    /// ë°ì´í„° ê²€ì¦
    DataValidation,

    /// ë°ì´í„° ì €ì¥
    DataSaving,
}

impl StageType {
    /// StageTypeì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    pub fn as_str(&self) -> &'static str {
        match self {
            StageType::StatusCheck => "status_check",
            StageType::ListPageCrawling => "list_page_crawling",
            StageType::ProductDetailCrawling => "product_detail_crawling",
            StageType::DataValidation => "data_validation",
            StageType::DataSaving => "data_saving",
        }
    }
}

/// ìŠ¤í…Œì´ì§€ ì•„ì´í…œ
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct StageItem {
    /// ì•„ì´í…œ ID
    pub id: String,

    /// ì•„ì´í…œ íƒ€ì…
    pub item_type: StageItemType,

    /// ì²˜ë¦¬í•  URL
    pub url: String,

    /// ë©”íƒ€ë°ì´í„°
    pub metadata: String,
}

#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub enum StageItemType {
    Page {
        page_number: u32,
    },
    Product {
        page_number: u32,
    },
    Url {
        url_type: String,
    },
    ProductUrls {
        urls: Vec<String>, // ê°„ë‹¨íˆ URL ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½
    },
    SiteCheck, // ì‚¬ì´íŠ¸ ìƒíƒœ í™•ì¸ìš© ì•„ì´í…œ íƒ€ì…
}

/// ìŠ¤í…Œì´ì§€ ê²°ê³¼
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct StageResult {
    /// ì²˜ë¦¬ëœ ì•„ì´í…œ ìˆ˜
    pub processed_items: u32,

    /// ì„±ê³µí•œ ì•„ì´í…œ ìˆ˜
    pub successful_items: u32,

    /// ì‹¤íŒ¨í•œ ì•„ì´í…œ ìˆ˜
    pub failed_items: u32,

    /// ì²˜ë¦¬ ì‹œê°„
    pub duration_ms: u64,

    /// ìƒì„¸ ê²°ê³¼
    pub details: Vec<StageItemResult>,
}

#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct StageItemResult {
    /// ì•„ì´í…œ ID
    pub item_id: String,

    /// ì•„ì´í…œ íƒ€ì…
    pub item_type: StageItemType,

    /// ì„±ê³µ ì—¬ë¶€
    pub success: bool,

    /// ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
    pub error: Option<String>,

    /// ì²˜ë¦¬ ì‹œê°„
    pub duration_ms: u64,

    /// ì¬ì‹œë„ íšŸìˆ˜
    pub retry_count: u32,

    /// ìˆ˜ì§‘ëœ ë°ì´í„° (JSON ë¬¸ìì—´)
    /// ListPageCrawling: ProductURLë“¤ì˜ JSON ë°°ì—´
    /// ProductDetailCrawling: ProductDetailë“¤ì˜ JSON ë°°ì—´
    /// DataSaving: ì €ì¥ëœ ë°ì´í„°ì˜ ë©”íƒ€ì •ë³´
    pub collected_data: Option<String>,
}

// =============================================================================
// ğŸ”¥ Phase 2: ë„ë©”ì¸ ê°ì²´ ì§ì ‘ ë°˜í™˜ì„ ìœ„í•œ ìƒˆë¡œìš´ íƒ€ì… ì •ì˜
// =============================================================================

/// ìŠ¤í…Œì´ì§€ ê²°ê³¼ ë°ì´í„°
///
/// JSON ì§ë ¬í™” ëŒ€ì‹  íƒ€ì… ì•ˆì „í•œ ë„ë©”ì¸ ê°ì²´ë¥¼ ì§ì ‘ ë°˜í™˜í•©ë‹ˆë‹¤.
/// ì´ëŠ” ì„±ëŠ¥ í–¥ìƒê³¼ íƒ€ì… ì•ˆì „ì„±ì„ ë™ì‹œì— ì œê³µí•©ë‹ˆë‹¤.
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub enum StageResultData {
    /// ìƒíƒœ í™•ì¸ ê²°ê³¼
    StatusCheck {
        site_available: bool,
        total_pages: Option<u32>,
        last_page_products: Option<u32>,
        response_time_ms: u64,
    },

    /// ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ í¬ë¡¤ë§ ê²°ê³¼ - ProductUrl ì§ì ‘ ë°˜í™˜
    ProductUrls {
        urls: Vec<ProductUrl>,
        page_number: u32,
        total_found: u32,
    },

    /// ìƒí’ˆ ìƒì„¸ í¬ë¡¤ë§ ê²°ê³¼ - ProductDetail ì§ì ‘ ë°˜í™˜
    ProductDetails {
        details: Vec<ProductDetail>,
        successful_count: u32,
        failed_count: u32,
    },

    /// ë°ì´í„° ê²€ì¦ ê²°ê³¼
    ValidationResult {
        validated_count: u32,
        error_count: u32,
        warnings: Vec<String>,
    },

    /// ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ê²°ê³¼
    QualityAnalysis {
        total_analyzed: u32,
        new_products: u32,
        updated_products: u32,
        duplicate_products: u32,
        incomplete_products: u32,
        quality_score: f64,
        field_completeness_score: f64,
        recommendations: Vec<String>,
    },

    /// ë°ì´í„° ì €ì¥ ê²°ê³¼
    SavingResult {
        saved_count: u32,
        duplicates_found: u32,
        database_id_range: Option<(i64, i64)>, // (min_id, max_id)
    },

    /// ë¹ˆ ê²°ê³¼ (ì²˜ë¦¬í•  ë°ì´í„° ì—†ìŒ)
    Empty,
}

/// ê°œì„ ëœ ìŠ¤í…Œì´ì§€ ì•„ì´í…œ ê²°ê³¼
///
/// collected_dataë¥¼ StageResultDataë¡œ êµì²´í•˜ì—¬ íƒ€ì… ì•ˆì „ì„± í–¥ìƒ
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct EnhancedStageItemResult {
    /// ì•„ì´í…œ ID
    pub item_id: String,

    /// ì•„ì´í…œ íƒ€ì…
    pub item_type: StageItemType,

    /// ì„±ê³µ ì—¬ë¶€
    pub success: bool,

    /// ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
    pub error: Option<String>,

    /// ì²˜ë¦¬ ì‹œê°„
    pub duration_ms: u64,

    /// ì¬ì‹œë„ íšŸìˆ˜
    pub retry_count: u32,

    /// ìˆ˜ì§‘ëœ ë°ì´í„° - íƒ€ì… ì•ˆì „í•œ ë„ë©”ì¸ ê°ì²´ ì§ì ‘ ë°˜í™˜
    pub collected_data: Option<StageResultData>,
}

/// ì„¸ì…˜ ìš”ì•½
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct SessionSummary {
    /// ì„¸ì…˜ ID
    pub session_id: String,

    /// ì´ ì²˜ë¦¬ ì‹œê°„
    pub total_duration_ms: u64,

    /// ì´ ì²˜ë¦¬ëœ í˜ì´ì§€ ìˆ˜
    pub total_pages_processed: u32,

    /// ì´ ì²˜ë¦¬ëœ ìƒí’ˆ ìˆ˜
    pub total_products_processed: u32,

    /// ì„±ê³µë¥ 
    pub success_rate: f64,

    /// í‰ê·  ì²˜ë¦¬ ì‹œê°„ (í˜ì´ì§€ë‹¹, ë°€ë¦¬ì´ˆ)
    pub avg_page_processing_time: u64,

    /// ì—ëŸ¬ ìš”ì•½
    pub error_summary: Vec<ErrorSummary>,

    /// ì¬ì‹œë„ ê´€ë ¨ í†µê³„ (ì¶”ê°€ í•„ë“œ)
    #[serde(default)]
    pub total_retry_events: u32,
    #[serde(default)]
    pub max_retries_single_page: u32,
    #[serde(default)]
    pub pages_retried: u32,
    #[serde(default)]
    pub retry_histogram: Vec<(u32, u32)>, // (retry_count, pages_with_that_count)

    /// ì²˜ë¦¬ëœ ë°°ì¹˜ ìˆ˜
    pub processed_batches: u32,

    /// ì´ ì„±ê³µ ìˆ˜
    pub total_success_count: u32,

    /// ì„¸ì…˜ ì „ì²´ì—ì„œ ì¤‘ë³µ ì œê±°ë¡œ ìŠ¤í‚µëœ Product URL ìˆ˜ (BatchReport í•©ì‚°)
    #[serde(default)]
    pub duplicates_skipped: u32,
    #[serde(default)]
    pub products_inserted: u32,
    #[serde(default)]
    pub products_updated: u32,
    #[serde(default)]
    pub planned_list_batches: u32,
    #[serde(default)]
    pub executed_list_batches: u32,
    #[serde(default)]
    pub failed_pages_count: u32,
    #[serde(default)]
    pub failed_page_ids: Vec<u32>,

    /// ìµœì¢… ìƒíƒœ
    pub final_state: String,

    /// íƒ€ì„ìŠ¤íƒ¬í”„
    pub timestamp: DateTime<Utc>,
}

#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct ErrorSummary {
    /// ì—ëŸ¬ íƒ€ì…
    pub error_type: String,

    /// ë°œìƒ íšŸìˆ˜
    pub count: u32,

    /// ì²« ë²ˆì§¸ ë°œìƒ ì‹œê°„
    pub first_occurrence: DateTime<Utc>,

    /// ë§ˆì§€ë§‰ ë°œìƒ ì‹œê°„
    pub last_occurrence: DateTime<Utc>,
}

/// ì„±ëŠ¥ ë©”íŠ¸ë¦­
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct PerformanceMetrics {
    /// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
    pub memory_usage_mb: f64,

    /// CPU ì‚¬ìš©ë¥  (%)
    pub cpu_usage_percent: f64,

    /// í™œì„± ì‘ì—… ìˆ˜
    pub active_tasks_count: u32,

    /// í ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ìˆ˜
    pub queued_tasks_count: u32,

    /// í‰ê·  ì‘ë‹µ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    pub avg_response_time_ms: f64,

    /// ì²˜ë¦¬ëŸ‰ (ì‘ì—…/ì´ˆ)
    pub throughput_per_second: f64,
}

// =============================================================================
// ì—ëŸ¬ íƒ€ì… ì •ì˜
// =============================================================================

/// Stage ì²˜ë¦¬ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì—ëŸ¬
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub enum StageError {
    /// ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨
    NetworkError { message: String },

    /// HTML íŒŒì‹± ì—ëŸ¬
    ParsingError { message: String },

    /// ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨
    ValidationError { message: String },

    /// ë°ì´í„°ë² ì´ìŠ¤ ì—ëŸ¬
    DatabaseError { message: String },

    /// íƒ€ì„ì•„ì›ƒ ì—ëŸ¬
    TimeoutError { timeout_ms: u64 },

    /// ì„¤ì • ì—ëŸ¬
    ConfigurationError { message: String },

    /// ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ
    NetworkTimeout { timeout_ms: u64 },

    /// ì¼ë°˜ì ì¸ ì—ëŸ¬
    GenericError { message: String },
}

// =============================================================================
// ì„±ê³µ ê²°ê³¼ íƒ€ì… ì •ì˜
// =============================================================================

/// Stage ì„±ê³µ ê²°ê³¼ ìƒì„¸
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct StageSuccessResult {
    /// ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì•„ì´í…œ ìˆ˜
    pub processed_items: u32,

    /// ì²˜ë¦¬ ì†Œìš” ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    pub duration_ms: u64,

    /// ìŠ¤í…Œì´ì§€ ì²˜ë¦¬ ì‹œê°„ (ë°€ë¦¬ì´ˆ) - í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
    pub stage_duration_ms: u64,

    /// ì²˜ë¦¬ìœ¨ (items/second)
    pub throughput: f64,

    /// ì„±ê³µë¥  (0.0 ~ 1.0)
    pub success_rate: f64,

    /// ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    pub metadata: String,

    /// ìˆ˜ì§‘ ë©”íŠ¸ë¦­ìŠ¤
    pub collection_metrics: Option<CollectionMetrics>,

    /// ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤
    pub processing_metrics: Option<ProcessingMetrics>,
}

// =============================================================================
// ë©”íŠ¸ë¦­ìŠ¤ íƒ€ì… ì •ì˜
// =============================================================================

/// ë°ì´í„° ìˆ˜ì§‘ ë©”íŠ¸ë¦­ìŠ¤
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct CollectionMetrics {
    /// ìˆ˜ì§‘ëœ ì´ ì•„ì´í…œ ìˆ˜
    pub total_collected: u32,

    /// ì´ ì•„ì´í…œ ìˆ˜ (í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­)
    pub total_items: u32,

    /// ì„±ê³µí•œ ì•„ì´í…œ ìˆ˜
    pub successful_items: u32,

    /// ì‹¤íŒ¨í•œ ì•„ì´í…œ ìˆ˜  
    pub failed_items: u32,

    /// ìˆ˜ì§‘ ì„±ê³µë¥ 
    pub collection_rate: f64,

    /// í‰ê·  ìˆ˜ì§‘ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    pub avg_collection_time_ms: u64,

    /// ì²˜ë¦¬ ì‹œê°„ (ë°€ë¦¬ì´ˆ) - í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
    pub duration_ms: u64,

    /// í‰ê·  ì‘ë‹µ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    pub avg_response_time_ms: u64,

    /// ì„±ê³µë¥  (0.0 ~ 1.0)
    pub success_rate: f64,

    /// ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ (0.0 ~ 1.0)
    pub data_quality_score: f64,
}

/// ì²˜ë¦¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ìŠ¤
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct ProcessingMetrics {
    /// ì²˜ë¦¬ëœ ì´ ì•„ì´í…œ ìˆ˜
    pub total_processed: u32,

    /// ì²˜ë¦¬ ì„±ê³µë¥ 
    pub processing_rate: f64,

    /// í‰ê·  ì²˜ë¦¬ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    pub avg_processing_time_ms: u64,

    /// ì—ëŸ¬ìœ¨
    pub error_rate: f64,

    /// ì¬ì‹œë„ìœ¨
    pub retry_rate: f64,
}

/// ì‹¤íŒ¨í•œ ì•„ì´í…œ ì •ë³´
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct FailedItem {
    /// ì•„ì´í…œ ID
    pub item_id: String,

    /// ì•„ì´í…œ íƒ€ì…
    pub item_type: String,

    /// ì‹¤íŒ¨ ì‚¬ìœ 
    pub error_message: String,

    /// ì¬ì‹œë„ íšŸìˆ˜
    pub retry_count: u32,

    /// ì‹¤íŒ¨ ì‹œê°
    pub failed_at: DateTime<Utc>,
}

/// Actor ì—ëŸ¬ íƒ€ì…
#[derive(Debug, Clone, Serialize, Deserialize, TS, thiserror::Error)]
#[ts(export)]
pub enum ActorError {
    #[error("ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: {0}")]
    EventBroadcastFailed(String),

    #[error("ëª…ë ¹ ì²˜ë¦¬ ì‹¤íŒ¨: {0}")]
    CommandProcessingFailed(String),

    #[error("ì±„ë„ í†µì‹  ì˜¤ë¥˜: {0}")]
    ChannelError(String),

    #[error("ì„¤ì • ì˜¤ë¥˜: {0}")]
    ConfigurationError(String),

    #[error("íƒ€ì„ì•„ì›ƒ ë°œìƒ: {0}")]
    Timeout(String),

    #[error("ì·¨ì†Œë¨: {0}")]
    Cancelled(String),

    #[error("ë¦¬ì†ŒìŠ¤ ë¶€ì¡±: {0}")]
    ResourceExhausted(String),

    #[error("HTTP ìš”ì²­ ì‹¤íŒ¨: {0}")]
    RequestFailed(String),

    #[error("ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {0}")]
    ParsingFailed(String),

    #[error("ë ˆê±°ì‹œ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {0}")]
    LegacyServiceError(String),

    #[error("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {0}")]
    DatabaseError(String),

    #[error("ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {0}")]
    Unknown(String),
}

// From êµ¬í˜„ë“¤
impl From<anyhow::Error> for ActorError {
    fn from(err: anyhow::Error) -> Self {
        ActorError::CommandProcessingFailed(err.to_string())
    }
}

/// ì‹¤í–‰ ê³„íš - CrawlingPlannerì—ì„œ ìƒì„±ë˜ì–´ SessionActorì—ê²Œ ì „ë‹¬
///
/// ë¶„ì„-ê³„íš-ì‹¤í–‰ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª…í™•íˆ ë¶„ë¦¬í•˜ê¸° ìœ„í•œ í•µì‹¬ êµ¬ì¡°ì²´ì…ë‹ˆë‹¤.
/// CrawlingPlannerê°€ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„±í•œ ìµœì ì˜ ì‹¤í–‰ ê³„íšì„ ë‹´ìŠµë‹ˆë‹¤.
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct ExecutionPlan {
    /// ì‹¤í–‰ ê³„íš ID
    pub plan_id: String,

    /// ì„¸ì…˜ ID
    pub session_id: String,

    /// í¬ë¡¤ë§ ë²”ìœ„ ëª©ë¡ (ì—¬ëŸ¬ ë²”ìœ„ë¥¼ ìˆœì°¨ ì²˜ë¦¬)
    pub crawling_ranges: Vec<PageRange>,

    /// ë°°ì¹˜ í¬ê¸°
    pub batch_size: u32,

    /// ë™ì‹œ ì‹¤í–‰ ì œí•œ
    pub concurrency_limit: u32,

    /// ì˜ˆìƒ ì†Œìš” ì‹œê°„
    pub estimated_duration_secs: u64,

    /// ê³„íš ìƒì„± ì‹œê°„
    pub created_at: DateTime<Utc>,

    /// ë¶„ì„ ì •ë³´ (ë””ë²„ê¹…ìš©)
    pub analysis_summary: String,

    /// ì›ë³¸ ìµœì í™” ì „ëµ (í•´ì‹œ/ê²€ì¦ ì‹œ ì•ˆì •ì  ì‚¬ìš©)
    pub original_strategy: String,

    /// ê³„íš ì…ë ¥ ìŠ¤ëƒ…ìƒ· (ì‚¬ì´íŠ¸/DB ìƒíƒœ) - ë‹¨ì¼ ê¶Œìœ„ ë³´ì¥ ìš©ë„
    pub input_snapshot: PlanInputSnapshot,

    /// ì…ë ¥ ìŠ¤ëƒ…ìƒ· + í•µì‹¬ íŒŒë¼ë¯¸í„° ì§ë ¬í™” í›„ ê³„ì‚°ëœ í•´ì‹œ
    pub plan_hash: String,
    /// ì¤‘ë³µ ìƒí’ˆ URL ìŠ¤í‚µ ì—¬ë¶€ (ê²½ëŸ‰ dedupe 1ë‹¨ê³„)
    pub skip_duplicate_urls: bool,
    pub kpi_meta: Option<ExecutionPlanKpi>,
    /// API / ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ ê³„ì•½ ë²„ì „ (additive-only ë³€ê²½ ì¶”ì )
    pub contract_version: u32,
    /// ì‚¬ì „ ê³„ì‚°ëœ ë…¼ë¦¬ì  page slot ëª©ë¡ (ì—­ìˆœ/ì •ìˆœ í˜¼í•© ì‹œ ìˆœì„œ ìœ ì§€)
    pub page_slots: Vec<PageSlot>,
}

#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct PageSlot {
    /// ì‹¤ì œ ë¬¼ë¦¬ í˜ì´ì§€ ë²ˆí˜¸ (ì‚¬ì´íŠ¸ ê¸°ì¤€)
    pub physical_page: u32,
    /// ë…¼ë¦¬ page_id (0 = ê°€ì¥ ì˜¤ë˜ëœ í˜ì´ì§€ì˜ ë§ˆì§€ë§‰ ì œí’ˆ ê·¸ë£¹)
    pub page_id: i64,
    /// í•´ë‹¹ ë¬¼ë¦¬ í˜ì´ì§€ ë‚´ì—ì„œì˜ index_in_page (0 ê¸°ë°˜, ìµœì‹ â†’ì˜¤ë˜ëœ ì—­ìˆœ ê·œì¹™ ë°˜ì˜)
    pub index_in_page: i16,
}

#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct ExecutionPlanKpi {
    pub total_ranges: usize,
    pub total_pages: u32,
    pub batches: usize,
    pub strategy: String,
    pub created_at: DateTime<Utc>,
}

impl ExecutionPlan {
    /// Preplanned ì‹¤í–‰ ì‹œ ìµœì†Œí•œì˜ SiteStatus í˜•íƒœë¥¼ êµ¬ì„± (í˜ì´ì§€ ì²˜ë¦¬ í†µê³„ìš©)
    pub fn input_snapshot_to_site_status(&self) -> crate::domain::services::SiteStatus {
        use crate::domain::services::crawling_services::{
            CrawlingRangeRecommendation, SiteDataChangeStatus,
        };
        // ì•ˆì • ìƒíƒœ count ì‚°ì¶œ: DB ì´ëŸ‰ >0 ì´ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ í˜ì´ì§€ * ë§ˆì§€ë§‰í˜ì´ì§€ìƒí’ˆìˆ˜ (ëŒ€ëµì¹˜)
        let stable_count: u32 = if self.input_snapshot.db_total_products > 0 {
            // u64 -> u32 ìºìŠ¤íŒ… (ê³¼ë„í•œ ê°’ì€ u32::MAX ë¡œ clamp)
            self.input_snapshot.db_total_products.min(u32::MAX as u64) as u32
        } else {
            let fallback =
                self.input_snapshot.total_pages * self.input_snapshot.products_on_last_page.max(1);
            fallback
        };
        crate::domain::services::SiteStatus {
            is_accessible: true,
            response_time_ms: 0,
            total_pages: self.input_snapshot.total_pages,
            // Use stable_count heuristic (DB total if available) as estimated products
            estimated_products: stable_count,
            products_on_last_page: self.input_snapshot.products_on_last_page,
            last_check_time: chrono::Utc::now(),
            health_score: 1.0,
            data_change_status: SiteDataChangeStatus::Stable {
                count: stable_count,
            },
            decrease_recommendation: None,
            crawling_range_recommendation: CrawlingRangeRecommendation::Full,
        }
    }
}

/// ExecutionPlan ìƒì„± ì‹œì˜ ì…ë ¥ ìƒíƒœ ìŠ¤ëƒ…ìƒ·
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct PlanInputSnapshot {
    pub total_pages: u32,
    pub products_on_last_page: u32,
    pub db_max_page_id: Option<i32>,
    pub db_max_index_in_page: Option<i32>,
    pub db_total_products: u64,
    pub page_range_limit: u32,
    pub batch_size: u32,
    pub concurrency_limit: u32,
    pub created_at: DateTime<Utc>,
}

/// í˜ì´ì§€ ë²”ìœ„
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export)]
pub struct PageRange {
    /// ì‹œì‘ í˜ì´ì§€
    pub start_page: u32,

    /// ë í˜ì´ì§€
    pub end_page: u32,

    /// ì´ ë²”ìœ„ì˜ ì˜ˆìƒ ì œí’ˆ ìˆ˜
    pub estimated_products: u32,

    /// ì—­ìˆœ í¬ë¡¤ë§ ì—¬ë¶€
    pub reverse_order: bool,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_crawling_config_default() {
        let config = CrawlingConfig::default();
        assert_eq!(config.start_page, 1);
        assert_eq!(config.end_page, 10);
        assert_eq!(config.concurrency_limit, 5);
        assert_eq!(config.batch_size, 20);
    }

    #[test]
    fn test_batch_config_default() {
        let config = BatchConfig::default();
        assert_eq!(config.batch_size, 20);
    assert_eq!(config.concurrency_limit, 3);
        assert!(config.retry_on_failure);
    }

    #[test]
    fn test_actor_command_serialization() {
        let command = ActorCommand::StartCrawling {
            session_id: "test-session".to_string(),
            config: CrawlingConfig::default(),
        };

        let serialized = serde_json::to_string(&command).unwrap();
        let deserialized: ActorCommand = serde_json::from_str(&serialized).unwrap();

        match deserialized {
            ActorCommand::StartCrawling { session_id, .. } => {
                assert_eq!(session_id, "test-session");
            }
            _ => panic!("Unexpected command type"),
        }
    }

    #[test]
    fn test_app_event_serialization() {
        let event = AppEvent::SessionStarted {
            session_id: "test-session".to_string(),
            config: CrawlingConfig::default(),
            timestamp: Utc::now(),
        };

        let serialized = serde_json::to_string(&event).unwrap();
        let deserialized: AppEvent = serde_json::from_str(&serialized).unwrap();

        match deserialized {
            AppEvent::SessionStarted { session_id, .. } => {
                assert_eq!(session_id, "test-session");
            }
            _ => panic!("Unexpected event type"),
        }
    }

    #[test]
    fn test_stage_result() {
        let result = StageResult {
            processed_items: 100,
            successful_items: 95,
            failed_items: 5,
            duration_ms: 60000, // 60 seconds in milliseconds
            details: vec![StageItemResult {
                item_id: "item1".to_string(),
                item_type: StageItemType::Url {
                    url_type: "test".to_string(),
                },
                success: true,
                error: None,
                duration_ms: 500,
                retry_count: 0,
                collected_data: None,
            }],
        };

        assert_eq!(result.processed_items, 100);
        assert_eq!(result.successful_items, 95);
        assert_eq!(result.failed_items, 5);
        assert_eq!(result.details.len(), 1);
    }

    #[test]
    fn test_performance_metrics() {
        let metrics = PerformanceMetrics {
            memory_usage_mb: 512.0,
            cpu_usage_percent: 25.5,
            active_tasks_count: 10,
            queued_tasks_count: 5,
            avg_response_time_ms: 150.0,
            throughput_per_second: 50.0,
        };

        assert_eq!(metrics.memory_usage_mb, 512.0);
        assert_eq!(metrics.cpu_usage_percent, 25.5);
        assert_eq!(metrics.active_tasks_count, 10);
    }
}
